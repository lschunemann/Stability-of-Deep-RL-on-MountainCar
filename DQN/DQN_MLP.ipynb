{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc04ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_DQN import running_mean, scale_and_resize, ExperienceMemory, PrioritizedExperienceReplayBuffer\n",
    "import collections\n",
    "import random\n",
    "import gymnasium as gym\n",
    "from models import MLP_state\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "class TrainMountainCar:\n",
    "    def __init__(self, n_training_episodes=200, gamma=0.99, learning_rate=0.1, epsilon_max=0.5,\n",
    "                 epsilon_min=0.05, max_steps=10000, batch_size=32, fixed_target=False,\n",
    "                 copy_target=10000, replay_size=100000, double=False, dueling=False, prioritized=False, debug=False,\n",
    "                 eval_epsilon=None, eval_episodes=10, eval_every=50, noisy=False, distributional=False, env=None,\n",
    "                 epsilon_frame=500000):\n",
    "        self.n_training_episodes = n_training_episodes\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon_max = epsilon_max\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_frame = epsilon_frame\n",
    "        self.max_steps = max_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.fixed_target = fixed_target\n",
    "        self.copy_target = copy_target\n",
    "        self.replay_size = replay_size\n",
    "        self.double = double\n",
    "        self.dueling = dueling\n",
    "        self.debug = debug\n",
    "        self.eval_epsilon = eval_epsilon if eval_epsilon is not None else epsilon_min\n",
    "        self.eval_episodes = eval_episodes\n",
    "        self.eval_every = eval_every\n",
    "        self.prioritized = prioritized,\n",
    "\n",
    "    def epsilon_greedy_policy(self, policy: torch.nn.Module, X, epsilon: float, env: gym.envs):\n",
    "        \"\"\"\n",
    "        Samples a random action with probability epsilon and picks the maximum action under policy network otherwise.\n",
    "        :param policy: Policy Network under which to take action\n",
    "        :param X: stacked tensor of shape (4,80,120)\n",
    "        :param epsilon: float probability of sampling a random action\n",
    "        :param env: Gymnasium environment\n",
    "        :return: Randomly sampled action or maximum action under policy network\n",
    "        \"\"\"\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                X = np.vstack(X).astype(np.float32)\n",
    "                X = torch.tensor(X).squeeze(1)\n",
    "                return policy(X).max(0)[1].view(1, 1).item()\n",
    "\n",
    "\n",
    "#     def get_action(self, policy, s, eps=0.1):\n",
    "#         with torch.no_grad():\n",
    "#             self.seq.pop(0)\n",
    "#             self.seq.append(s)\n",
    "#             if np.random.random() >= eps:\n",
    "#                 X = torch.tensor(np.vstack(self.seq).astype(np.float32), device=device, dtype=torch.float)\n",
    "#                 a = policy(X.unsqueeze(0))\n",
    "#                 # a = a[:, -1, :]  # select last element of seq\n",
    "#                 a = a.max(1)[1]\n",
    "#                 return a.item()\n",
    "#             else:\n",
    "#                 return env.action_space.sample()\n",
    "\n",
    "    # def initialize_measuring_states(self, env):\n",
    "    #     \"\"\"\n",
    "    #     Randomly samples 200 states by taking random actions\n",
    "    #     :param env: Gymnasium environment\n",
    "    #     :return: list of states that were visited by random walk\n",
    "    #     \"\"\"\n",
    "    #     measuring_states = []\n",
    "    #     env.reset()\n",
    "    #     for i in range(200):\n",
    "    #         action = env.action_space.sample()\n",
    "    #         env.step(action)\n",
    "    #         img = env.render()\n",
    "    #         img = transforms.ToTensor()(img)\n",
    "    #         measuring_states.append(transform(img))\n",
    "    #     env.reset()\n",
    "    #     return measuring_states\n",
    "\n",
    "    def eval(self, policy: torch.nn.Module, env: gym.envs):\n",
    "        \"\"\"\n",
    "        Evaluate a policy and return the average reward over self.eval_episodes trials with maximum 10000 steps each\n",
    "        :param policy: The policy to be evaluated\n",
    "        :param env: The Gymnasium environment\n",
    "        :return: average over rewards collected turing trials\n",
    "        \"\"\"\n",
    "        rewards_list = []\n",
    "        for episode in range(self.eval_episodes):\n",
    "            state = env.reset()[0]\n",
    "\n",
    "            # up to 30 no-op actions\n",
    "            noop = random.randint(0, 30)\n",
    "            for i in range(noop):\n",
    "                action = env.action_space.sample()\n",
    "                state,_,_,_,_ = env.step(action)\n",
    "\n",
    "            rewards = 0\n",
    "\n",
    "            for i in range(0, self.max_steps):      # max episode length 10000\n",
    "                action = self.epsilon_greedy_policy(policy, state, self.eval_epsilon, env)\n",
    "#                 action = self.get_action(policy, state, self.eval_epsilon)\n",
    "                state, reward, terminated, _, _ = env.step(action)\n",
    "                rewards += reward\n",
    "\n",
    "                if terminated:\n",
    "                    break\n",
    "\n",
    "            rewards_list.append(rewards)\n",
    "\n",
    "        return np.mean(rewards_list)\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        trains DQN using a fixed target network if self.fixed_target == True, otherwise with the policy network.\n",
    "        :return: list of total rewards, list of steps in each episode, q values over sampled states\n",
    "        \"\"\"\n",
    "\n",
    "        # keep track of total steps and rewards\n",
    "        total_steps = 0\n",
    "        total_rewards = []\n",
    "        total_steps_list = []\n",
    "        evaluations = []\n",
    "\n",
    "        # initialize states in which Q value is measured every X episodes to track progress\n",
    "        # measuring_states = self.initialize_measuring_states(env)\n",
    "        # q_measures = []\n",
    "\n",
    "        # Initialize Experience Memory\n",
    "        if self.prioritized:\n",
    "            beta_start = 0.5\n",
    "            beta_frames = 1000\n",
    "            beta_by_frame = lambda total_steps: min(1.0, beta_start + total_steps * (1.0 - beta_start) / beta_frames)\n",
    "            experience_memory = PrioritizedExperienceReplayBuffer(alpha=0.7, batch_size=self.batch_size,\n",
    "                                                                  buffer_size=self.replay_size)\n",
    "        else:\n",
    "            experience_memory = ExperienceMemory(self.replay_size)\n",
    "\n",
    "        # initialize policy (and target) network\n",
    "        if self.dueling:\n",
    "            policy = MLP_state(env.action_space.n).to(device)\n",
    "            if self.fixed_target:\n",
    "                target = MLP_state(env.action_space.n).to(device)\n",
    "                target.load_state_dict(policy.state_dict())\n",
    "                target.eval()\n",
    "        else:\n",
    "            policy = MLP_state(env.action_space.n).to(device)\n",
    "            if self.fixed_target:\n",
    "                target = MLP_state(env.action_space.n).to(device)\n",
    "                target.load_state_dict(policy.state_dict())\n",
    "                target.eval()\n",
    "\n",
    "        # Best values found during evaluation\n",
    "        best_reward = - float('inf')\n",
    "        best_policy = policy.state_dict()\n",
    "\n",
    "        optimizer = torch.optim.RMSprop(policy.parameters(), lr=self.learning_rate, weight_decay=0.99, momentum=0.95) \n",
    "\n",
    "        for episode in range(self.n_training_episodes):\n",
    "            steps = 0\n",
    "            rewards = 0\n",
    "\n",
    "            state = env.reset()[0]\n",
    "\n",
    "            # up to 30 no-op actions\n",
    "            noop = random.randint(0, 30)\n",
    "            for i in range(noop):\n",
    "                action = env.action_space.sample()\n",
    "                state, _, _, _, _ = env.step(action)\n",
    "\n",
    "            while True:\n",
    "                # linear epsilon decay based on steps\n",
    "                epsilon = max(self.epsilon_max - ((self.epsilon_max - self.epsilon_min)/self.epsilon_frame) *\n",
    "                              total_steps, self.epsilon_min)\n",
    "\n",
    "                # Choose the action At using epsilon greedy policy\n",
    "                action = self.epsilon_greedy_policy(policy, state, epsilon, env)\n",
    "#                 action = self.get_action(policy, X, epsilon)\n",
    "                # take action\n",
    "                new_state, reward, terminated, _, _ = env.step(action)\n",
    "\n",
    "                experience_memory.add((state, action, reward, new_state, terminated))\n",
    "\n",
    "                steps += 1\n",
    "                total_steps += 1\n",
    "\n",
    "                if len(experience_memory) > self.batch_size:\n",
    "                    if self.prioritized:\n",
    "                        beta = beta_by_frame(total_steps)\n",
    "                        idxs, experiences, weights = experience_memory.sample(beta)\n",
    "#                         states, actions, _rewards, next_states, terminations = (i for i in\n",
    "#                                                                                 zip(*experiences))  # (torch.Tensor(vs).to(device) for vs in\n",
    "                        # zip(*experiences))\n",
    "                        weights = torch.tensor(weights).to(device)\n",
    "                    else:\n",
    "                        experiences = experience_memory.sample(self.batch_size)\n",
    "#                     print(list(len(i) for i in zip(*experiences)))\n",
    "                    states, actions, _rewards, next_states, terminations = (i for i in zip(*experiences))\n",
    "                    a = torch.tensor(actions).long().unsqueeze(dim=1).to(device)\n",
    "                    r = torch.tensor(_rewards).unsqueeze(dim=1).to(device)\n",
    "                    states = np.vstack(states).astype(np.float32)\n",
    "                    states = torch.tensor(states).to(device)\n",
    "                    next_states = np.vstack(states).astype(np.float32)\n",
    "                    next_states = torch.tensor(next_states).to(device)\n",
    "#                     states = np.vstack(states).astype(np.float32)\n",
    "#                     states = torch.from_numpy(states)\n",
    "#                     next_states = np.vstack(next_states).astype(np.float32)\n",
    "#                     next_states = torch.from_numpy(next_states)\n",
    "#                     states = torch.reshape(states, (self.batch_size, 1, 84, 84)).to(device)  # 80,120\n",
    "#                     next_states = torch.reshape(next_states, (self.batch_size, 1, 84, 84)).to(device)\n",
    "                    mask = [i for i, x in enumerate(terminations) if not x]  # get all non-final states\n",
    "                    \n",
    "#                     reward = torch.tensor([reward]).to(device)\n",
    "#                     action = torch.tensor([action]).unsqueeze(0).to(device)\n",
    "#                     state = X.unsqueeze(0)\n",
    "#                     new_state = X_new.unsqueeze(0)\n",
    "                    \n",
    "                    steps += 1\n",
    "                    total_steps += 1\n",
    "                    \n",
    "                    state_action_values = policy(states).gather(1, a)\n",
    "                    \n",
    "                    next_state_values = torch.zeros(self.batch_size, device=device)\n",
    "                    \n",
    "                    # update network\n",
    "                    if self.double:\n",
    "                        max_next_action = policy(next_states).max(1)[1].view(-1, 1)\n",
    "                        next_state_values[mask] = target(next_states[mask]).gather(1, max_next_action[mask]).squeeze(1)\n",
    "                    elif self.fixed_target:\n",
    "                        next_state_values[mask] = target(next_states[mask]).max(1)[0].detach()\n",
    "                    else:\n",
    "                        next_state_values[mask] = policy(next_states[mask]).max(1)[0].detach()\n",
    "                    # Compute the expected Q values\n",
    "                    expected_state_action_values = (next_state_values * self.gamma) + r.squeeze(1)\n",
    "                    \n",
    "\n",
    "                    if self.prioritized:\n",
    "                            diff = expected_state_action_values.unsqueeze(1) - state_action_values\n",
    "                            experience_memory.update_priority(idxs, diff.cpu().detach().squeeze().abs().numpy().tolist())\n",
    "\n",
    "                            loss = torch.nn.MSELoss()(state_action_values,\n",
    "                                                      expected_state_action_values.unsqueeze(1)).squeeze() * weights\n",
    "                    else:\n",
    "                    # loss = torch.nn.MSELoss()(state_action_values, expected_state_action_values.unsqueeze(1)).squeeze()\n",
    "                        loss = torch.nn.MSELoss()(state_action_values, expected_state_action_values)\n",
    "\n",
    "                    loss = loss.mean()\n",
    "\n",
    "                    # Optimize the model\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "\n",
    "                    torch.nn.utils.clip_grad_norm_(policy.parameters(), 10.)    # clip gradients\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Update total reward\n",
    "                rewards += reward\n",
    "\n",
    "                # update current state to be next state\n",
    "                state = new_state\n",
    "\n",
    "                # If done, finish the episode\n",
    "                if terminated or steps >= self.max_steps-1:  # or truncated:\n",
    "                    # Track rewards\n",
    "                    total_rewards.append(rewards)\n",
    "                    total_steps_list.append(steps)\n",
    "\n",
    "                    # # measure Q values in selected states\n",
    "                    # Q_states = torch.stack(measuring_states).to(device)\n",
    "                    # Q_states = torch.unique(Q_states, dim=0, sorted=False)  # eliminate duplicate states\n",
    "                    # with torch.no_grad():\n",
    "                    #     q_measures.append(torch.mean(policy(Q_states).max(1)[0]).item())\n",
    "\n",
    "                    # Evaluate current policy and save optimal policy weights\n",
    "                    if episode == self.n_training_episodes-1 or (episode > 0 and episode % self.eval_every == 0):\n",
    "                        eval_reward = self.eval(policy, env)\n",
    "                        if eval_reward > best_reward:\n",
    "                            best_reward = eval_reward\n",
    "                            best_policy = policy.state_dict()\n",
    "                        print(f\"Evaluation: {int(episode/self.eval_every)}\\t average reward: {eval_reward}\")\n",
    "                        evaluations.append(eval_reward)\n",
    "\n",
    "                    # print training information\n",
    "                    if self.debug:\n",
    "                        print(f\"episode: {episode + 1:03d}\\t steps: {steps + 1:05d}\\t total steps:\"\n",
    "                              f\"{total_steps + 1:06d}\\t epsilon: {epsilon:.2f}\")#\\t average Q: {q_measures[-1]:.3f}\")\n",
    "                    break\n",
    "\n",
    "                if self.fixed_target:\n",
    "                    # copy policy network weights to target net every copy_target steps\n",
    "                    if total_steps % self.copy_target <= 4:\n",
    "                        target.load_state_dict(policy.state_dict())\n",
    "\n",
    "        return total_rewards, total_steps_list, best_policy, evaluations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08516760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_training_episodes = 1000\n",
    "gamma = 0.99\n",
    "learning_rate = 0.00025  # 0.1\n",
    "max_training_steps = 10000\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon_max = 1\n",
    "epsilon_min = 0.1\n",
    "# epsilon_frame = 100000\n",
    "\n",
    "# replay memory parameters\n",
    "replay_size = 100000\n",
    "batch_size = 32\n",
    "\n",
    "# fixed target network\n",
    "fixed_target = True\n",
    "copy_target = 10000\n",
    "\n",
    "debug = True\n",
    "\n",
    "epsilon_frame = 500000\n",
    "\n",
    "transform = scale_and_resize()\n",
    "\n",
    "env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "\n",
    "car = TrainMountainCar(n_training_episodes=n_training_episodes, gamma=gamma, learning_rate=learning_rate,\n",
    "                       epsilon_max=epsilon_max, epsilon_min=epsilon_min,\n",
    "                       max_steps=max_training_steps, batch_size=batch_size, fixed_target=fixed_target,\n",
    "                       copy_target=copy_target, debug=debug, env=env, epsilon_frame=epsilon_frame)\n",
    "\n",
    "total_rewards, total_steps_list, best_policy, evaluations = car.train()\n",
    "\n",
    "# save best policy as well as steps and q measures\n",
    "torch.save(best_policy, 'data/DRQN_final.pth')\n",
    "np.savetxt(f'data/steps_DRQN_txt', total_steps_list)\n",
    "# np.savetxt(f'data/q_values_DRQN.txt', q_measures)\n",
    "np.savetxt(f'data/eval_DRQN.txt', evaluations)\n",
    "\n",
    "# Plot steps per episode\n",
    "plt.plot(np.arange(len(total_steps_list)) + 1, total_steps_list, zorder=0, label='training')\n",
    "x = np.arange(50, n_training_episodes+1, 50)\n",
    "plt.scatter(x, [-e for e in evaluations], color='r', marker='x', zorder=1, label='evaluations')\n",
    "N = 10\n",
    "steps_mean = running_mean(total_steps_list, N)\n",
    "plt.plot(np.arange(len(steps_mean)) + 1, steps_mean, zorder=0, label='running average')\n",
    "plt.legend()\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps')\n",
    "plt.title('Steps per Episode - DRQN')\n",
    "plt.savefig('plots/steps_DRQN.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot q measures per episode\n",
    "# plt.plot(np.arange(len(q_measures)) + 1, q_measures)\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Average Q')\n",
    "# plt.title('Average Q measure over sampled states')\n",
    "# plt.savefig('plots/q_measures_DRQN.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f7ef4c",
   "metadata": {},
   "source": [
    "## DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab0f184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 001\t steps: 10001\t total steps:010001\t epsilon: 0.98\n",
      "episode: 002\t steps: 10001\t total steps:020001\t epsilon: 0.96\n",
      "episode: 003\t steps: 10001\t total steps:030001\t epsilon: 0.95\n",
      "episode: 004\t steps: 10001\t total steps:040001\t epsilon: 0.93\n",
      "episode: 005\t steps: 10001\t total steps:050001\t epsilon: 0.91\n",
      "episode: 006\t steps: 10001\t total steps:060001\t epsilon: 0.89\n",
      "episode: 007\t steps: 07721\t total steps:067721\t epsilon: 0.88\n",
      "episode: 008\t steps: 10001\t total steps:077721\t epsilon: 0.86\n",
      "episode: 009\t steps: 10001\t total steps:087721\t epsilon: 0.84\n",
      "episode: 010\t steps: 10001\t total steps:097721\t epsilon: 0.82\n",
      "episode: 011\t steps: 08955\t total steps:106675\t epsilon: 0.81\n",
      "episode: 012\t steps: 10001\t total steps:116675\t epsilon: 0.79\n",
      "episode: 013\t steps: 08125\t total steps:124799\t epsilon: 0.78\n",
      "episode: 014\t steps: 10001\t total steps:134799\t epsilon: 0.76\n",
      "episode: 015\t steps: 10001\t total steps:144799\t epsilon: 0.74\n",
      "episode: 016\t steps: 10001\t total steps:154799\t epsilon: 0.72\n",
      "episode: 017\t steps: 10001\t total steps:164799\t epsilon: 0.70\n",
      "episode: 018\t steps: 05669\t total steps:170467\t epsilon: 0.69\n",
      "episode: 019\t steps: 10001\t total steps:180467\t epsilon: 0.68\n",
      "episode: 020\t steps: 10001\t total steps:190467\t epsilon: 0.66\n",
      "episode: 021\t steps: 10001\t total steps:200467\t epsilon: 0.64\n",
      "episode: 022\t steps: 10001\t total steps:210467\t epsilon: 0.62\n",
      "episode: 023\t steps: 10001\t total steps:220467\t epsilon: 0.60\n",
      "episode: 024\t steps: 06759\t total steps:227225\t epsilon: 0.59\n",
      "episode: 025\t steps: 10001\t total steps:237225\t epsilon: 0.57\n",
      "episode: 026\t steps: 10001\t total steps:247225\t epsilon: 0.56\n",
      "episode: 027\t steps: 04369\t total steps:251593\t epsilon: 0.55\n",
      "episode: 028\t steps: 07967\t total steps:259559\t epsilon: 0.53\n",
      "episode: 029\t steps: 10001\t total steps:269559\t epsilon: 0.51\n",
      "episode: 030\t steps: 07475\t total steps:277033\t epsilon: 0.50\n",
      "episode: 031\t steps: 04749\t total steps:281781\t epsilon: 0.49\n",
      "episode: 032\t steps: 10001\t total steps:291781\t epsilon: 0.47\n",
      "episode: 033\t steps: 10001\t total steps:301781\t epsilon: 0.46\n",
      "episode: 034\t steps: 05455\t total steps:307235\t epsilon: 0.45\n",
      "episode: 035\t steps: 04945\t total steps:312179\t epsilon: 0.44\n",
      "episode: 036\t steps: 08785\t total steps:320963\t epsilon: 0.42\n",
      "episode: 037\t steps: 01513\t total steps:322475\t epsilon: 0.42\n",
      "episode: 038\t steps: 08857\t total steps:331331\t epsilon: 0.40\n",
      "episode: 039\t steps: 06429\t total steps:337759\t epsilon: 0.39\n",
      "episode: 040\t steps: 02251\t total steps:340009\t epsilon: 0.39\n",
      "episode: 041\t steps: 02683\t total steps:342691\t epsilon: 0.38\n",
      "episode: 042\t steps: 10001\t total steps:352691\t epsilon: 0.37\n",
      "episode: 043\t steps: 03107\t total steps:355797\t epsilon: 0.36\n",
      "episode: 044\t steps: 10001\t total steps:365797\t epsilon: 0.34\n",
      "episode: 045\t steps: 07551\t total steps:373347\t epsilon: 0.33\n",
      "episode: 046\t steps: 03667\t total steps:377013\t epsilon: 0.32\n",
      "episode: 047\t steps: 10001\t total steps:387013\t epsilon: 0.30\n",
      "episode: 048\t steps: 10001\t total steps:397013\t epsilon: 0.29\n",
      "episode: 049\t steps: 05761\t total steps:402773\t epsilon: 0.28\n",
      "episode: 050\t steps: 08637\t total steps:411409\t epsilon: 0.26\n",
      "Evaluation: 1\t average reward: -10000.0\n",
      "episode: 051\t steps: 01135\t total steps:412543\t epsilon: 0.26\n",
      "episode: 052\t steps: 02915\t total steps:415457\t epsilon: 0.25\n",
      "episode: 053\t steps: 03173\t total steps:418629\t epsilon: 0.25\n",
      "episode: 054\t steps: 10001\t total steps:428629\t epsilon: 0.23\n",
      "episode: 055\t steps: 02477\t total steps:431105\t epsilon: 0.22\n",
      "episode: 056\t steps: 00827\t total steps:431931\t epsilon: 0.22\n",
      "episode: 057\t steps: 01157\t total steps:433087\t epsilon: 0.22\n",
      "episode: 058\t steps: 03929\t total steps:437015\t epsilon: 0.21\n",
      "episode: 059\t steps: 04227\t total steps:441241\t epsilon: 0.21\n",
      "episode: 060\t steps: 02301\t total steps:443541\t epsilon: 0.20\n",
      "episode: 061\t steps: 02207\t total steps:445747\t epsilon: 0.20\n",
      "episode: 062\t steps: 02409\t total steps:448155\t epsilon: 0.19\n",
      "episode: 063\t steps: 03011\t total steps:451165\t epsilon: 0.19\n",
      "episode: 064\t steps: 05489\t total steps:456653\t epsilon: 0.18\n",
      "episode: 065\t steps: 08049\t total steps:464701\t epsilon: 0.16\n",
      "episode: 066\t steps: 01671\t total steps:466371\t epsilon: 0.16\n",
      "episode: 067\t steps: 04285\t total steps:470655\t epsilon: 0.15\n",
      "episode: 068\t steps: 10001\t total steps:480655\t epsilon: 0.13\n",
      "episode: 069\t steps: 01267\t total steps:481921\t epsilon: 0.13\n",
      "episode: 070\t steps: 01423\t total steps:483343\t epsilon: 0.13\n",
      "episode: 071\t steps: 10001\t total steps:493343\t epsilon: 0.11\n",
      "episode: 072\t steps: 10001\t total steps:503343\t epsilon: 0.10\n",
      "episode: 073\t steps: 01267\t total steps:504609\t epsilon: 0.10\n",
      "episode: 074\t steps: 02331\t total steps:506939\t epsilon: 0.10\n",
      "episode: 075\t steps: 05189\t total steps:512127\t epsilon: 0.10\n",
      "episode: 076\t steps: 05131\t total steps:517257\t epsilon: 0.10\n",
      "episode: 077\t steps: 01331\t total steps:518587\t epsilon: 0.10\n",
      "episode: 078\t steps: 09227\t total steps:527813\t epsilon: 0.10\n",
      "episode: 079\t steps: 00963\t total steps:528775\t epsilon: 0.10\n",
      "episode: 080\t steps: 04725\t total steps:533499\t epsilon: 0.10\n",
      "episode: 081\t steps: 01975\t total steps:535473\t epsilon: 0.10\n",
      "episode: 082\t steps: 02877\t total steps:538349\t epsilon: 0.10\n",
      "episode: 083\t steps: 02755\t total steps:541103\t epsilon: 0.10\n",
      "episode: 084\t steps: 01139\t total steps:542241\t epsilon: 0.10\n",
      "episode: 085\t steps: 02709\t total steps:544949\t epsilon: 0.10\n",
      "episode: 086\t steps: 03477\t total steps:548425\t epsilon: 0.10\n",
      "episode: 087\t steps: 04515\t total steps:552939\t epsilon: 0.10\n",
      "episode: 088\t steps: 04985\t total steps:557923\t epsilon: 0.10\n",
      "episode: 089\t steps: 04035\t total steps:561957\t epsilon: 0.10\n",
      "episode: 090\t steps: 02205\t total steps:564161\t epsilon: 0.10\n",
      "episode: 091\t steps: 04925\t total steps:569085\t epsilon: 0.10\n",
      "episode: 092\t steps: 01285\t total steps:570369\t epsilon: 0.10\n",
      "episode: 093\t steps: 02843\t total steps:573211\t epsilon: 0.10\n",
      "episode: 094\t steps: 04007\t total steps:577217\t epsilon: 0.10\n",
      "episode: 095\t steps: 04147\t total steps:581363\t epsilon: 0.10\n",
      "episode: 096\t steps: 07647\t total steps:589009\t epsilon: 0.10\n",
      "episode: 097\t steps: 01735\t total steps:590743\t epsilon: 0.10\n",
      "episode: 098\t steps: 09411\t total steps:600153\t epsilon: 0.10\n",
      "episode: 099\t steps: 01645\t total steps:601797\t epsilon: 0.10\n",
      "episode: 100\t steps: 06211\t total steps:608007\t epsilon: 0.10\n",
      "Evaluation: 2\t average reward: -10000.0\n",
      "episode: 101\t steps: 04515\t total steps:612521\t epsilon: 0.10\n",
      "episode: 102\t steps: 04275\t total steps:616795\t epsilon: 0.10\n",
      "episode: 103\t steps: 10001\t total steps:626795\t epsilon: 0.10\n",
      "episode: 104\t steps: 10001\t total steps:636795\t epsilon: 0.10\n",
      "episode: 105\t steps: 08499\t total steps:645293\t epsilon: 0.10\n",
      "episode: 106\t steps: 02143\t total steps:647435\t epsilon: 0.10\n",
      "episode: 107\t steps: 06079\t total steps:653513\t epsilon: 0.10\n",
      "episode: 108\t steps: 07941\t total steps:661453\t epsilon: 0.10\n",
      "episode: 109\t steps: 03031\t total steps:664483\t epsilon: 0.10\n",
      "episode: 110\t steps: 00981\t total steps:665463\t epsilon: 0.10\n",
      "episode: 111\t steps: 04205\t total steps:669667\t epsilon: 0.10\n",
      "episode: 112\t steps: 01775\t total steps:671441\t epsilon: 0.10\n",
      "episode: 113\t steps: 10001\t total steps:681441\t epsilon: 0.10\n",
      "episode: 114\t steps: 08017\t total steps:689457\t epsilon: 0.10\n",
      "episode: 115\t steps: 00713\t total steps:690169\t epsilon: 0.10\n",
      "episode: 116\t steps: 03665\t total steps:693833\t epsilon: 0.10\n",
      "episode: 117\t steps: 05111\t total steps:698943\t epsilon: 0.10\n",
      "episode: 118\t steps: 05905\t total steps:704847\t epsilon: 0.10\n",
      "episode: 119\t steps: 05121\t total steps:709967\t epsilon: 0.10\n",
      "episode: 120\t steps: 05021\t total steps:714987\t epsilon: 0.10\n",
      "episode: 121\t steps: 10001\t total steps:724987\t epsilon: 0.10\n",
      "episode: 122\t steps: 03463\t total steps:728449\t epsilon: 0.10\n",
      "episode: 123\t steps: 03649\t total steps:732097\t epsilon: 0.10\n",
      "episode: 124\t steps: 06071\t total steps:738167\t epsilon: 0.10\n",
      "episode: 125\t steps: 04885\t total steps:743051\t epsilon: 0.10\n",
      "episode: 126\t steps: 05113\t total steps:748163\t epsilon: 0.10\n",
      "episode: 127\t steps: 05627\t total steps:753789\t epsilon: 0.10\n",
      "episode: 128\t steps: 03117\t total steps:756905\t epsilon: 0.10\n",
      "episode: 129\t steps: 03377\t total steps:760281\t epsilon: 0.10\n",
      "episode: 130\t steps: 04323\t total steps:764603\t epsilon: 0.10\n",
      "episode: 131\t steps: 03379\t total steps:767981\t epsilon: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 132\t steps: 04129\t total steps:772109\t epsilon: 0.10\n",
      "episode: 133\t steps: 05227\t total steps:777335\t epsilon: 0.10\n",
      "episode: 134\t steps: 02539\t total steps:779873\t epsilon: 0.10\n",
      "episode: 135\t steps: 03061\t total steps:782933\t epsilon: 0.10\n",
      "episode: 136\t steps: 01169\t total steps:784101\t epsilon: 0.10\n",
      "episode: 137\t steps: 01303\t total steps:785403\t epsilon: 0.10\n",
      "episode: 138\t steps: 04189\t total steps:789591\t epsilon: 0.10\n",
      "episode: 139\t steps: 09433\t total steps:799023\t epsilon: 0.10\n",
      "episode: 140\t steps: 02275\t total steps:801297\t epsilon: 0.10\n",
      "episode: 141\t steps: 09755\t total steps:811051\t epsilon: 0.10\n",
      "episode: 142\t steps: 04213\t total steps:815263\t epsilon: 0.10\n",
      "episode: 143\t steps: 02383\t total steps:817645\t epsilon: 0.10\n",
      "episode: 144\t steps: 05631\t total steps:823275\t epsilon: 0.10\n",
      "episode: 145\t steps: 05093\t total steps:828367\t epsilon: 0.10\n",
      "episode: 146\t steps: 01341\t total steps:829707\t epsilon: 0.10\n",
      "episode: 147\t steps: 00593\t total steps:830299\t epsilon: 0.10\n",
      "episode: 148\t steps: 04135\t total steps:834433\t epsilon: 0.10\n",
      "episode: 149\t steps: 08431\t total steps:842863\t epsilon: 0.10\n",
      "episode: 150\t steps: 03361\t total steps:846223\t epsilon: 0.10\n",
      "Evaluation: 3\t average reward: -10000.0\n",
      "episode: 151\t steps: 02633\t total steps:848855\t epsilon: 0.10\n",
      "episode: 152\t steps: 05095\t total steps:853949\t epsilon: 0.10\n",
      "episode: 153\t steps: 02375\t total steps:856323\t epsilon: 0.10\n",
      "episode: 154\t steps: 04933\t total steps:861255\t epsilon: 0.10\n",
      "episode: 155\t steps: 10001\t total steps:871255\t epsilon: 0.10\n",
      "episode: 156\t steps: 01987\t total steps:873241\t epsilon: 0.10\n",
      "episode: 157\t steps: 00731\t total steps:873971\t epsilon: 0.10\n",
      "episode: 158\t steps: 00883\t total steps:874853\t epsilon: 0.10\n",
      "episode: 159\t steps: 02109\t total steps:876961\t epsilon: 0.10\n",
      "episode: 160\t steps: 01309\t total steps:878269\t epsilon: 0.10\n",
      "episode: 161\t steps: 03891\t total steps:882159\t epsilon: 0.10\n",
      "episode: 162\t steps: 01593\t total steps:883751\t epsilon: 0.10\n",
      "episode: 163\t steps: 04813\t total steps:888563\t epsilon: 0.10\n",
      "episode: 164\t steps: 05091\t total steps:893653\t epsilon: 0.10\n",
      "episode: 165\t steps: 05803\t total steps:899455\t epsilon: 0.10\n",
      "episode: 166\t steps: 04571\t total steps:904025\t epsilon: 0.10\n",
      "episode: 167\t steps: 04383\t total steps:908407\t epsilon: 0.10\n",
      "episode: 168\t steps: 01949\t total steps:910355\t epsilon: 0.10\n",
      "episode: 169\t steps: 01589\t total steps:911943\t epsilon: 0.10\n",
      "episode: 170\t steps: 02157\t total steps:914099\t epsilon: 0.10\n",
      "episode: 171\t steps: 05131\t total steps:919229\t epsilon: 0.10\n",
      "episode: 172\t steps: 01619\t total steps:920847\t epsilon: 0.10\n",
      "episode: 173\t steps: 03405\t total steps:924251\t epsilon: 0.10\n",
      "episode: 174\t steps: 01005\t total steps:925255\t epsilon: 0.10\n",
      "episode: 175\t steps: 02887\t total steps:928141\t epsilon: 0.10\n",
      "episode: 176\t steps: 04165\t total steps:932305\t epsilon: 0.10\n",
      "episode: 177\t steps: 03045\t total steps:935349\t epsilon: 0.10\n",
      "episode: 178\t steps: 05937\t total steps:941285\t epsilon: 0.10\n",
      "episode: 179\t steps: 07177\t total steps:948461\t epsilon: 0.10\n",
      "episode: 180\t steps: 01901\t total steps:950361\t epsilon: 0.10\n",
      "episode: 181\t steps: 02343\t total steps:952703\t epsilon: 0.10\n",
      "episode: 182\t steps: 10001\t total steps:962703\t epsilon: 0.10\n",
      "episode: 183\t steps: 01429\t total steps:964131\t epsilon: 0.10\n",
      "episode: 184\t steps: 02173\t total steps:966303\t epsilon: 0.10\n",
      "episode: 185\t steps: 02143\t total steps:968445\t epsilon: 0.10\n",
      "episode: 186\t steps: 05275\t total steps:973719\t epsilon: 0.10\n",
      "episode: 187\t steps: 05377\t total steps:979095\t epsilon: 0.10\n",
      "episode: 188\t steps: 01319\t total steps:980413\t epsilon: 0.10\n",
      "episode: 189\t steps: 07235\t total steps:987647\t epsilon: 0.10\n",
      "episode: 190\t steps: 03379\t total steps:991025\t epsilon: 0.10\n",
      "episode: 191\t steps: 03401\t total steps:994425\t epsilon: 0.10\n",
      "episode: 192\t steps: 03939\t total steps:998363\t epsilon: 0.10\n",
      "episode: 193\t steps: 00933\t total steps:999295\t epsilon: 0.10\n",
      "episode: 194\t steps: 04665\t total steps:1003959\t epsilon: 0.10\n",
      "episode: 195\t steps: 01601\t total steps:1005559\t epsilon: 0.10\n",
      "episode: 196\t steps: 01927\t total steps:1007485\t epsilon: 0.10\n",
      "episode: 197\t steps: 01517\t total steps:1009001\t epsilon: 0.10\n",
      "episode: 198\t steps: 10001\t total steps:1019001\t epsilon: 0.10\n",
      "episode: 199\t steps: 01257\t total steps:1020257\t epsilon: 0.10\n",
      "episode: 200\t steps: 02599\t total steps:1022855\t epsilon: 0.10\n",
      "Evaluation: 4\t average reward: -7787.2\n",
      "episode: 201\t steps: 04543\t total steps:1027397\t epsilon: 0.10\n",
      "episode: 202\t steps: 04435\t total steps:1031831\t epsilon: 0.10\n",
      "episode: 203\t steps: 02597\t total steps:1034427\t epsilon: 0.10\n",
      "episode: 204\t steps: 02583\t total steps:1037009\t epsilon: 0.10\n",
      "episode: 205\t steps: 04197\t total steps:1041205\t epsilon: 0.10\n",
      "episode: 206\t steps: 02927\t total steps:1044131\t epsilon: 0.10\n",
      "episode: 207\t steps: 02197\t total steps:1046327\t epsilon: 0.10\n",
      "episode: 208\t steps: 05663\t total steps:1051989\t epsilon: 0.10\n",
      "episode: 209\t steps: 04623\t total steps:1056611\t epsilon: 0.10\n",
      "episode: 210\t steps: 07117\t total steps:1063727\t epsilon: 0.10\n",
      "episode: 211\t steps: 03955\t total steps:1067681\t epsilon: 0.10\n",
      "episode: 212\t steps: 01437\t total steps:1069117\t epsilon: 0.10\n",
      "episode: 213\t steps: 10001\t total steps:1079117\t epsilon: 0.10\n",
      "episode: 214\t steps: 05013\t total steps:1084129\t epsilon: 0.10\n",
      "episode: 215\t steps: 02157\t total steps:1086285\t epsilon: 0.10\n",
      "episode: 216\t steps: 05797\t total steps:1092081\t epsilon: 0.10\n",
      "episode: 217\t steps: 02093\t total steps:1094173\t epsilon: 0.10\n",
      "episode: 218\t steps: 02207\t total steps:1096379\t epsilon: 0.10\n",
      "episode: 219\t steps: 05819\t total steps:1102197\t epsilon: 0.10\n",
      "episode: 220\t steps: 05523\t total steps:1107719\t epsilon: 0.10\n",
      "episode: 221\t steps: 01121\t total steps:1108839\t epsilon: 0.10\n",
      "episode: 222\t steps: 08887\t total steps:1117725\t epsilon: 0.10\n",
      "episode: 223\t steps: 00799\t total steps:1118523\t epsilon: 0.10\n",
      "episode: 224\t steps: 03065\t total steps:1121587\t epsilon: 0.10\n",
      "episode: 225\t steps: 07105\t total steps:1128691\t epsilon: 0.10\n",
      "episode: 226\t steps: 02179\t total steps:1130869\t epsilon: 0.10\n",
      "episode: 227\t steps: 03001\t total steps:1133869\t epsilon: 0.10\n",
      "episode: 228\t steps: 01013\t total steps:1134881\t epsilon: 0.10\n",
      "episode: 229\t steps: 01573\t total steps:1136453\t epsilon: 0.10\n",
      "episode: 230\t steps: 01085\t total steps:1137537\t epsilon: 0.10\n",
      "episode: 231\t steps: 03353\t total steps:1140889\t epsilon: 0.10\n",
      "episode: 232\t steps: 02655\t total steps:1143543\t epsilon: 0.10\n",
      "episode: 233\t steps: 02587\t total steps:1146129\t epsilon: 0.10\n",
      "episode: 234\t steps: 04917\t total steps:1151045\t epsilon: 0.10\n",
      "episode: 235\t steps: 03161\t total steps:1154205\t epsilon: 0.10\n",
      "episode: 236\t steps: 04871\t total steps:1159075\t epsilon: 0.10\n",
      "episode: 237\t steps: 00707\t total steps:1159781\t epsilon: 0.10\n",
      "episode: 238\t steps: 02003\t total steps:1161783\t epsilon: 0.10\n",
      "episode: 239\t steps: 01275\t total steps:1163057\t epsilon: 0.10\n",
      "episode: 240\t steps: 09161\t total steps:1172217\t epsilon: 0.10\n",
      "episode: 241\t steps: 07109\t total steps:1179325\t epsilon: 0.10\n",
      "episode: 242\t steps: 07315\t total steps:1186639\t epsilon: 0.10\n",
      "episode: 243\t steps: 04791\t total steps:1191429\t epsilon: 0.10\n",
      "episode: 244\t steps: 01203\t total steps:1192631\t epsilon: 0.10\n",
      "episode: 245\t steps: 01409\t total steps:1194039\t epsilon: 0.10\n",
      "episode: 246\t steps: 06117\t total steps:1200155\t epsilon: 0.10\n",
      "episode: 247\t steps: 01149\t total steps:1201303\t epsilon: 0.10\n",
      "episode: 248\t steps: 01441\t total steps:1202743\t epsilon: 0.10\n",
      "episode: 249\t steps: 01509\t total steps:1204251\t epsilon: 0.10\n",
      "episode: 250\t steps: 04375\t total steps:1208625\t epsilon: 0.10\n",
      "Evaluation: 5\t average reward: -10000.0\n",
      "episode: 251\t steps: 02785\t total steps:1211409\t epsilon: 0.10\n",
      "episode: 252\t steps: 02039\t total steps:1213447\t epsilon: 0.10\n",
      "episode: 253\t steps: 06711\t total steps:1220157\t epsilon: 0.10\n",
      "episode: 254\t steps: 00933\t total steps:1221089\t epsilon: 0.10\n",
      "episode: 255\t steps: 00451\t total steps:1221539\t epsilon: 0.10\n",
      "episode: 256\t steps: 09701\t total steps:1231239\t epsilon: 0.10\n",
      "episode: 257\t steps: 01619\t total steps:1232857\t epsilon: 0.10\n",
      "episode: 258\t steps: 03639\t total steps:1236495\t epsilon: 0.10\n",
      "episode: 259\t steps: 10001\t total steps:1246495\t epsilon: 0.10\n",
      "episode: 260\t steps: 01601\t total steps:1248095\t epsilon: 0.10\n",
      "episode: 261\t steps: 06651\t total steps:1254745\t epsilon: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 262\t steps: 06737\t total steps:1261481\t epsilon: 0.10\n",
      "episode: 263\t steps: 05087\t total steps:1266567\t epsilon: 0.10\n",
      "episode: 264\t steps: 02319\t total steps:1268885\t epsilon: 0.10\n",
      "episode: 265\t steps: 00929\t total steps:1269813\t epsilon: 0.10\n",
      "episode: 266\t steps: 07767\t total steps:1277579\t epsilon: 0.10\n",
      "episode: 267\t steps: 06451\t total steps:1284029\t epsilon: 0.10\n",
      "episode: 268\t steps: 08727\t total steps:1292755\t epsilon: 0.10\n",
      "episode: 269\t steps: 00505\t total steps:1293259\t epsilon: 0.10\n",
      "episode: 270\t steps: 09749\t total steps:1303007\t epsilon: 0.10\n",
      "episode: 271\t steps: 02677\t total steps:1305683\t epsilon: 0.10\n",
      "episode: 272\t steps: 02223\t total steps:1307905\t epsilon: 0.10\n",
      "episode: 273\t steps: 05883\t total steps:1313787\t epsilon: 0.10\n",
      "episode: 274\t steps: 00807\t total steps:1314593\t epsilon: 0.10\n",
      "episode: 275\t steps: 02269\t total steps:1316861\t epsilon: 0.10\n",
      "episode: 276\t steps: 01135\t total steps:1317995\t epsilon: 0.10\n",
      "episode: 277\t steps: 02439\t total steps:1320433\t epsilon: 0.10\n",
      "episode: 278\t steps: 02145\t total steps:1322577\t epsilon: 0.10\n",
      "episode: 279\t steps: 03291\t total steps:1325867\t epsilon: 0.10\n",
      "episode: 280\t steps: 07717\t total steps:1333583\t epsilon: 0.10\n",
      "episode: 281\t steps: 02011\t total steps:1335593\t epsilon: 0.10\n",
      "episode: 282\t steps: 01441\t total steps:1337033\t epsilon: 0.10\n",
      "episode: 283\t steps: 05823\t total steps:1342855\t epsilon: 0.10\n",
      "episode: 284\t steps: 01169\t total steps:1344023\t epsilon: 0.10\n",
      "episode: 285\t steps: 06627\t total steps:1350649\t epsilon: 0.10\n",
      "episode: 286\t steps: 07485\t total steps:1358133\t epsilon: 0.10\n",
      "episode: 287\t steps: 03799\t total steps:1361931\t epsilon: 0.10\n",
      "episode: 288\t steps: 02665\t total steps:1364595\t epsilon: 0.10\n",
      "episode: 289\t steps: 01735\t total steps:1366329\t epsilon: 0.10\n",
      "episode: 290\t steps: 03419\t total steps:1369747\t epsilon: 0.10\n",
      "episode: 291\t steps: 03411\t total steps:1373157\t epsilon: 0.10\n",
      "episode: 292\t steps: 09883\t total steps:1383039\t epsilon: 0.10\n",
      "episode: 293\t steps: 04941\t total steps:1387979\t epsilon: 0.10\n",
      "episode: 294\t steps: 05553\t total steps:1393531\t epsilon: 0.10\n",
      "episode: 295\t steps: 05841\t total steps:1399371\t epsilon: 0.10\n",
      "episode: 296\t steps: 10001\t total steps:1409371\t epsilon: 0.10\n",
      "episode: 297\t steps: 01591\t total steps:1410961\t epsilon: 0.10\n",
      "episode: 298\t steps: 03587\t total steps:1414547\t epsilon: 0.10\n",
      "episode: 299\t steps: 03027\t total steps:1417573\t epsilon: 0.10\n",
      "episode: 300\t steps: 01193\t total steps:1418765\t epsilon: 0.10\n",
      "Evaluation: 6\t average reward: -10000.0\n",
      "episode: 301\t steps: 05997\t total steps:1424761\t epsilon: 0.10\n",
      "episode: 302\t steps: 02071\t total steps:1426831\t epsilon: 0.10\n",
      "episode: 303\t steps: 02287\t total steps:1429117\t epsilon: 0.10\n",
      "episode: 304\t steps: 02157\t total steps:1431273\t epsilon: 0.10\n",
      "episode: 305\t steps: 02935\t total steps:1434207\t epsilon: 0.10\n",
      "episode: 306\t steps: 10001\t total steps:1444207\t epsilon: 0.10\n",
      "episode: 307\t steps: 01795\t total steps:1446001\t epsilon: 0.10\n",
      "episode: 308\t steps: 03017\t total steps:1449017\t epsilon: 0.10\n",
      "episode: 309\t steps: 06409\t total steps:1455425\t epsilon: 0.10\n",
      "episode: 310\t steps: 02923\t total steps:1458347\t epsilon: 0.10\n",
      "episode: 311\t steps: 10001\t total steps:1468347\t epsilon: 0.10\n",
      "episode: 312\t steps: 03215\t total steps:1471561\t epsilon: 0.10\n",
      "episode: 313\t steps: 00657\t total steps:1472217\t epsilon: 0.10\n",
      "episode: 314\t steps: 02561\t total steps:1474777\t epsilon: 0.10\n",
      "episode: 315\t steps: 02699\t total steps:1477475\t epsilon: 0.10\n",
      "episode: 316\t steps: 00639\t total steps:1478113\t epsilon: 0.10\n",
      "episode: 317\t steps: 05341\t total steps:1483453\t epsilon: 0.10\n",
      "episode: 318\t steps: 06017\t total steps:1489469\t epsilon: 0.10\n",
      "episode: 319\t steps: 09273\t total steps:1498741\t epsilon: 0.10\n",
      "episode: 320\t steps: 04359\t total steps:1503099\t epsilon: 0.10\n",
      "episode: 321\t steps: 04489\t total steps:1507587\t epsilon: 0.10\n",
      "episode: 322\t steps: 04875\t total steps:1512461\t epsilon: 0.10\n",
      "episode: 323\t steps: 02743\t total steps:1515203\t epsilon: 0.10\n",
      "episode: 324\t steps: 05173\t total steps:1520375\t epsilon: 0.10\n",
      "episode: 325\t steps: 01331\t total steps:1521705\t epsilon: 0.10\n",
      "episode: 326\t steps: 03429\t total steps:1525133\t epsilon: 0.10\n",
      "episode: 327\t steps: 02115\t total steps:1527247\t epsilon: 0.10\n",
      "episode: 328\t steps: 02273\t total steps:1529519\t epsilon: 0.10\n",
      "episode: 329\t steps: 06641\t total steps:1536159\t epsilon: 0.10\n",
      "episode: 330\t steps: 04255\t total steps:1540413\t epsilon: 0.10\n",
      "episode: 331\t steps: 02151\t total steps:1542563\t epsilon: 0.10\n",
      "episode: 332\t steps: 04433\t total steps:1546995\t epsilon: 0.10\n",
      "episode: 333\t steps: 01595\t total steps:1548589\t epsilon: 0.10\n",
      "episode: 334\t steps: 01823\t total steps:1550411\t epsilon: 0.10\n",
      "episode: 335\t steps: 04047\t total steps:1554457\t epsilon: 0.10\n",
      "episode: 336\t steps: 00593\t total steps:1555049\t epsilon: 0.10\n",
      "episode: 337\t steps: 00465\t total steps:1555513\t epsilon: 0.10\n",
      "episode: 338\t steps: 03979\t total steps:1559491\t epsilon: 0.10\n",
      "episode: 339\t steps: 00891\t total steps:1560381\t epsilon: 0.10\n",
      "episode: 340\t steps: 06013\t total steps:1566393\t epsilon: 0.10\n",
      "episode: 341\t steps: 05263\t total steps:1571655\t epsilon: 0.10\n",
      "episode: 342\t steps: 02157\t total steps:1573811\t epsilon: 0.10\n",
      "episode: 343\t steps: 03953\t total steps:1577763\t epsilon: 0.10\n",
      "episode: 344\t steps: 05937\t total steps:1583699\t epsilon: 0.10\n",
      "episode: 345\t steps: 01245\t total steps:1584943\t epsilon: 0.10\n",
      "episode: 346\t steps: 01111\t total steps:1586053\t epsilon: 0.10\n",
      "episode: 347\t steps: 01083\t total steps:1587135\t epsilon: 0.10\n",
      "episode: 348\t steps: 04837\t total steps:1591971\t epsilon: 0.10\n",
      "episode: 349\t steps: 02283\t total steps:1594253\t epsilon: 0.10\n",
      "episode: 350\t steps: 02841\t total steps:1597093\t epsilon: 0.10\n",
      "Evaluation: 7\t average reward: -10000.0\n",
      "episode: 351\t steps: 03875\t total steps:1600967\t epsilon: 0.10\n",
      "episode: 352\t steps: 03719\t total steps:1604685\t epsilon: 0.10\n",
      "episode: 353\t steps: 03541\t total steps:1608225\t epsilon: 0.10\n",
      "episode: 354\t steps: 01719\t total steps:1609943\t epsilon: 0.10\n",
      "episode: 355\t steps: 10001\t total steps:1619943\t epsilon: 0.10\n",
      "episode: 356\t steps: 03031\t total steps:1622973\t epsilon: 0.10\n",
      "episode: 357\t steps: 04211\t total steps:1627183\t epsilon: 0.10\n",
      "episode: 358\t steps: 03377\t total steps:1630559\t epsilon: 0.10\n",
      "episode: 359\t steps: 02463\t total steps:1633021\t epsilon: 0.10\n",
      "episode: 360\t steps: 02809\t total steps:1635829\t epsilon: 0.10\n",
      "episode: 361\t steps: 10001\t total steps:1645829\t epsilon: 0.10\n",
      "episode: 362\t steps: 01359\t total steps:1647187\t epsilon: 0.10\n",
      "episode: 363\t steps: 06873\t total steps:1654059\t epsilon: 0.10\n",
      "episode: 364\t steps: 03123\t total steps:1657181\t epsilon: 0.10\n",
      "episode: 365\t steps: 02773\t total steps:1659953\t epsilon: 0.10\n",
      "episode: 366\t steps: 10001\t total steps:1669953\t epsilon: 0.10\n",
      "episode: 367\t steps: 07687\t total steps:1677639\t epsilon: 0.10\n",
      "episode: 368\t steps: 02079\t total steps:1679717\t epsilon: 0.10\n",
      "episode: 369\t steps: 01533\t total steps:1681249\t epsilon: 0.10\n",
      "episode: 370\t steps: 10001\t total steps:1691249\t epsilon: 0.10\n",
      "episode: 371\t steps: 08499\t total steps:1699747\t epsilon: 0.10\n",
      "episode: 372\t steps: 01129\t total steps:1700875\t epsilon: 0.10\n",
      "episode: 373\t steps: 04211\t total steps:1705085\t epsilon: 0.10\n",
      "episode: 374\t steps: 05133\t total steps:1710217\t epsilon: 0.10\n",
      "episode: 375\t steps: 06495\t total steps:1716711\t epsilon: 0.10\n",
      "episode: 376\t steps: 01943\t total steps:1718653\t epsilon: 0.10\n",
      "episode: 377\t steps: 02333\t total steps:1720985\t epsilon: 0.10\n",
      "episode: 378\t steps: 03633\t total steps:1724617\t epsilon: 0.10\n",
      "episode: 379\t steps: 10001\t total steps:1734617\t epsilon: 0.10\n",
      "episode: 380\t steps: 03043\t total steps:1737659\t epsilon: 0.10\n",
      "episode: 381\t steps: 10001\t total steps:1747659\t epsilon: 0.10\n",
      "episode: 382\t steps: 02869\t total steps:1750527\t epsilon: 0.10\n",
      "episode: 383\t steps: 05381\t total steps:1755907\t epsilon: 0.10\n",
      "episode: 384\t steps: 02597\t total steps:1758503\t epsilon: 0.10\n",
      "episode: 385\t steps: 01499\t total steps:1760001\t epsilon: 0.10\n",
      "episode: 386\t steps: 01803\t total steps:1761803\t epsilon: 0.10\n",
      "episode: 387\t steps: 10001\t total steps:1771803\t epsilon: 0.10\n",
      "episode: 388\t steps: 09063\t total steps:1780865\t epsilon: 0.10\n",
      "episode: 389\t steps: 07169\t total steps:1788033\t epsilon: 0.10\n",
      "episode: 390\t steps: 01131\t total steps:1789163\t epsilon: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 391\t steps: 05231\t total steps:1794393\t epsilon: 0.10\n",
      "episode: 392\t steps: 10001\t total steps:1804393\t epsilon: 0.10\n",
      "episode: 393\t steps: 01057\t total steps:1805449\t epsilon: 0.10\n",
      "episode: 394\t steps: 04157\t total steps:1809605\t epsilon: 0.10\n",
      "episode: 395\t steps: 00947\t total steps:1810551\t epsilon: 0.10\n",
      "episode: 396\t steps: 05375\t total steps:1815925\t epsilon: 0.10\n",
      "episode: 397\t steps: 01425\t total steps:1817349\t epsilon: 0.10\n",
      "episode: 398\t steps: 01651\t total steps:1818999\t epsilon: 0.10\n",
      "episode: 399\t steps: 07941\t total steps:1826939\t epsilon: 0.10\n",
      "episode: 400\t steps: 07037\t total steps:1833975\t epsilon: 0.10\n",
      "Evaluation: 8\t average reward: -10000.0\n",
      "episode: 401\t steps: 01301\t total steps:1835275\t epsilon: 0.10\n",
      "episode: 402\t steps: 02621\t total steps:1837895\t epsilon: 0.10\n",
      "episode: 403\t steps: 06421\t total steps:1844315\t epsilon: 0.10\n",
      "episode: 404\t steps: 01473\t total steps:1845787\t epsilon: 0.10\n",
      "episode: 405\t steps: 10001\t total steps:1855787\t epsilon: 0.10\n",
      "episode: 406\t steps: 03491\t total steps:1859277\t epsilon: 0.10\n",
      "episode: 407\t steps: 10001\t total steps:1869277\t epsilon: 0.10\n",
      "episode: 408\t steps: 02985\t total steps:1872261\t epsilon: 0.10\n",
      "episode: 409\t steps: 05063\t total steps:1877323\t epsilon: 0.10\n",
      "episode: 410\t steps: 02005\t total steps:1879327\t epsilon: 0.10\n",
      "episode: 411\t steps: 05351\t total steps:1884677\t epsilon: 0.10\n",
      "episode: 412\t steps: 03829\t total steps:1888505\t epsilon: 0.10\n",
      "episode: 413\t steps: 04671\t total steps:1893175\t epsilon: 0.10\n",
      "episode: 414\t steps: 03825\t total steps:1896999\t epsilon: 0.10\n",
      "episode: 415\t steps: 10001\t total steps:1906999\t epsilon: 0.10\n",
      "episode: 416\t steps: 02345\t total steps:1909343\t epsilon: 0.10\n",
      "episode: 417\t steps: 03585\t total steps:1912927\t epsilon: 0.10\n",
      "episode: 418\t steps: 01317\t total steps:1914243\t epsilon: 0.10\n",
      "episode: 419\t steps: 01875\t total steps:1916117\t epsilon: 0.10\n",
      "episode: 420\t steps: 02183\t total steps:1918299\t epsilon: 0.10\n",
      "episode: 421\t steps: 01493\t total steps:1919791\t epsilon: 0.10\n",
      "episode: 422\t steps: 02475\t total steps:1922265\t epsilon: 0.10\n",
      "episode: 423\t steps: 01233\t total steps:1923497\t epsilon: 0.10\n",
      "episode: 424\t steps: 03227\t total steps:1926723\t epsilon: 0.10\n",
      "episode: 425\t steps: 02617\t total steps:1929339\t epsilon: 0.10\n",
      "episode: 426\t steps: 02553\t total steps:1931891\t epsilon: 0.10\n",
      "episode: 427\t steps: 02003\t total steps:1933893\t epsilon: 0.10\n",
      "episode: 428\t steps: 05165\t total steps:1939057\t epsilon: 0.10\n",
      "episode: 429\t steps: 02253\t total steps:1941309\t epsilon: 0.10\n",
      "episode: 430\t steps: 10001\t total steps:1951309\t epsilon: 0.10\n",
      "episode: 431\t steps: 07689\t total steps:1958997\t epsilon: 0.10\n",
      "episode: 432\t steps: 01133\t total steps:1960129\t epsilon: 0.10\n",
      "episode: 433\t steps: 06497\t total steps:1966625\t epsilon: 0.10\n",
      "episode: 434\t steps: 10001\t total steps:1976625\t epsilon: 0.10\n",
      "episode: 435\t steps: 10001\t total steps:1986625\t epsilon: 0.10\n",
      "episode: 436\t steps: 01891\t total steps:1988515\t epsilon: 0.10\n",
      "episode: 437\t steps: 07349\t total steps:1995863\t epsilon: 0.10\n",
      "episode: 438\t steps: 01695\t total steps:1997557\t epsilon: 0.10\n",
      "episode: 439\t steps: 10001\t total steps:2007557\t epsilon: 0.10\n",
      "episode: 440\t steps: 10001\t total steps:2017557\t epsilon: 0.10\n",
      "episode: 441\t steps: 03571\t total steps:2021127\t epsilon: 0.10\n",
      "episode: 442\t steps: 02675\t total steps:2023801\t epsilon: 0.10\n",
      "episode: 443\t steps: 02577\t total steps:2026377\t epsilon: 0.10\n",
      "episode: 444\t steps: 02299\t total steps:2028675\t epsilon: 0.10\n",
      "episode: 445\t steps: 01561\t total steps:2030235\t epsilon: 0.10\n",
      "episode: 446\t steps: 10001\t total steps:2040235\t epsilon: 0.10\n",
      "episode: 447\t steps: 02519\t total steps:2042753\t epsilon: 0.10\n",
      "episode: 448\t steps: 00961\t total steps:2043713\t epsilon: 0.10\n",
      "episode: 449\t steps: 02787\t total steps:2046499\t epsilon: 0.10\n",
      "episode: 450\t steps: 01725\t total steps:2048223\t epsilon: 0.10\n",
      "Evaluation: 9\t average reward: -10000.0\n",
      "episode: 451\t steps: 03391\t total steps:2051613\t epsilon: 0.10\n",
      "episode: 452\t steps: 04679\t total steps:2056291\t epsilon: 0.10\n",
      "episode: 453\t steps: 00787\t total steps:2057077\t epsilon: 0.10\n",
      "episode: 454\t steps: 04017\t total steps:2061093\t epsilon: 0.10\n",
      "episode: 455\t steps: 02271\t total steps:2063363\t epsilon: 0.10\n",
      "episode: 456\t steps: 03251\t total steps:2066613\t epsilon: 0.10\n",
      "episode: 457\t steps: 03757\t total steps:2070369\t epsilon: 0.10\n",
      "episode: 458\t steps: 04413\t total steps:2074781\t epsilon: 0.10\n",
      "episode: 459\t steps: 03713\t total steps:2078493\t epsilon: 0.10\n",
      "episode: 460\t steps: 07165\t total steps:2085657\t epsilon: 0.10\n",
      "episode: 461\t steps: 03349\t total steps:2089005\t epsilon: 0.10\n",
      "episode: 462\t steps: 02457\t total steps:2091461\t epsilon: 0.10\n",
      "episode: 463\t steps: 06449\t total steps:2097909\t epsilon: 0.10\n",
      "episode: 464\t steps: 00559\t total steps:2098467\t epsilon: 0.10\n",
      "episode: 465\t steps: 06499\t total steps:2104965\t epsilon: 0.10\n",
      "episode: 466\t steps: 02547\t total steps:2107511\t epsilon: 0.10\n",
      "episode: 467\t steps: 04821\t total steps:2112331\t epsilon: 0.10\n",
      "episode: 468\t steps: 01495\t total steps:2113825\t epsilon: 0.10\n",
      "episode: 469\t steps: 01261\t total steps:2115085\t epsilon: 0.10\n",
      "episode: 470\t steps: 02963\t total steps:2118047\t epsilon: 0.10\n",
      "episode: 471\t steps: 07065\t total steps:2125111\t epsilon: 0.10\n",
      "episode: 472\t steps: 08093\t total steps:2133203\t epsilon: 0.10\n",
      "episode: 473\t steps: 02025\t total steps:2135227\t epsilon: 0.10\n",
      "episode: 474\t steps: 01343\t total steps:2136569\t epsilon: 0.10\n",
      "episode: 475\t steps: 09207\t total steps:2145775\t epsilon: 0.10\n",
      "episode: 476\t steps: 02087\t total steps:2147861\t epsilon: 0.10\n",
      "episode: 477\t steps: 02365\t total steps:2150225\t epsilon: 0.10\n",
      "episode: 478\t steps: 07871\t total steps:2158095\t epsilon: 0.10\n",
      "episode: 479\t steps: 02005\t total steps:2160099\t epsilon: 0.10\n",
      "episode: 480\t steps: 01689\t total steps:2161787\t epsilon: 0.10\n",
      "episode: 481\t steps: 02949\t total steps:2164735\t epsilon: 0.10\n",
      "episode: 482\t steps: 03683\t total steps:2168417\t epsilon: 0.10\n",
      "episode: 483\t steps: 02335\t total steps:2170751\t epsilon: 0.10\n",
      "episode: 484\t steps: 10001\t total steps:2180751\t epsilon: 0.10\n",
      "episode: 485\t steps: 00981\t total steps:2181731\t epsilon: 0.10\n",
      "episode: 486\t steps: 02513\t total steps:2184243\t epsilon: 0.10\n",
      "episode: 487\t steps: 05471\t total steps:2189713\t epsilon: 0.10\n",
      "episode: 488\t steps: 05475\t total steps:2195187\t epsilon: 0.10\n",
      "episode: 489\t steps: 03067\t total steps:2198253\t epsilon: 0.10\n",
      "episode: 490\t steps: 04521\t total steps:2202773\t epsilon: 0.10\n",
      "episode: 491\t steps: 03023\t total steps:2205795\t epsilon: 0.10\n",
      "episode: 492\t steps: 01035\t total steps:2206829\t epsilon: 0.10\n",
      "episode: 493\t steps: 03093\t total steps:2209921\t epsilon: 0.10\n",
      "episode: 494\t steps: 03439\t total steps:2213359\t epsilon: 0.10\n",
      "episode: 495\t steps: 01647\t total steps:2215005\t epsilon: 0.10\n",
      "episode: 496\t steps: 06671\t total steps:2221675\t epsilon: 0.10\n",
      "episode: 497\t steps: 03603\t total steps:2225277\t epsilon: 0.10\n",
      "episode: 498\t steps: 10001\t total steps:2235277\t epsilon: 0.10\n",
      "episode: 499\t steps: 00741\t total steps:2236017\t epsilon: 0.10\n",
      "episode: 500\t steps: 07411\t total steps:2243427\t epsilon: 0.10\n",
      "Evaluation: 10\t average reward: -7351.9\n",
      "episode: 501\t steps: 03209\t total steps:2246635\t epsilon: 0.10\n",
      "episode: 502\t steps: 05059\t total steps:2251693\t epsilon: 0.10\n",
      "episode: 503\t steps: 03173\t total steps:2254865\t epsilon: 0.10\n",
      "episode: 504\t steps: 02329\t total steps:2257193\t epsilon: 0.10\n",
      "episode: 505\t steps: 00929\t total steps:2258121\t epsilon: 0.10\n",
      "episode: 506\t steps: 01167\t total steps:2259287\t epsilon: 0.10\n",
      "episode: 507\t steps: 07019\t total steps:2266305\t epsilon: 0.10\n",
      "episode: 508\t steps: 02605\t total steps:2268909\t epsilon: 0.10\n",
      "episode: 509\t steps: 03031\t total steps:2271939\t epsilon: 0.10\n",
      "episode: 510\t steps: 02725\t total steps:2274663\t epsilon: 0.10\n",
      "episode: 511\t steps: 10001\t total steps:2284663\t epsilon: 0.10\n",
      "episode: 512\t steps: 01461\t total steps:2286123\t epsilon: 0.10\n",
      "episode: 513\t steps: 01699\t total steps:2287821\t epsilon: 0.10\n",
      "episode: 514\t steps: 00971\t total steps:2288791\t epsilon: 0.10\n",
      "episode: 515\t steps: 04081\t total steps:2292871\t epsilon: 0.10\n",
      "episode: 516\t steps: 01723\t total steps:2294593\t epsilon: 0.10\n",
      "episode: 517\t steps: 02971\t total steps:2297563\t epsilon: 0.10\n",
      "episode: 518\t steps: 01549\t total steps:2299111\t epsilon: 0.10\n",
      "episode: 519\t steps: 03695\t total steps:2302805\t epsilon: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 520\t steps: 02055\t total steps:2304859\t epsilon: 0.10\n",
      "episode: 521\t steps: 01017\t total steps:2305875\t epsilon: 0.10\n",
      "episode: 522\t steps: 00941\t total steps:2306815\t epsilon: 0.10\n",
      "episode: 523\t steps: 01543\t total steps:2308357\t epsilon: 0.10\n",
      "episode: 524\t steps: 01087\t total steps:2309443\t epsilon: 0.10\n",
      "episode: 525\t steps: 10001\t total steps:2319443\t epsilon: 0.10\n",
      "episode: 526\t steps: 06613\t total steps:2326055\t epsilon: 0.10\n",
      "episode: 527\t steps: 00775\t total steps:2326829\t epsilon: 0.10\n",
      "episode: 528\t steps: 10001\t total steps:2336829\t epsilon: 0.10\n",
      "episode: 529\t steps: 05075\t total steps:2341903\t epsilon: 0.10\n",
      "episode: 530\t steps: 03473\t total steps:2345375\t epsilon: 0.10\n",
      "episode: 531\t steps: 04885\t total steps:2350259\t epsilon: 0.10\n",
      "episode: 532\t steps: 03561\t total steps:2353819\t epsilon: 0.10\n",
      "episode: 533\t steps: 02585\t total steps:2356403\t epsilon: 0.10\n",
      "episode: 534\t steps: 07939\t total steps:2364341\t epsilon: 0.10\n",
      "episode: 535\t steps: 03221\t total steps:2367561\t epsilon: 0.10\n",
      "episode: 536\t steps: 03933\t total steps:2371493\t epsilon: 0.10\n",
      "episode: 537\t steps: 01051\t total steps:2372543\t epsilon: 0.10\n",
      "episode: 538\t steps: 07985\t total steps:2380527\t epsilon: 0.10\n",
      "episode: 539\t steps: 01685\t total steps:2382211\t epsilon: 0.10\n",
      "episode: 540\t steps: 05109\t total steps:2387319\t epsilon: 0.10\n",
      "episode: 541\t steps: 01769\t total steps:2389087\t epsilon: 0.10\n",
      "episode: 542\t steps: 04911\t total steps:2393997\t epsilon: 0.10\n",
      "episode: 543\t steps: 01577\t total steps:2395573\t epsilon: 0.10\n",
      "episode: 544\t steps: 08275\t total steps:2403847\t epsilon: 0.10\n",
      "episode: 545\t steps: 09257\t total steps:2413103\t epsilon: 0.10\n",
      "episode: 546\t steps: 03693\t total steps:2416795\t epsilon: 0.10\n",
      "episode: 547\t steps: 02371\t total steps:2419165\t epsilon: 0.10\n",
      "episode: 548\t steps: 07659\t total steps:2426823\t epsilon: 0.10\n",
      "episode: 549\t steps: 04155\t total steps:2430977\t epsilon: 0.10\n",
      "episode: 550\t steps: 10001\t total steps:2440977\t epsilon: 0.10\n",
      "Evaluation: 11\t average reward: -7144.2\n",
      "episode: 551\t steps: 04657\t total steps:2445633\t epsilon: 0.10\n",
      "episode: 552\t steps: 03121\t total steps:2448753\t epsilon: 0.10\n",
      "episode: 553\t steps: 01045\t total steps:2449797\t epsilon: 0.10\n",
      "episode: 554\t steps: 10001\t total steps:2459797\t epsilon: 0.10\n",
      "episode: 555\t steps: 03523\t total steps:2463319\t epsilon: 0.10\n",
      "episode: 556\t steps: 03947\t total steps:2467265\t epsilon: 0.10\n",
      "episode: 557\t steps: 04283\t total steps:2471547\t epsilon: 0.10\n",
      "episode: 558\t steps: 03255\t total steps:2474801\t epsilon: 0.10\n",
      "episode: 559\t steps: 02089\t total steps:2476889\t epsilon: 0.10\n",
      "episode: 560\t steps: 06015\t total steps:2482903\t epsilon: 0.10\n",
      "episode: 561\t steps: 10001\t total steps:2492903\t epsilon: 0.10\n",
      "episode: 562\t steps: 10001\t total steps:2502903\t epsilon: 0.10\n",
      "episode: 563\t steps: 02359\t total steps:2505261\t epsilon: 0.10\n",
      "episode: 564\t steps: 03119\t total steps:2508379\t epsilon: 0.10\n",
      "episode: 565\t steps: 04871\t total steps:2513249\t epsilon: 0.10\n",
      "episode: 566\t steps: 01433\t total steps:2514681\t epsilon: 0.10\n",
      "episode: 567\t steps: 00789\t total steps:2515469\t epsilon: 0.10\n",
      "episode: 568\t steps: 02573\t total steps:2518041\t epsilon: 0.10\n",
      "episode: 569\t steps: 05543\t total steps:2523583\t epsilon: 0.10\n",
      "episode: 570\t steps: 02267\t total steps:2525849\t epsilon: 0.10\n",
      "episode: 571\t steps: 02639\t total steps:2528487\t epsilon: 0.10\n",
      "episode: 572\t steps: 04165\t total steps:2532651\t epsilon: 0.10\n",
      "episode: 573\t steps: 02809\t total steps:2535459\t epsilon: 0.10\n",
      "episode: 574\t steps: 00979\t total steps:2536437\t epsilon: 0.10\n",
      "episode: 575\t steps: 07563\t total steps:2543999\t epsilon: 0.10\n",
      "episode: 576\t steps: 02337\t total steps:2546335\t epsilon: 0.10\n",
      "episode: 577\t steps: 02839\t total steps:2549173\t epsilon: 0.10\n",
      "episode: 578\t steps: 02381\t total steps:2551553\t epsilon: 0.10\n",
      "episode: 579\t steps: 10001\t total steps:2561553\t epsilon: 0.10\n",
      "episode: 580\t steps: 09041\t total steps:2570593\t epsilon: 0.10\n",
      "episode: 581\t steps: 10001\t total steps:2580593\t epsilon: 0.10\n",
      "episode: 582\t steps: 05701\t total steps:2586293\t epsilon: 0.10\n",
      "episode: 583\t steps: 03079\t total steps:2589371\t epsilon: 0.10\n",
      "episode: 584\t steps: 03697\t total steps:2593067\t epsilon: 0.10\n",
      "episode: 585\t steps: 00993\t total steps:2594059\t epsilon: 0.10\n",
      "episode: 586\t steps: 01321\t total steps:2595379\t epsilon: 0.10\n",
      "episode: 587\t steps: 05259\t total steps:2600637\t epsilon: 0.10\n",
      "episode: 588\t steps: 04139\t total steps:2604775\t epsilon: 0.10\n",
      "episode: 589\t steps: 02111\t total steps:2606885\t epsilon: 0.10\n",
      "episode: 590\t steps: 06249\t total steps:2613133\t epsilon: 0.10\n",
      "episode: 591\t steps: 04669\t total steps:2617801\t epsilon: 0.10\n",
      "episode: 592\t steps: 02163\t total steps:2619963\t epsilon: 0.10\n",
      "episode: 593\t steps: 04825\t total steps:2624787\t epsilon: 0.10\n",
      "episode: 594\t steps: 01767\t total steps:2626553\t epsilon: 0.10\n",
      "episode: 595\t steps: 05409\t total steps:2631961\t epsilon: 0.10\n",
      "episode: 596\t steps: 01405\t total steps:2633365\t epsilon: 0.10\n",
      "episode: 597\t steps: 01955\t total steps:2635319\t epsilon: 0.10\n",
      "episode: 598\t steps: 03211\t total steps:2638529\t epsilon: 0.10\n",
      "episode: 599\t steps: 10001\t total steps:2648529\t epsilon: 0.10\n",
      "episode: 600\t steps: 01453\t total steps:2649981\t epsilon: 0.10\n",
      "Evaluation: 12\t average reward: -10000.0\n",
      "episode: 601\t steps: 09769\t total steps:2659749\t epsilon: 0.10\n",
      "episode: 602\t steps: 03703\t total steps:2663451\t epsilon: 0.10\n",
      "episode: 603\t steps: 02819\t total steps:2666269\t epsilon: 0.10\n",
      "episode: 604\t steps: 02173\t total steps:2668441\t epsilon: 0.10\n",
      "episode: 605\t steps: 02411\t total steps:2670851\t epsilon: 0.10\n",
      "episode: 606\t steps: 08523\t total steps:2679373\t epsilon: 0.10\n",
      "episode: 607\t steps: 02249\t total steps:2681621\t epsilon: 0.10\n",
      "episode: 608\t steps: 01549\t total steps:2683169\t epsilon: 0.10\n",
      "episode: 609\t steps: 10001\t total steps:2693169\t epsilon: 0.10\n",
      "episode: 610\t steps: 01961\t total steps:2695129\t epsilon: 0.10\n",
      "episode: 611\t steps: 02235\t total steps:2697363\t epsilon: 0.10\n",
      "episode: 612\t steps: 08143\t total steps:2705505\t epsilon: 0.10\n",
      "episode: 613\t steps: 07289\t total steps:2712793\t epsilon: 0.10\n",
      "episode: 614\t steps: 06335\t total steps:2719127\t epsilon: 0.10\n",
      "episode: 615\t steps: 02945\t total steps:2722071\t epsilon: 0.10\n",
      "episode: 616\t steps: 01185\t total steps:2723255\t epsilon: 0.10\n",
      "episode: 617\t steps: 00617\t total steps:2723871\t epsilon: 0.10\n",
      "episode: 618\t steps: 06403\t total steps:2730273\t epsilon: 0.10\n",
      "episode: 619\t steps: 01619\t total steps:2731891\t epsilon: 0.10\n",
      "episode: 620\t steps: 04739\t total steps:2736629\t epsilon: 0.10\n",
      "episode: 621\t steps: 04083\t total steps:2740711\t epsilon: 0.10\n",
      "episode: 622\t steps: 01891\t total steps:2742601\t epsilon: 0.10\n",
      "episode: 623\t steps: 04331\t total steps:2746931\t epsilon: 0.10\n",
      "episode: 624\t steps: 01311\t total steps:2748241\t epsilon: 0.10\n",
      "episode: 625\t steps: 04043\t total steps:2752283\t epsilon: 0.10\n",
      "episode: 626\t steps: 02251\t total steps:2754533\t epsilon: 0.10\n",
      "episode: 627\t steps: 05109\t total steps:2759641\t epsilon: 0.10\n",
      "episode: 628\t steps: 01507\t total steps:2761147\t epsilon: 0.10\n",
      "episode: 629\t steps: 04923\t total steps:2766069\t epsilon: 0.10\n",
      "episode: 630\t steps: 09473\t total steps:2775541\t epsilon: 0.10\n",
      "episode: 631\t steps: 04681\t total steps:2780221\t epsilon: 0.10\n",
      "episode: 632\t steps: 02737\t total steps:2782957\t epsilon: 0.10\n",
      "episode: 633\t steps: 03325\t total steps:2786281\t epsilon: 0.10\n",
      "episode: 634\t steps: 01469\t total steps:2787749\t epsilon: 0.10\n",
      "episode: 635\t steps: 10001\t total steps:2797749\t epsilon: 0.10\n",
      "episode: 636\t steps: 01891\t total steps:2799639\t epsilon: 0.10\n",
      "episode: 637\t steps: 08615\t total steps:2808253\t epsilon: 0.10\n",
      "episode: 638\t steps: 03235\t total steps:2811487\t epsilon: 0.10\n",
      "episode: 639\t steps: 02851\t total steps:2814337\t epsilon: 0.10\n",
      "episode: 640\t steps: 06941\t total steps:2821277\t epsilon: 0.10\n",
      "episode: 641\t steps: 06619\t total steps:2827895\t epsilon: 0.10\n",
      "episode: 642\t steps: 06961\t total steps:2834855\t epsilon: 0.10\n",
      "episode: 643\t steps: 00805\t total steps:2835659\t epsilon: 0.10\n",
      "episode: 644\t steps: 05467\t total steps:2841125\t epsilon: 0.10\n",
      "episode: 645\t steps: 03661\t total steps:2844785\t epsilon: 0.10\n",
      "episode: 646\t steps: 06231\t total steps:2851015\t epsilon: 0.10\n",
      "episode: 647\t steps: 03055\t total steps:2854069\t epsilon: 0.10\n",
      "episode: 648\t steps: 03441\t total steps:2857509\t epsilon: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 649\t steps: 01837\t total steps:2859345\t epsilon: 0.10\n",
      "episode: 650\t steps: 06765\t total steps:2866109\t epsilon: 0.10\n",
      "Evaluation: 13\t average reward: -10000.0\n",
      "episode: 651\t steps: 03191\t total steps:2869299\t epsilon: 0.10\n",
      "episode: 652\t steps: 05671\t total steps:2874969\t epsilon: 0.10\n",
      "episode: 653\t steps: 04553\t total steps:2879521\t epsilon: 0.10\n",
      "episode: 654\t steps: 01323\t total steps:2880843\t epsilon: 0.10\n",
      "episode: 655\t steps: 03907\t total steps:2884749\t epsilon: 0.10\n",
      "episode: 656\t steps: 01989\t total steps:2886737\t epsilon: 0.10\n",
      "episode: 657\t steps: 03041\t total steps:2889777\t epsilon: 0.10\n",
      "episode: 658\t steps: 08603\t total steps:2898379\t epsilon: 0.10\n",
      "episode: 659\t steps: 04211\t total steps:2902589\t epsilon: 0.10\n",
      "episode: 660\t steps: 06269\t total steps:2908857\t epsilon: 0.10\n",
      "episode: 661\t steps: 07759\t total steps:2916615\t epsilon: 0.10\n",
      "episode: 662\t steps: 03233\t total steps:2919847\t epsilon: 0.10\n",
      "episode: 663\t steps: 10001\t total steps:2929847\t epsilon: 0.10\n",
      "episode: 664\t steps: 02701\t total steps:2932547\t epsilon: 0.10\n",
      "episode: 665\t steps: 01507\t total steps:2934053\t epsilon: 0.10\n",
      "episode: 666\t steps: 04815\t total steps:2938867\t epsilon: 0.10\n",
      "episode: 667\t steps: 02765\t total steps:2941631\t epsilon: 0.10\n",
      "episode: 668\t steps: 01609\t total steps:2943239\t epsilon: 0.10\n",
      "episode: 669\t steps: 08095\t total steps:2951333\t epsilon: 0.10\n",
      "episode: 670\t steps: 03639\t total steps:2954971\t epsilon: 0.10\n",
      "episode: 671\t steps: 02285\t total steps:2957255\t epsilon: 0.10\n",
      "episode: 672\t steps: 05853\t total steps:2963107\t epsilon: 0.10\n",
      "episode: 673\t steps: 04877\t total steps:2967983\t epsilon: 0.10\n",
      "episode: 674\t steps: 02859\t total steps:2970841\t epsilon: 0.10\n",
      "episode: 675\t steps: 01973\t total steps:2972813\t epsilon: 0.10\n",
      "episode: 676\t steps: 02065\t total steps:2974877\t epsilon: 0.10\n",
      "episode: 677\t steps: 10001\t total steps:2984877\t epsilon: 0.10\n",
      "episode: 678\t steps: 03581\t total steps:2988457\t epsilon: 0.10\n",
      "episode: 679\t steps: 03077\t total steps:2991533\t epsilon: 0.10\n",
      "episode: 680\t steps: 10001\t total steps:3001533\t epsilon: 0.10\n",
      "episode: 681\t steps: 00973\t total steps:3002505\t epsilon: 0.10\n",
      "episode: 682\t steps: 01987\t total steps:3004491\t epsilon: 0.10\n",
      "episode: 683\t steps: 01929\t total steps:3006419\t epsilon: 0.10\n",
      "episode: 684\t steps: 00939\t total steps:3007357\t epsilon: 0.10\n",
      "episode: 685\t steps: 01759\t total steps:3009115\t epsilon: 0.10\n",
      "episode: 686\t steps: 02129\t total steps:3011243\t epsilon: 0.10\n",
      "episode: 687\t steps: 07107\t total steps:3018349\t epsilon: 0.10\n",
      "episode: 688\t steps: 02065\t total steps:3020413\t epsilon: 0.10\n",
      "episode: 689\t steps: 08827\t total steps:3029239\t epsilon: 0.10\n",
      "episode: 690\t steps: 04873\t total steps:3034111\t epsilon: 0.10\n",
      "episode: 691\t steps: 02815\t total steps:3036925\t epsilon: 0.10\n",
      "episode: 692\t steps: 02519\t total steps:3039443\t epsilon: 0.10\n",
      "episode: 693\t steps: 04149\t total steps:3043591\t epsilon: 0.10\n",
      "episode: 694\t steps: 07259\t total steps:3050849\t epsilon: 0.10\n",
      "episode: 695\t steps: 04267\t total steps:3055115\t epsilon: 0.10\n",
      "episode: 696\t steps: 00691\t total steps:3055805\t epsilon: 0.10\n",
      "episode: 697\t steps: 01159\t total steps:3056963\t epsilon: 0.10\n",
      "episode: 698\t steps: 06503\t total steps:3063465\t epsilon: 0.10\n",
      "episode: 699\t steps: 09605\t total steps:3073069\t epsilon: 0.10\n",
      "episode: 700\t steps: 01257\t total steps:3074325\t epsilon: 0.10\n",
      "Evaluation: 14\t average reward: -10000.0\n",
      "episode: 701\t steps: 10001\t total steps:3084325\t epsilon: 0.10\n",
      "episode: 702\t steps: 01785\t total steps:3086109\t epsilon: 0.10\n",
      "episode: 703\t steps: 02029\t total steps:3088137\t epsilon: 0.10\n",
      "episode: 704\t steps: 06225\t total steps:3094361\t epsilon: 0.10\n",
      "episode: 705\t steps: 01849\t total steps:3096209\t epsilon: 0.10\n",
      "episode: 706\t steps: 10001\t total steps:3106209\t epsilon: 0.10\n",
      "episode: 707\t steps: 08169\t total steps:3114377\t epsilon: 0.10\n",
      "episode: 708\t steps: 07027\t total steps:3121403\t epsilon: 0.10\n",
      "episode: 709\t steps: 00911\t total steps:3122313\t epsilon: 0.10\n",
      "episode: 710\t steps: 00501\t total steps:3122813\t epsilon: 0.10\n",
      "episode: 711\t steps: 01051\t total steps:3123863\t epsilon: 0.10\n",
      "episode: 712\t steps: 03395\t total steps:3127257\t epsilon: 0.10\n",
      "episode: 713\t steps: 02901\t total steps:3130157\t epsilon: 0.10\n",
      "episode: 714\t steps: 01123\t total steps:3131279\t epsilon: 0.10\n",
      "episode: 715\t steps: 03817\t total steps:3135095\t epsilon: 0.10\n",
      "episode: 716\t steps: 02753\t total steps:3137847\t epsilon: 0.10\n",
      "episode: 717\t steps: 03869\t total steps:3141715\t epsilon: 0.10\n",
      "episode: 718\t steps: 03599\t total steps:3145313\t epsilon: 0.10\n",
      "episode: 719\t steps: 02925\t total steps:3148237\t epsilon: 0.10\n",
      "episode: 720\t steps: 06603\t total steps:3154839\t epsilon: 0.10\n",
      "episode: 721\t steps: 03665\t total steps:3158503\t epsilon: 0.10\n",
      "episode: 722\t steps: 05411\t total steps:3163913\t epsilon: 0.10\n",
      "episode: 723\t steps: 02329\t total steps:3166241\t epsilon: 0.10\n",
      "episode: 724\t steps: 01405\t total steps:3167645\t epsilon: 0.10\n",
      "episode: 725\t steps: 01385\t total steps:3169029\t epsilon: 0.10\n",
      "episode: 726\t steps: 00625\t total steps:3169653\t epsilon: 0.10\n",
      "episode: 727\t steps: 02195\t total steps:3171847\t epsilon: 0.10\n",
      "episode: 728\t steps: 00667\t total steps:3172513\t epsilon: 0.10\n",
      "episode: 729\t steps: 10001\t total steps:3182513\t epsilon: 0.10\n",
      "episode: 730\t steps: 01607\t total steps:3184119\t epsilon: 0.10\n",
      "episode: 731\t steps: 08491\t total steps:3192609\t epsilon: 0.10\n",
      "episode: 732\t steps: 04133\t total steps:3196741\t epsilon: 0.10\n",
      "episode: 733\t steps: 04771\t total steps:3201511\t epsilon: 0.10\n",
      "episode: 734\t steps: 04091\t total steps:3205601\t epsilon: 0.10\n",
      "episode: 735\t steps: 10001\t total steps:3215601\t epsilon: 0.10\n",
      "episode: 736\t steps: 06639\t total steps:3222239\t epsilon: 0.10\n",
      "episode: 737\t steps: 03397\t total steps:3225635\t epsilon: 0.10\n",
      "episode: 738\t steps: 03993\t total steps:3229627\t epsilon: 0.10\n",
      "episode: 739\t steps: 02047\t total steps:3231673\t epsilon: 0.10\n",
      "episode: 740\t steps: 02921\t total steps:3234593\t epsilon: 0.10\n",
      "episode: 741\t steps: 01871\t total steps:3236463\t epsilon: 0.10\n",
      "episode: 742\t steps: 08673\t total steps:3245135\t epsilon: 0.10\n",
      "episode: 743\t steps: 10001\t total steps:3255135\t epsilon: 0.10\n",
      "episode: 744\t steps: 02055\t total steps:3257189\t epsilon: 0.10\n",
      "episode: 745\t steps: 02051\t total steps:3259239\t epsilon: 0.10\n",
      "episode: 746\t steps: 06213\t total steps:3265451\t epsilon: 0.10\n",
      "episode: 747\t steps: 04111\t total steps:3269561\t epsilon: 0.10\n",
      "episode: 748\t steps: 01909\t total steps:3271469\t epsilon: 0.10\n",
      "episode: 749\t steps: 06225\t total steps:3277693\t epsilon: 0.10\n",
      "episode: 750\t steps: 02877\t total steps:3280569\t epsilon: 0.10\n",
      "Evaluation: 15\t average reward: -10000.0\n",
      "episode: 751\t steps: 04543\t total steps:3285111\t epsilon: 0.10\n",
      "episode: 752\t steps: 01651\t total steps:3286761\t epsilon: 0.10\n",
      "episode: 753\t steps: 02507\t total steps:3289267\t epsilon: 0.10\n",
      "episode: 754\t steps: 02325\t total steps:3291591\t epsilon: 0.10\n",
      "episode: 755\t steps: 09743\t total steps:3301333\t epsilon: 0.10\n",
      "episode: 756\t steps: 07615\t total steps:3308947\t epsilon: 0.10\n",
      "episode: 757\t steps: 05055\t total steps:3314001\t epsilon: 0.10\n",
      "episode: 758\t steps: 02401\t total steps:3316401\t epsilon: 0.10\n",
      "episode: 759\t steps: 02483\t total steps:3318883\t epsilon: 0.10\n",
      "episode: 760\t steps: 01141\t total steps:3320023\t epsilon: 0.10\n",
      "episode: 761\t steps: 09481\t total steps:3329503\t epsilon: 0.10\n",
      "episode: 762\t steps: 01597\t total steps:3331099\t epsilon: 0.10\n",
      "episode: 763\t steps: 03273\t total steps:3334371\t epsilon: 0.10\n",
      "episode: 764\t steps: 07999\t total steps:3342369\t epsilon: 0.10\n",
      "episode: 765\t steps: 03705\t total steps:3346073\t epsilon: 0.10\n",
      "episode: 766\t steps: 00963\t total steps:3347035\t epsilon: 0.10\n",
      "episode: 767\t steps: 09921\t total steps:3356955\t epsilon: 0.10\n",
      "episode: 768\t steps: 04185\t total steps:3361139\t epsilon: 0.10\n",
      "episode: 769\t steps: 02465\t total steps:3363603\t epsilon: 0.10\n",
      "episode: 770\t steps: 01549\t total steps:3365151\t epsilon: 0.10\n",
      "episode: 771\t steps: 01219\t total steps:3366369\t epsilon: 0.10\n",
      "episode: 772\t steps: 01513\t total steps:3367881\t epsilon: 0.10\n",
      "episode: 773\t steps: 02277\t total steps:3370157\t epsilon: 0.10\n",
      "episode: 774\t steps: 10001\t total steps:3380157\t epsilon: 0.10\n",
      "episode: 775\t steps: 08111\t total steps:3388267\t epsilon: 0.10\n",
      "episode: 776\t steps: 03243\t total steps:3391509\t epsilon: 0.10\n",
      "episode: 777\t steps: 01611\t total steps:3393119\t epsilon: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 778\t steps: 05977\t total steps:3399095\t epsilon: 0.10\n",
      "episode: 779\t steps: 01183\t total steps:3400277\t epsilon: 0.10\n",
      "episode: 780\t steps: 01285\t total steps:3401561\t epsilon: 0.10\n",
      "episode: 781\t steps: 02913\t total steps:3404473\t epsilon: 0.10\n",
      "episode: 782\t steps: 07117\t total steps:3411589\t epsilon: 0.10\n",
      "episode: 783\t steps: 05283\t total steps:3416871\t epsilon: 0.10\n",
      "episode: 784\t steps: 10001\t total steps:3426871\t epsilon: 0.10\n",
      "episode: 785\t steps: 00661\t total steps:3427531\t epsilon: 0.10\n",
      "episode: 786\t steps: 01805\t total steps:3429335\t epsilon: 0.10\n",
      "episode: 787\t steps: 02277\t total steps:3431611\t epsilon: 0.10\n",
      "episode: 788\t steps: 00609\t total steps:3432219\t epsilon: 0.10\n",
      "episode: 789\t steps: 01495\t total steps:3433713\t epsilon: 0.10\n",
      "episode: 790\t steps: 06141\t total steps:3439853\t epsilon: 0.10\n",
      "episode: 791\t steps: 04451\t total steps:3444303\t epsilon: 0.10\n",
      "episode: 792\t steps: 04239\t total steps:3448541\t epsilon: 0.10\n",
      "episode: 793\t steps: 01683\t total steps:3450223\t epsilon: 0.10\n",
      "episode: 794\t steps: 10001\t total steps:3460223\t epsilon: 0.10\n",
      "episode: 795\t steps: 03729\t total steps:3463951\t epsilon: 0.10\n",
      "episode: 796\t steps: 05633\t total steps:3469583\t epsilon: 0.10\n",
      "episode: 797\t steps: 05523\t total steps:3475105\t epsilon: 0.10\n",
      "episode: 798\t steps: 02289\t total steps:3477393\t epsilon: 0.10\n",
      "episode: 799\t steps: 02839\t total steps:3480231\t epsilon: 0.10\n",
      "episode: 800\t steps: 07133\t total steps:3487363\t epsilon: 0.10\n",
      "Evaluation: 16\t average reward: -10000.0\n",
      "episode: 801\t steps: 07947\t total steps:3495309\t epsilon: 0.10\n",
      "episode: 802\t steps: 04055\t total steps:3499363\t epsilon: 0.10\n",
      "episode: 803\t steps: 00823\t total steps:3500185\t epsilon: 0.10\n",
      "episode: 804\t steps: 01917\t total steps:3502101\t epsilon: 0.10\n",
      "episode: 805\t steps: 08277\t total steps:3510377\t epsilon: 0.10\n",
      "episode: 806\t steps: 03667\t total steps:3514043\t epsilon: 0.10\n",
      "episode: 807\t steps: 04321\t total steps:3518363\t epsilon: 0.10\n",
      "episode: 808\t steps: 07757\t total steps:3526119\t epsilon: 0.10\n",
      "episode: 809\t steps: 10001\t total steps:3536119\t epsilon: 0.10\n",
      "episode: 810\t steps: 06993\t total steps:3543111\t epsilon: 0.10\n",
      "episode: 811\t steps: 03189\t total steps:3546299\t epsilon: 0.10\n",
      "episode: 812\t steps: 05287\t total steps:3551585\t epsilon: 0.10\n",
      "episode: 813\t steps: 04223\t total steps:3555807\t epsilon: 0.10\n",
      "episode: 814\t steps: 02993\t total steps:3558799\t epsilon: 0.10\n",
      "episode: 815\t steps: 05091\t total steps:3563889\t epsilon: 0.10\n",
      "episode: 816\t steps: 08067\t total steps:3571955\t epsilon: 0.10\n",
      "episode: 817\t steps: 10001\t total steps:3581955\t epsilon: 0.10\n",
      "episode: 818\t steps: 04607\t total steps:3586561\t epsilon: 0.10\n",
      "episode: 819\t steps: 00707\t total steps:3587267\t epsilon: 0.10\n",
      "episode: 820\t steps: 02455\t total steps:3589721\t epsilon: 0.10\n",
      "episode: 821\t steps: 08771\t total steps:3598491\t epsilon: 0.10\n",
      "episode: 822\t steps: 02983\t total steps:3601473\t epsilon: 0.10\n",
      "episode: 823\t steps: 02141\t total steps:3603613\t epsilon: 0.10\n",
      "episode: 824\t steps: 08721\t total steps:3612333\t epsilon: 0.10\n",
      "episode: 825\t steps: 02853\t total steps:3615185\t epsilon: 0.10\n",
      "episode: 826\t steps: 01737\t total steps:3616921\t epsilon: 0.10\n",
      "episode: 827\t steps: 01751\t total steps:3618671\t epsilon: 0.10\n",
      "episode: 828\t steps: 01621\t total steps:3620291\t epsilon: 0.10\n",
      "episode: 829\t steps: 03043\t total steps:3623333\t epsilon: 0.10\n",
      "episode: 830\t steps: 03251\t total steps:3626583\t epsilon: 0.10\n",
      "episode: 831\t steps: 01973\t total steps:3628555\t epsilon: 0.10\n",
      "episode: 832\t steps: 01897\t total steps:3630451\t epsilon: 0.10\n",
      "episode: 833\t steps: 01641\t total steps:3632091\t epsilon: 0.10\n",
      "episode: 834\t steps: 03793\t total steps:3635883\t epsilon: 0.10\n",
      "episode: 835\t steps: 02911\t total steps:3638793\t epsilon: 0.10\n",
      "episode: 836\t steps: 03325\t total steps:3642117\t epsilon: 0.10\n",
      "episode: 837\t steps: 05737\t total steps:3647853\t epsilon: 0.10\n",
      "episode: 838\t steps: 02181\t total steps:3650033\t epsilon: 0.10\n",
      "episode: 839\t steps: 01687\t total steps:3651719\t epsilon: 0.10\n",
      "episode: 840\t steps: 04255\t total steps:3655973\t epsilon: 0.10\n",
      "episode: 841\t steps: 02533\t total steps:3658505\t epsilon: 0.10\n",
      "episode: 842\t steps: 03861\t total steps:3662365\t epsilon: 0.10\n",
      "episode: 843\t steps: 03097\t total steps:3665461\t epsilon: 0.10\n",
      "episode: 844\t steps: 05149\t total steps:3670609\t epsilon: 0.10\n",
      "episode: 845\t steps: 08369\t total steps:3678977\t epsilon: 0.10\n",
      "episode: 846\t steps: 10001\t total steps:3688977\t epsilon: 0.10\n",
      "episode: 847\t steps: 01397\t total steps:3690373\t epsilon: 0.10\n",
      "episode: 848\t steps: 00509\t total steps:3690881\t epsilon: 0.10\n",
      "episode: 849\t steps: 05711\t total steps:3696591\t epsilon: 0.10\n",
      "episode: 850\t steps: 03757\t total steps:3700347\t epsilon: 0.10\n",
      "Evaluation: 17\t average reward: -7665.3\n",
      "episode: 851\t steps: 03751\t total steps:3704097\t epsilon: 0.10\n",
      "episode: 852\t steps: 03053\t total steps:3707149\t epsilon: 0.10\n",
      "episode: 853\t steps: 02277\t total steps:3709425\t epsilon: 0.10\n",
      "episode: 854\t steps: 10001\t total steps:3719425\t epsilon: 0.10\n",
      "episode: 855\t steps: 02343\t total steps:3721767\t epsilon: 0.10\n",
      "episode: 856\t steps: 04347\t total steps:3726113\t epsilon: 0.10\n",
      "episode: 857\t steps: 07063\t total steps:3733175\t epsilon: 0.10\n",
      "episode: 858\t steps: 04657\t total steps:3737831\t epsilon: 0.10\n",
      "episode: 859\t steps: 02823\t total steps:3740653\t epsilon: 0.10\n",
      "episode: 860\t steps: 02317\t total steps:3742969\t epsilon: 0.10\n",
      "episode: 861\t steps: 04429\t total steps:3747397\t epsilon: 0.10\n",
      "episode: 862\t steps: 02923\t total steps:3750319\t epsilon: 0.10\n",
      "episode: 863\t steps: 05051\t total steps:3755369\t epsilon: 0.10\n",
      "episode: 864\t steps: 01541\t total steps:3756909\t epsilon: 0.10\n",
      "episode: 865\t steps: 09431\t total steps:3766339\t epsilon: 0.10\n",
      "episode: 866\t steps: 03985\t total steps:3770323\t epsilon: 0.10\n",
      "episode: 867\t steps: 01841\t total steps:3772163\t epsilon: 0.10\n",
      "episode: 868\t steps: 02779\t total steps:3774941\t epsilon: 0.10\n",
      "episode: 869\t steps: 02737\t total steps:3777677\t epsilon: 0.10\n",
      "episode: 870\t steps: 03623\t total steps:3781299\t epsilon: 0.10\n",
      "episode: 871\t steps: 07877\t total steps:3789175\t epsilon: 0.10\n",
      "episode: 872\t steps: 10001\t total steps:3799175\t epsilon: 0.10\n",
      "episode: 873\t steps: 03233\t total steps:3802407\t epsilon: 0.10\n",
      "episode: 874\t steps: 03079\t total steps:3805485\t epsilon: 0.10\n",
      "episode: 875\t steps: 05721\t total steps:3811205\t epsilon: 0.10\n",
      "episode: 876\t steps: 04563\t total steps:3815767\t epsilon: 0.10\n",
      "episode: 877\t steps: 00925\t total steps:3816691\t epsilon: 0.10\n",
      "episode: 878\t steps: 01803\t total steps:3818493\t epsilon: 0.10\n",
      "episode: 879\t steps: 09035\t total steps:3827527\t epsilon: 0.10\n",
      "episode: 880\t steps: 00609\t total steps:3828135\t epsilon: 0.10\n",
      "episode: 881\t steps: 02263\t total steps:3830397\t epsilon: 0.10\n",
      "episode: 882\t steps: 05169\t total steps:3835565\t epsilon: 0.10\n",
      "episode: 883\t steps: 01171\t total steps:3836735\t epsilon: 0.10\n",
      "episode: 884\t steps: 06091\t total steps:3842825\t epsilon: 0.10\n",
      "episode: 885\t steps: 02293\t total steps:3845117\t epsilon: 0.10\n",
      "episode: 886\t steps: 01715\t total steps:3846831\t epsilon: 0.10\n",
      "episode: 887\t steps: 02563\t total steps:3849393\t epsilon: 0.10\n",
      "episode: 888\t steps: 02575\t total steps:3851967\t epsilon: 0.10\n",
      "episode: 889\t steps: 02971\t total steps:3854937\t epsilon: 0.10\n",
      "episode: 890\t steps: 07465\t total steps:3862401\t epsilon: 0.10\n",
      "episode: 891\t steps: 10001\t total steps:3872401\t epsilon: 0.10\n",
      "episode: 892\t steps: 01229\t total steps:3873629\t epsilon: 0.10\n",
      "episode: 893\t steps: 08759\t total steps:3882387\t epsilon: 0.10\n",
      "episode: 894\t steps: 02345\t total steps:3884731\t epsilon: 0.10\n",
      "episode: 895\t steps: 03137\t total steps:3887867\t epsilon: 0.10\n",
      "episode: 896\t steps: 07997\t total steps:3895863\t epsilon: 0.10\n",
      "episode: 897\t steps: 07577\t total steps:3903439\t epsilon: 0.10\n",
      "episode: 898\t steps: 02693\t total steps:3906131\t epsilon: 0.10\n",
      "episode: 899\t steps: 10001\t total steps:3916131\t epsilon: 0.10\n",
      "episode: 900\t steps: 08615\t total steps:3924745\t epsilon: 0.10\n",
      "Evaluation: 18\t average reward: -10000.0\n",
      "episode: 901\t steps: 02635\t total steps:3927379\t epsilon: 0.10\n",
      "episode: 902\t steps: 00775\t total steps:3928153\t epsilon: 0.10\n",
      "episode: 903\t steps: 01449\t total steps:3929601\t epsilon: 0.10\n",
      "episode: 904\t steps: 10001\t total steps:3939601\t epsilon: 0.10\n",
      "episode: 905\t steps: 02151\t total steps:3941751\t epsilon: 0.10\n",
      "episode: 906\t steps: 02143\t total steps:3943893\t epsilon: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 907\t steps: 03009\t total steps:3946901\t epsilon: 0.10\n",
      "episode: 908\t steps: 04097\t total steps:3950997\t epsilon: 0.10\n",
      "episode: 909\t steps: 08183\t total steps:3959179\t epsilon: 0.10\n",
      "episode: 910\t steps: 01061\t total steps:3960239\t epsilon: 0.10\n",
      "episode: 911\t steps: 03881\t total steps:3964119\t epsilon: 0.10\n",
      "episode: 912\t steps: 01271\t total steps:3965389\t epsilon: 0.10\n",
      "episode: 913\t steps: 04149\t total steps:3969537\t epsilon: 0.10\n",
      "episode: 914\t steps: 02107\t total steps:3971643\t epsilon: 0.10\n",
      "episode: 915\t steps: 02855\t total steps:3974497\t epsilon: 0.10\n",
      "episode: 916\t steps: 04211\t total steps:3978707\t epsilon: 0.10\n",
      "episode: 917\t steps: 06105\t total steps:3984811\t epsilon: 0.10\n",
      "episode: 918\t steps: 03307\t total steps:3988117\t epsilon: 0.10\n",
      "episode: 919\t steps: 00753\t total steps:3988869\t epsilon: 0.10\n",
      "episode: 920\t steps: 07621\t total steps:3996489\t epsilon: 0.10\n",
      "episode: 921\t steps: 03585\t total steps:4000073\t epsilon: 0.10\n",
      "episode: 922\t steps: 04001\t total steps:4004073\t epsilon: 0.10\n",
      "episode: 923\t steps: 02145\t total steps:4006217\t epsilon: 0.10\n",
      "episode: 924\t steps: 04565\t total steps:4010781\t epsilon: 0.10\n",
      "episode: 925\t steps: 07411\t total steps:4018191\t epsilon: 0.10\n",
      "episode: 926\t steps: 05209\t total steps:4023399\t epsilon: 0.10\n",
      "episode: 927\t steps: 01967\t total steps:4025365\t epsilon: 0.10\n",
      "episode: 928\t steps: 05387\t total steps:4030751\t epsilon: 0.10\n",
      "episode: 929\t steps: 05897\t total steps:4036647\t epsilon: 0.10\n",
      "episode: 930\t steps: 02847\t total steps:4039493\t epsilon: 0.10\n",
      "episode: 931\t steps: 03569\t total steps:4043061\t epsilon: 0.10\n",
      "episode: 932\t steps: 03703\t total steps:4046763\t epsilon: 0.10\n",
      "episode: 933\t steps: 05569\t total steps:4052331\t epsilon: 0.10\n",
      "episode: 934\t steps: 01557\t total steps:4053887\t epsilon: 0.10\n",
      "episode: 935\t steps: 01645\t total steps:4055531\t epsilon: 0.10\n",
      "episode: 936\t steps: 01557\t total steps:4057087\t epsilon: 0.10\n",
      "episode: 937\t steps: 05661\t total steps:4062747\t epsilon: 0.10\n",
      "episode: 938\t steps: 04317\t total steps:4067063\t epsilon: 0.10\n",
      "episode: 939\t steps: 10001\t total steps:4077063\t epsilon: 0.10\n",
      "episode: 940\t steps: 01633\t total steps:4078695\t epsilon: 0.10\n",
      "episode: 941\t steps: 05317\t total steps:4084011\t epsilon: 0.10\n",
      "episode: 942\t steps: 01119\t total steps:4085129\t epsilon: 0.10\n",
      "episode: 943\t steps: 05037\t total steps:4090165\t epsilon: 0.10\n",
      "episode: 944\t steps: 05903\t total steps:4096067\t epsilon: 0.10\n",
      "episode: 945\t steps: 02453\t total steps:4098519\t epsilon: 0.10\n",
      "episode: 946\t steps: 03009\t total steps:4101527\t epsilon: 0.10\n",
      "episode: 947\t steps: 05831\t total steps:4107357\t epsilon: 0.10\n",
      "episode: 948\t steps: 05077\t total steps:4112433\t epsilon: 0.10\n",
      "episode: 949\t steps: 04555\t total steps:4116987\t epsilon: 0.10\n",
      "episode: 950\t steps: 03761\t total steps:4120747\t epsilon: 0.10\n",
      "Evaluation: 19\t average reward: -6362.9\n",
      "episode: 951\t steps: 10001\t total steps:4130747\t epsilon: 0.10\n",
      "episode: 952\t steps: 04389\t total steps:4135135\t epsilon: 0.10\n",
      "episode: 953\t steps: 02487\t total steps:4137621\t epsilon: 0.10\n",
      "episode: 954\t steps: 02671\t total steps:4140291\t epsilon: 0.10\n",
      "episode: 955\t steps: 03501\t total steps:4143791\t epsilon: 0.10\n",
      "episode: 956\t steps: 01913\t total steps:4145703\t epsilon: 0.10\n",
      "episode: 957\t steps: 03865\t total steps:4149567\t epsilon: 0.10\n",
      "episode: 958\t steps: 06807\t total steps:4156373\t epsilon: 0.10\n",
      "episode: 959\t steps: 03869\t total steps:4160241\t epsilon: 0.10\n",
      "episode: 960\t steps: 01275\t total steps:4161515\t epsilon: 0.10\n",
      "episode: 961\t steps: 02317\t total steps:4163831\t epsilon: 0.10\n",
      "episode: 962\t steps: 03341\t total steps:4167171\t epsilon: 0.10\n",
      "episode: 963\t steps: 00933\t total steps:4168103\t epsilon: 0.10\n",
      "episode: 964\t steps: 01223\t total steps:4169325\t epsilon: 0.10\n",
      "episode: 965\t steps: 02155\t total steps:4171479\t epsilon: 0.10\n",
      "episode: 966\t steps: 04095\t total steps:4175573\t epsilon: 0.10\n",
      "episode: 967\t steps: 02691\t total steps:4178263\t epsilon: 0.10\n",
      "episode: 968\t steps: 02901\t total steps:4181163\t epsilon: 0.10\n",
      "episode: 969\t steps: 02447\t total steps:4183609\t epsilon: 0.10\n",
      "episode: 970\t steps: 02833\t total steps:4186441\t epsilon: 0.10\n",
      "episode: 971\t steps: 06369\t total steps:4192809\t epsilon: 0.10\n",
      "episode: 972\t steps: 05813\t total steps:4198621\t epsilon: 0.10\n",
      "episode: 973\t steps: 02229\t total steps:4200849\t epsilon: 0.10\n",
      "episode: 974\t steps: 01487\t total steps:4202335\t epsilon: 0.10\n",
      "episode: 975\t steps: 01303\t total steps:4203637\t epsilon: 0.10\n",
      "episode: 976\t steps: 07185\t total steps:4210821\t epsilon: 0.10\n",
      "episode: 977\t steps: 09557\t total steps:4220377\t epsilon: 0.10\n",
      "episode: 978\t steps: 04471\t total steps:4224847\t epsilon: 0.10\n",
      "episode: 979\t steps: 06011\t total steps:4230857\t epsilon: 0.10\n",
      "episode: 980\t steps: 10001\t total steps:4240857\t epsilon: 0.10\n",
      "episode: 981\t steps: 02755\t total steps:4243611\t epsilon: 0.10\n",
      "episode: 982\t steps: 02155\t total steps:4245765\t epsilon: 0.10\n",
      "episode: 983\t steps: 01513\t total steps:4247277\t epsilon: 0.10\n",
      "episode: 984\t steps: 10001\t total steps:4257277\t epsilon: 0.10\n",
      "episode: 985\t steps: 02505\t total steps:4259781\t epsilon: 0.10\n",
      "episode: 986\t steps: 01269\t total steps:4261049\t epsilon: 0.10\n",
      "episode: 987\t steps: 03277\t total steps:4264325\t epsilon: 0.10\n",
      "episode: 988\t steps: 02587\t total steps:4266911\t epsilon: 0.10\n",
      "episode: 989\t steps: 01051\t total steps:4267961\t epsilon: 0.10\n",
      "episode: 990\t steps: 02097\t total steps:4270057\t epsilon: 0.10\n",
      "episode: 991\t steps: 04759\t total steps:4274815\t epsilon: 0.10\n",
      "episode: 992\t steps: 01063\t total steps:4275877\t epsilon: 0.10\n",
      "episode: 993\t steps: 06083\t total steps:4281959\t epsilon: 0.10\n",
      "episode: 994\t steps: 02263\t total steps:4284221\t epsilon: 0.10\n",
      "episode: 995\t steps: 07189\t total steps:4291409\t epsilon: 0.10\n",
      "episode: 996\t steps: 01575\t total steps:4292983\t epsilon: 0.10\n",
      "episode: 997\t steps: 01371\t total steps:4294353\t epsilon: 0.10\n",
      "episode: 998\t steps: 10001\t total steps:4304353\t epsilon: 0.10\n",
      "episode: 999\t steps: 01919\t total steps:4306271\t epsilon: 0.10\n",
      "Evaluation: 19\t average reward: -10000.0\n",
      "episode: 1000\t steps: 05885\t total steps:4312155\t epsilon: 0.10\n"
     ]
    }
   ],
   "source": [
    "#  Hyperparameters\n",
    "n_training_episodes = 1000\n",
    "gamma = 0.99\n",
    "learning_rate = 0.00025  # 0.1\n",
    "max_training_steps = 10000\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon_max = 1\n",
    "epsilon_min = 0.1\n",
    "# epsilon_frame = 100000\n",
    "\n",
    "# replay memory parameters\n",
    "replay_size = 100000\n",
    "batch_size = 32\n",
    "\n",
    "# fixed target network\n",
    "fixed_target = True\n",
    "copy_target = 10000\n",
    "\n",
    "debug = True\n",
    "\n",
    "double = True\n",
    "\n",
    "epsilon_frame = 500000\n",
    "\n",
    "transform = scale_and_resize()\n",
    "\n",
    "env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "\n",
    "car = TrainMountainCar(n_training_episodes=n_training_episodes, gamma=gamma, learning_rate=learning_rate,\n",
    "                       epsilon_max=epsilon_max, epsilon_min=epsilon_min,double=double,\n",
    "                       max_steps=max_training_steps, batch_size=batch_size, fixed_target=fixed_target,\n",
    "                       copy_target=copy_target, debug=debug, env=env, epsilon_frame=epsilon_frame)\n",
    "\n",
    "total_rewards, total_steps_list, best_policy, evaluations = car.train()\n",
    "\n",
    "# save best policy as well as steps and q measures\n",
    "torch.save(best_policy, 'data/DDQN_MLP.pth')\n",
    "np.savetxt(f'data/steps_DDQN_MLP_txt', total_steps_list)\n",
    "# np.savetxt(f'data/q_values_DDQN_MLP.txt', q_measures)\n",
    "np.savetxt(f'data/eval_DDQN_MLP.txt', evaluations)\n",
    "\n",
    "# Plot steps per episode\n",
    "plt.plot(np.arange(len(total_steps_list)) + 1, total_steps_list, zorder=0, label='training')\n",
    "x = np.arange(50, n_training_episodes+1, 50)\n",
    "plt.scatter(x, [-e for e in evaluations], color='r', marker='x', zorder=1, label='evaluations')\n",
    "N = 10\n",
    "steps_mean = running_mean(total_steps_list, N)\n",
    "plt.plot(np.arange(len(steps_mean)) + 1, steps_mean, zorder=0, label='running average')\n",
    "plt.legend()\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps')\n",
    "plt.title('Steps per Episode - DDQN_MLP')\n",
    "plt.savefig('plots/steps_DDQN_MLP.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot q measures per episode\n",
    "# plt.plot(np.arange(len(q_measures)) + 1, q_measures)\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Average Q')\n",
    "# plt.title('Average Q measure over sampled states')\n",
    "# plt.savefig('plots/q_measures_DRQN.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893640a",
   "metadata": {},
   "source": [
    "## Prioritized_DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c39dea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 001\t steps: 10001\t total steps:010001\t epsilon: 0.98\n",
      "episode: 002\t steps: 10001\t total steps:020001\t epsilon: 0.96\n",
      "episode: 003\t steps: 10001\t total steps:030001\t epsilon: 0.94\n",
      "episode: 004\t steps: 10001\t total steps:040001\t epsilon: 0.92\n",
      "episode: 005\t steps: 10001\t total steps:050001\t epsilon: 0.90\n",
      "episode: 006\t steps: 10001\t total steps:060001\t epsilon: 0.88\n",
      "episode: 007\t steps: 10001\t total steps:070001\t epsilon: 0.86\n",
      "episode: 008\t steps: 10001\t total steps:080001\t epsilon: 0.84\n",
      "episode: 009\t steps: 10001\t total steps:090001\t epsilon: 0.82\n",
      "episode: 010\t steps: 10001\t total steps:100001\t epsilon: 0.80\n",
      "episode: 011\t steps: 10001\t total steps:110001\t epsilon: 0.78\n",
      "episode: 012\t steps: 10001\t total steps:120001\t epsilon: 0.76\n",
      "episode: 013\t steps: 09111\t total steps:129111\t epsilon: 0.74\n",
      "episode: 014\t steps: 05877\t total steps:134987\t epsilon: 0.73\n",
      "episode: 015\t steps: 10001\t total steps:144987\t epsilon: 0.71\n",
      "episode: 016\t steps: 02917\t total steps:147903\t epsilon: 0.71\n",
      "episode: 017\t steps: 03507\t total steps:151409\t epsilon: 0.70\n",
      "episode: 018\t steps: 10001\t total steps:161409\t epsilon: 0.68\n",
      "episode: 019\t steps: 08923\t total steps:170331\t epsilon: 0.66\n",
      "episode: 020\t steps: 10001\t total steps:180331\t epsilon: 0.64\n",
      "episode: 021\t steps: 04319\t total steps:184649\t epsilon: 0.63\n",
      "episode: 022\t steps: 06683\t total steps:191331\t epsilon: 0.62\n",
      "episode: 023\t steps: 10001\t total steps:201331\t epsilon: 0.60\n",
      "episode: 024\t steps: 01493\t total steps:202823\t epsilon: 0.60\n",
      "episode: 025\t steps: 02683\t total steps:205505\t epsilon: 0.59\n",
      "episode: 026\t steps: 02961\t total steps:208465\t epsilon: 0.59\n",
      "episode: 027\t steps: 03991\t total steps:212455\t epsilon: 0.58\n",
      "episode: 028\t steps: 06049\t total steps:218503\t epsilon: 0.57\n",
      "episode: 029\t steps: 02613\t total steps:221115\t epsilon: 0.56\n",
      "episode: 030\t steps: 02835\t total steps:223949\t epsilon: 0.56\n",
      "episode: 031\t steps: 05305\t total steps:229253\t epsilon: 0.55\n",
      "episode: 032\t steps: 02407\t total steps:231659\t epsilon: 0.54\n",
      "episode: 033\t steps: 04487\t total steps:236145\t epsilon: 0.53\n",
      "episode: 034\t steps: 04993\t total steps:241137\t epsilon: 0.52\n",
      "episode: 035\t steps: 05229\t total steps:246365\t epsilon: 0.51\n",
      "episode: 036\t steps: 02141\t total steps:248505\t epsilon: 0.51\n",
      "episode: 037\t steps: 01221\t total steps:249725\t epsilon: 0.51\n",
      "episode: 038\t steps: 02949\t total steps:252673\t epsilon: 0.50\n",
      "episode: 039\t steps: 05051\t total steps:257723\t epsilon: 0.49\n",
      "episode: 040\t steps: 03595\t total steps:261317\t epsilon: 0.48\n",
      "episode: 041\t steps: 02505\t total steps:263821\t epsilon: 0.48\n",
      "episode: 042\t steps: 02985\t total steps:266805\t epsilon: 0.47\n",
      "episode: 043\t steps: 01325\t total steps:268129\t epsilon: 0.47\n",
      "episode: 044\t steps: 01227\t total steps:269355\t epsilon: 0.47\n",
      "episode: 045\t steps: 00817\t total steps:270171\t epsilon: 0.47\n",
      "episode: 046\t steps: 00689\t total steps:270859\t epsilon: 0.46\n",
      "episode: 047\t steps: 02051\t total steps:272909\t epsilon: 0.46\n",
      "episode: 048\t steps: 08073\t total steps:280981\t epsilon: 0.44\n",
      "episode: 049\t steps: 08725\t total steps:289705\t epsilon: 0.43\n",
      "episode: 050\t steps: 01557\t total steps:291261\t epsilon: 0.42\n",
      "Evaluation: 1\t average reward: -10000.0\n",
      "episode: 051\t steps: 02931\t total steps:294191\t epsilon: 0.42\n",
      "episode: 052\t steps: 00673\t total steps:294863\t epsilon: 0.42\n",
      "episode: 053\t steps: 01345\t total steps:296207\t epsilon: 0.41\n",
      "episode: 054\t steps: 05643\t total steps:301849\t epsilon: 0.40\n",
      "episode: 055\t steps: 01481\t total steps:303329\t epsilon: 0.40\n",
      "episode: 056\t steps: 10001\t total steps:313329\t epsilon: 0.38\n",
      "episode: 057\t steps: 01975\t total steps:315303\t epsilon: 0.38\n",
      "episode: 058\t steps: 03495\t total steps:318797\t epsilon: 0.37\n",
      "episode: 059\t steps: 01593\t total steps:320389\t epsilon: 0.37\n",
      "episode: 060\t steps: 00985\t total steps:321373\t epsilon: 0.36\n",
      "episode: 061\t steps: 04503\t total steps:325875\t epsilon: 0.35\n",
      "episode: 062\t steps: 00641\t total steps:326515\t epsilon: 0.35\n",
      "episode: 063\t steps: 07667\t total steps:334181\t epsilon: 0.34\n",
      "episode: 064\t steps: 00835\t total steps:335015\t epsilon: 0.34\n",
      "episode: 065\t steps: 01947\t total steps:336961\t epsilon: 0.33\n",
      "episode: 066\t steps: 00405\t total steps:337365\t epsilon: 0.33\n",
      "episode: 067\t steps: 02559\t total steps:339923\t epsilon: 0.33\n",
      "episode: 068\t steps: 02237\t total steps:342159\t epsilon: 0.32\n",
      "episode: 069\t steps: 00667\t total steps:342825\t epsilon: 0.32\n",
      "episode: 070\t steps: 03045\t total steps:345869\t epsilon: 0.32\n",
      "episode: 071\t steps: 00745\t total steps:346613\t epsilon: 0.31\n",
      "episode: 072\t steps: 01041\t total steps:347653\t epsilon: 0.31\n",
      "episode: 073\t steps: 01379\t total steps:349031\t epsilon: 0.31\n",
      "episode: 074\t steps: 01737\t total steps:350767\t epsilon: 0.31\n",
      "episode: 075\t steps: 01039\t total steps:351805\t epsilon: 0.30\n",
      "episode: 076\t steps: 01601\t total steps:353405\t epsilon: 0.30\n",
      "episode: 077\t steps: 00583\t total steps:353987\t epsilon: 0.30\n",
      "episode: 078\t steps: 01291\t total steps:355277\t epsilon: 0.30\n",
      "episode: 079\t steps: 01861\t total steps:357137\t epsilon: 0.29\n",
      "episode: 080\t steps: 01019\t total steps:358155\t epsilon: 0.29\n",
      "episode: 081\t steps: 00469\t total steps:358623\t epsilon: 0.29\n",
      "episode: 082\t steps: 00703\t total steps:359325\t epsilon: 0.29\n",
      "episode: 083\t steps: 01595\t total steps:360919\t epsilon: 0.29\n",
      "episode: 084\t steps: 01171\t total steps:362089\t epsilon: 0.28\n",
      "episode: 085\t steps: 00549\t total steps:362637\t epsilon: 0.28\n",
      "episode: 086\t steps: 01755\t total steps:364391\t epsilon: 0.28\n",
      "episode: 087\t steps: 01475\t total steps:365865\t epsilon: 0.28\n",
      "episode: 088\t steps: 00531\t total steps:366395\t epsilon: 0.27\n",
      "episode: 089\t steps: 03319\t total steps:369713\t epsilon: 0.27\n",
      "episode: 090\t steps: 02785\t total steps:372497\t epsilon: 0.26\n",
      "episode: 091\t steps: 01887\t total steps:374383\t epsilon: 0.26\n",
      "episode: 092\t steps: 03055\t total steps:377437\t epsilon: 0.25\n",
      "episode: 093\t steps: 00691\t total steps:378127\t epsilon: 0.25\n",
      "episode: 094\t steps: 01817\t total steps:379943\t epsilon: 0.25\n",
      "episode: 095\t steps: 00621\t total steps:380563\t epsilon: 0.25\n",
      "episode: 096\t steps: 01507\t total steps:382069\t epsilon: 0.24\n",
      "episode: 097\t steps: 01199\t total steps:383267\t epsilon: 0.24\n",
      "episode: 098\t steps: 00473\t total steps:383739\t epsilon: 0.24\n",
      "episode: 099\t steps: 00835\t total steps:384573\t epsilon: 0.24\n",
      "episode: 100\t steps: 01163\t total steps:385735\t epsilon: 0.24\n",
      "Evaluation: 2\t average reward: -10000.0\n",
      "episode: 101\t steps: 04003\t total steps:389737\t epsilon: 0.23\n",
      "episode: 102\t steps: 01367\t total steps:391103\t epsilon: 0.23\n",
      "episode: 103\t steps: 01033\t total steps:392135\t epsilon: 0.22\n",
      "episode: 104\t steps: 01031\t total steps:393165\t epsilon: 0.22\n",
      "episode: 105\t steps: 00707\t total steps:393871\t epsilon: 0.22\n",
      "episode: 106\t steps: 00455\t total steps:394325\t epsilon: 0.22\n",
      "episode: 107\t steps: 02055\t total steps:396379\t epsilon: 0.22\n",
      "episode: 108\t steps: 01451\t total steps:397829\t epsilon: 0.21\n",
      "episode: 109\t steps: 02375\t total steps:400203\t epsilon: 0.21\n",
      "episode: 110\t steps: 03179\t total steps:403381\t epsilon: 0.20\n",
      "episode: 111\t steps: 00949\t total steps:404329\t epsilon: 0.20\n",
      "episode: 112\t steps: 00761\t total steps:405089\t epsilon: 0.20\n",
      "episode: 113\t steps: 00803\t total steps:405891\t epsilon: 0.20\n",
      "episode: 114\t steps: 02261\t total steps:408151\t epsilon: 0.19\n",
      "episode: 115\t steps: 00693\t total steps:408843\t epsilon: 0.19\n",
      "episode: 116\t steps: 00379\t total steps:409221\t epsilon: 0.19\n",
      "episode: 117\t steps: 01907\t total steps:411127\t epsilon: 0.19\n",
      "episode: 118\t steps: 06391\t total steps:417517\t epsilon: 0.17\n",
      "episode: 119\t steps: 00981\t total steps:418497\t epsilon: 0.17\n",
      "episode: 120\t steps: 00679\t total steps:419175\t epsilon: 0.17\n",
      "episode: 121\t steps: 00475\t total steps:419649\t epsilon: 0.17\n",
      "episode: 122\t steps: 01165\t total steps:420813\t epsilon: 0.17\n",
      "episode: 123\t steps: 01293\t total steps:422105\t epsilon: 0.16\n",
      "episode: 124\t steps: 03457\t total steps:425561\t epsilon: 0.16\n",
      "episode: 125\t steps: 01169\t total steps:426729\t epsilon: 0.16\n",
      "episode: 126\t steps: 00545\t total steps:427273\t epsilon: 0.15\n",
      "episode: 127\t steps: 08335\t total steps:435607\t epsilon: 0.14\n",
      "episode: 128\t steps: 02795\t total steps:438401\t epsilon: 0.13\n",
      "episode: 129\t steps: 03087\t total steps:441487\t epsilon: 0.13\n",
      "episode: 130\t steps: 01029\t total steps:442515\t epsilon: 0.12\n",
      "episode: 131\t steps: 00995\t total steps:443509\t epsilon: 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 132\t steps: 01457\t total steps:444965\t epsilon: 0.12\n",
      "episode: 133\t steps: 01127\t total steps:446091\t epsilon: 0.12\n",
      "episode: 134\t steps: 00703\t total steps:446793\t epsilon: 0.12\n",
      "episode: 135\t steps: 01057\t total steps:447849\t epsilon: 0.11\n",
      "episode: 136\t steps: 03499\t total steps:451347\t epsilon: 0.11\n",
      "episode: 137\t steps: 04539\t total steps:455885\t epsilon: 0.10\n",
      "episode: 138\t steps: 02787\t total steps:458671\t epsilon: 0.09\n",
      "episode: 139\t steps: 00435\t total steps:459105\t epsilon: 0.09\n",
      "episode: 140\t steps: 01161\t total steps:460265\t epsilon: 0.09\n",
      "episode: 141\t steps: 02425\t total steps:462689\t epsilon: 0.08\n",
      "episode: 142\t steps: 02139\t total steps:464827\t epsilon: 0.08\n",
      "episode: 143\t steps: 00753\t total steps:465579\t epsilon: 0.08\n",
      "episode: 144\t steps: 00497\t total steps:466075\t epsilon: 0.08\n",
      "episode: 145\t steps: 00517\t total steps:466591\t epsilon: 0.08\n",
      "episode: 146\t steps: 00409\t total steps:466999\t epsilon: 0.08\n",
      "episode: 147\t steps: 00385\t total steps:467383\t epsilon: 0.07\n",
      "episode: 148\t steps: 01161\t total steps:468543\t epsilon: 0.07\n",
      "episode: 149\t steps: 00733\t total steps:469275\t epsilon: 0.07\n",
      "episode: 150\t steps: 01143\t total steps:470417\t epsilon: 0.07\n",
      "Evaluation: 3\t average reward: -10000.0\n",
      "episode: 151\t steps: 00661\t total steps:471077\t epsilon: 0.07\n",
      "episode: 152\t steps: 00709\t total steps:471785\t epsilon: 0.07\n",
      "episode: 153\t steps: 00545\t total steps:472329\t epsilon: 0.06\n",
      "episode: 154\t steps: 00357\t total steps:472685\t epsilon: 0.06\n",
      "episode: 155\t steps: 03549\t total steps:476233\t epsilon: 0.06\n",
      "episode: 156\t steps: 01079\t total steps:477311\t epsilon: 0.05\n",
      "episode: 157\t steps: 02673\t total steps:479983\t epsilon: 0.05\n",
      "episode: 158\t steps: 01565\t total steps:481547\t epsilon: 0.05\n",
      "episode: 159\t steps: 00289\t total steps:481835\t epsilon: 0.05\n",
      "episode: 160\t steps: 00763\t total steps:482597\t epsilon: 0.04\n",
      "episode: 161\t steps: 00353\t total steps:482949\t epsilon: 0.04\n",
      "episode: 162\t steps: 00739\t total steps:483687\t epsilon: 0.04\n",
      "episode: 163\t steps: 01747\t total steps:485433\t epsilon: 0.04\n",
      "episode: 164\t steps: 03607\t total steps:489039\t epsilon: 0.03\n",
      "episode: 165\t steps: 00307\t total steps:489345\t epsilon: 0.03\n",
      "episode: 166\t steps: 00315\t total steps:489659\t epsilon: 0.03\n",
      "episode: 167\t steps: 00389\t total steps:490047\t epsilon: 0.03\n",
      "episode: 168\t steps: 00695\t total steps:490741\t epsilon: 0.03\n",
      "episode: 169\t steps: 00929\t total steps:491669\t epsilon: 0.03\n",
      "episode: 170\t steps: 01271\t total steps:492939\t epsilon: 0.02\n",
      "episode: 171\t steps: 00437\t total steps:493375\t epsilon: 0.02\n",
      "episode: 172\t steps: 00609\t total steps:493983\t epsilon: 0.02\n",
      "episode: 173\t steps: 01921\t total steps:495903\t epsilon: 0.02\n",
      "episode: 174\t steps: 00373\t total steps:496275\t epsilon: 0.02\n",
      "episode: 175\t steps: 01279\t total steps:497553\t epsilon: 0.01\n",
      "episode: 176\t steps: 01437\t total steps:498989\t epsilon: 0.01\n",
      "episode: 177\t steps: 00373\t total steps:499361\t epsilon: 0.01\n",
      "episode: 178\t steps: 01005\t total steps:500365\t epsilon: 0.01\n",
      "episode: 179\t steps: 00547\t total steps:500911\t epsilon: 0.01\n",
      "episode: 180\t steps: 00565\t total steps:501475\t epsilon: 0.01\n",
      "episode: 181\t steps: 00509\t total steps:501983\t epsilon: 0.01\n",
      "episode: 182\t steps: 02799\t total steps:504781\t epsilon: 0.01\n",
      "episode: 183\t steps: 00457\t total steps:505237\t epsilon: 0.01\n",
      "episode: 184\t steps: 00841\t total steps:506077\t epsilon: 0.01\n",
      "episode: 185\t steps: 00611\t total steps:506687\t epsilon: 0.01\n",
      "episode: 186\t steps: 01407\t total steps:508093\t epsilon: 0.01\n",
      "episode: 187\t steps: 00633\t total steps:508725\t epsilon: 0.01\n",
      "episode: 188\t steps: 00481\t total steps:509205\t epsilon: 0.01\n",
      "episode: 189\t steps: 00247\t total steps:509451\t epsilon: 0.01\n",
      "episode: 190\t steps: 00717\t total steps:510167\t epsilon: 0.01\n",
      "episode: 191\t steps: 00593\t total steps:510759\t epsilon: 0.01\n",
      "episode: 192\t steps: 00555\t total steps:511313\t epsilon: 0.01\n",
      "episode: 193\t steps: 01681\t total steps:512993\t epsilon: 0.01\n",
      "episode: 194\t steps: 00483\t total steps:513475\t epsilon: 0.01\n",
      "episode: 195\t steps: 00451\t total steps:513925\t epsilon: 0.01\n",
      "episode: 196\t steps: 00757\t total steps:514681\t epsilon: 0.01\n",
      "episode: 197\t steps: 00359\t total steps:515039\t epsilon: 0.01\n",
      "episode: 198\t steps: 00631\t total steps:515669\t epsilon: 0.01\n",
      "episode: 199\t steps: 00533\t total steps:516201\t epsilon: 0.01\n",
      "episode: 200\t steps: 00739\t total steps:516939\t epsilon: 0.01\n",
      "Evaluation: 4\t average reward: -10000.0\n",
      "episode: 201\t steps: 00299\t total steps:517237\t epsilon: 0.01\n",
      "episode: 202\t steps: 02131\t total steps:519367\t epsilon: 0.01\n",
      "episode: 203\t steps: 00609\t total steps:519975\t epsilon: 0.01\n",
      "episode: 204\t steps: 00619\t total steps:520593\t epsilon: 0.01\n",
      "episode: 205\t steps: 01661\t total steps:522253\t epsilon: 0.01\n",
      "episode: 206\t steps: 00883\t total steps:523135\t epsilon: 0.01\n",
      "episode: 207\t steps: 00339\t total steps:523473\t epsilon: 0.01\n",
      "episode: 208\t steps: 01241\t total steps:524713\t epsilon: 0.01\n",
      "episode: 209\t steps: 00671\t total steps:525383\t epsilon: 0.01\n",
      "episode: 210\t steps: 00355\t total steps:525737\t epsilon: 0.01\n",
      "episode: 211\t steps: 00621\t total steps:526357\t epsilon: 0.01\n",
      "episode: 212\t steps: 00809\t total steps:527165\t epsilon: 0.01\n",
      "episode: 213\t steps: 01081\t total steps:528245\t epsilon: 0.01\n",
      "episode: 214\t steps: 00321\t total steps:528565\t epsilon: 0.01\n",
      "episode: 215\t steps: 01861\t total steps:530425\t epsilon: 0.01\n",
      "episode: 216\t steps: 00349\t total steps:530773\t epsilon: 0.01\n",
      "episode: 217\t steps: 01645\t total steps:532417\t epsilon: 0.01\n",
      "episode: 218\t steps: 01127\t total steps:533543\t epsilon: 0.01\n",
      "episode: 219\t steps: 00613\t total steps:534155\t epsilon: 0.01\n",
      "episode: 220\t steps: 00503\t total steps:534657\t epsilon: 0.01\n",
      "episode: 221\t steps: 00629\t total steps:535285\t epsilon: 0.01\n",
      "episode: 222\t steps: 00501\t total steps:535785\t epsilon: 0.01\n",
      "episode: 223\t steps: 00921\t total steps:536705\t epsilon: 0.01\n",
      "episode: 224\t steps: 02113\t total steps:538817\t epsilon: 0.01\n",
      "episode: 225\t steps: 00293\t total steps:539109\t epsilon: 0.01\n",
      "episode: 226\t steps: 01255\t total steps:540363\t epsilon: 0.01\n",
      "episode: 227\t steps: 03093\t total steps:543455\t epsilon: 0.01\n",
      "episode: 228\t steps: 02457\t total steps:545911\t epsilon: 0.01\n",
      "episode: 229\t steps: 00695\t total steps:546605\t epsilon: 0.01\n",
      "episode: 230\t steps: 01571\t total steps:548175\t epsilon: 0.01\n",
      "episode: 231\t steps: 01165\t total steps:549339\t epsilon: 0.01\n",
      "episode: 232\t steps: 00381\t total steps:549719\t epsilon: 0.01\n",
      "episode: 233\t steps: 00743\t total steps:550461\t epsilon: 0.01\n",
      "episode: 234\t steps: 00293\t total steps:550753\t epsilon: 0.01\n",
      "episode: 235\t steps: 00463\t total steps:551215\t epsilon: 0.01\n",
      "episode: 236\t steps: 00683\t total steps:551897\t epsilon: 0.01\n",
      "episode: 237\t steps: 00423\t total steps:552319\t epsilon: 0.01\n",
      "episode: 238\t steps: 00351\t total steps:552669\t epsilon: 0.01\n",
      "episode: 239\t steps: 00375\t total steps:553043\t epsilon: 0.01\n",
      "episode: 240\t steps: 00401\t total steps:553443\t epsilon: 0.01\n",
      "episode: 241\t steps: 01163\t total steps:554605\t epsilon: 0.01\n",
      "episode: 242\t steps: 00309\t total steps:554913\t epsilon: 0.01\n",
      "episode: 243\t steps: 00301\t total steps:555213\t epsilon: 0.01\n",
      "episode: 244\t steps: 00381\t total steps:555593\t epsilon: 0.01\n",
      "episode: 245\t steps: 00709\t total steps:556301\t epsilon: 0.01\n",
      "episode: 246\t steps: 00999\t total steps:557299\t epsilon: 0.01\n",
      "episode: 247\t steps: 00413\t total steps:557711\t epsilon: 0.01\n",
      "episode: 248\t steps: 00335\t total steps:558045\t epsilon: 0.01\n",
      "episode: 249\t steps: 00701\t total steps:558745\t epsilon: 0.01\n",
      "episode: 250\t steps: 00387\t total steps:559131\t epsilon: 0.01\n",
      "Evaluation: 5\t average reward: -10000.0\n",
      "episode: 251\t steps: 01231\t total steps:560361\t epsilon: 0.01\n",
      "episode: 252\t steps: 01095\t total steps:561455\t epsilon: 0.01\n",
      "episode: 253\t steps: 01745\t total steps:563199\t epsilon: 0.01\n",
      "episode: 254\t steps: 01053\t total steps:564251\t epsilon: 0.01\n",
      "episode: 255\t steps: 01179\t total steps:565429\t epsilon: 0.01\n",
      "episode: 256\t steps: 00977\t total steps:566405\t epsilon: 0.01\n",
      "episode: 257\t steps: 00339\t total steps:566743\t epsilon: 0.01\n",
      "episode: 258\t steps: 00593\t total steps:567335\t epsilon: 0.01\n",
      "episode: 259\t steps: 00539\t total steps:567873\t epsilon: 0.01\n",
      "episode: 260\t steps: 00529\t total steps:568401\t epsilon: 0.01\n",
      "episode: 261\t steps: 00281\t total steps:568681\t epsilon: 0.01\n",
      "episode: 262\t steps: 00467\t total steps:569147\t epsilon: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 263\t steps: 00255\t total steps:569401\t epsilon: 0.01\n",
      "episode: 264\t steps: 00493\t total steps:569893\t epsilon: 0.01\n",
      "episode: 265\t steps: 01145\t total steps:571037\t epsilon: 0.01\n",
      "episode: 266\t steps: 00247\t total steps:571283\t epsilon: 0.01\n",
      "episode: 267\t steps: 03585\t total steps:574867\t epsilon: 0.01\n",
      "episode: 268\t steps: 01443\t total steps:576309\t epsilon: 0.01\n",
      "episode: 269\t steps: 00939\t total steps:577247\t epsilon: 0.01\n",
      "episode: 270\t steps: 00877\t total steps:578123\t epsilon: 0.01\n",
      "episode: 271\t steps: 00733\t total steps:578855\t epsilon: 0.01\n",
      "episode: 272\t steps: 00873\t total steps:579727\t epsilon: 0.01\n",
      "episode: 273\t steps: 01077\t total steps:580803\t epsilon: 0.01\n",
      "episode: 274\t steps: 00781\t total steps:581583\t epsilon: 0.01\n",
      "episode: 275\t steps: 00325\t total steps:581907\t epsilon: 0.01\n",
      "episode: 276\t steps: 00509\t total steps:582415\t epsilon: 0.01\n",
      "episode: 277\t steps: 00517\t total steps:582931\t epsilon: 0.01\n",
      "episode: 278\t steps: 01097\t total steps:584027\t epsilon: 0.01\n",
      "episode: 279\t steps: 02551\t total steps:586577\t epsilon: 0.01\n",
      "episode: 280\t steps: 00271\t total steps:586847\t epsilon: 0.01\n",
      "episode: 281\t steps: 00647\t total steps:587493\t epsilon: 0.01\n",
      "episode: 282\t steps: 00943\t total steps:588435\t epsilon: 0.01\n",
      "episode: 283\t steps: 00437\t total steps:588871\t epsilon: 0.01\n",
      "episode: 284\t steps: 00505\t total steps:589375\t epsilon: 0.01\n",
      "episode: 285\t steps: 01443\t total steps:590817\t epsilon: 0.01\n",
      "episode: 286\t steps: 00761\t total steps:591577\t epsilon: 0.01\n",
      "episode: 287\t steps: 01197\t total steps:592773\t epsilon: 0.01\n",
      "episode: 288\t steps: 00307\t total steps:593079\t epsilon: 0.01\n",
      "episode: 289\t steps: 00759\t total steps:593837\t epsilon: 0.01\n",
      "episode: 290\t steps: 00333\t total steps:594169\t epsilon: 0.01\n",
      "episode: 291\t steps: 01343\t total steps:595511\t epsilon: 0.01\n",
      "episode: 292\t steps: 00405\t total steps:595915\t epsilon: 0.01\n",
      "episode: 293\t steps: 00319\t total steps:596233\t epsilon: 0.01\n",
      "episode: 294\t steps: 00695\t total steps:596927\t epsilon: 0.01\n",
      "episode: 295\t steps: 00301\t total steps:597227\t epsilon: 0.01\n",
      "episode: 296\t steps: 01829\t total steps:599055\t epsilon: 0.01\n",
      "episode: 297\t steps: 02017\t total steps:601071\t epsilon: 0.01\n",
      "episode: 298\t steps: 00595\t total steps:601665\t epsilon: 0.01\n",
      "episode: 299\t steps: 01027\t total steps:602691\t epsilon: 0.01\n",
      "episode: 300\t steps: 00595\t total steps:603285\t epsilon: 0.01\n",
      "Evaluation: 6\t average reward: -10000.0\n",
      "episode: 301\t steps: 02259\t total steps:605543\t epsilon: 0.01\n",
      "episode: 302\t steps: 00375\t total steps:605917\t epsilon: 0.01\n",
      "episode: 303\t steps: 00243\t total steps:606159\t epsilon: 0.01\n",
      "episode: 304\t steps: 01989\t total steps:608147\t epsilon: 0.01\n",
      "episode: 305\t steps: 00359\t total steps:608505\t epsilon: 0.01\n",
      "episode: 306\t steps: 00545\t total steps:609049\t epsilon: 0.01\n",
      "episode: 307\t steps: 01155\t total steps:610203\t epsilon: 0.01\n",
      "episode: 308\t steps: 00247\t total steps:610449\t epsilon: 0.01\n",
      "episode: 309\t steps: 00217\t total steps:610665\t epsilon: 0.01\n",
      "episode: 310\t steps: 00297\t total steps:610961\t epsilon: 0.01\n",
      "episode: 311\t steps: 00269\t total steps:611229\t epsilon: 0.01\n",
      "episode: 312\t steps: 00415\t total steps:611643\t epsilon: 0.01\n",
      "episode: 313\t steps: 00267\t total steps:611909\t epsilon: 0.01\n",
      "episode: 314\t steps: 01149\t total steps:613057\t epsilon: 0.01\n",
      "episode: 315\t steps: 00883\t total steps:613939\t epsilon: 0.01\n",
      "episode: 316\t steps: 01393\t total steps:615331\t epsilon: 0.01\n",
      "episode: 317\t steps: 00605\t total steps:615935\t epsilon: 0.01\n",
      "episode: 318\t steps: 00341\t total steps:616275\t epsilon: 0.01\n",
      "episode: 319\t steps: 00745\t total steps:617019\t epsilon: 0.01\n",
      "episode: 320\t steps: 00407\t total steps:617425\t epsilon: 0.01\n",
      "episode: 321\t steps: 00607\t total steps:618031\t epsilon: 0.01\n",
      "episode: 322\t steps: 01791\t total steps:619821\t epsilon: 0.01\n",
      "episode: 323\t steps: 00495\t total steps:620315\t epsilon: 0.01\n",
      "episode: 324\t steps: 00341\t total steps:620655\t epsilon: 0.01\n",
      "episode: 325\t steps: 01737\t total steps:622391\t epsilon: 0.01\n",
      "episode: 326\t steps: 00291\t total steps:622681\t epsilon: 0.01\n",
      "episode: 327\t steps: 00313\t total steps:622993\t epsilon: 0.01\n",
      "episode: 328\t steps: 01363\t total steps:624355\t epsilon: 0.01\n",
      "episode: 329\t steps: 00397\t total steps:624751\t epsilon: 0.01\n",
      "episode: 330\t steps: 00389\t total steps:625139\t epsilon: 0.01\n",
      "episode: 331\t steps: 00411\t total steps:625549\t epsilon: 0.01\n",
      "episode: 332\t steps: 00503\t total steps:626051\t epsilon: 0.01\n",
      "episode: 333\t steps: 01285\t total steps:627335\t epsilon: 0.01\n",
      "episode: 334\t steps: 00783\t total steps:628117\t epsilon: 0.01\n",
      "episode: 335\t steps: 00401\t total steps:628517\t epsilon: 0.01\n",
      "episode: 336\t steps: 00609\t total steps:629125\t epsilon: 0.01\n",
      "episode: 337\t steps: 01799\t total steps:630923\t epsilon: 0.01\n",
      "episode: 338\t steps: 00831\t total steps:631753\t epsilon: 0.01\n",
      "episode: 339\t steps: 01917\t total steps:633669\t epsilon: 0.01\n",
      "episode: 340\t steps: 00607\t total steps:634275\t epsilon: 0.01\n",
      "episode: 341\t steps: 01413\t total steps:635687\t epsilon: 0.01\n",
      "episode: 342\t steps: 00507\t total steps:636193\t epsilon: 0.01\n",
      "episode: 343\t steps: 03365\t total steps:639557\t epsilon: 0.01\n",
      "episode: 344\t steps: 01627\t total steps:641183\t epsilon: 0.01\n",
      "episode: 345\t steps: 01033\t total steps:642215\t epsilon: 0.01\n",
      "episode: 346\t steps: 00389\t total steps:642603\t epsilon: 0.01\n",
      "episode: 347\t steps: 00411\t total steps:643013\t epsilon: 0.01\n",
      "episode: 348\t steps: 00737\t total steps:643749\t epsilon: 0.01\n",
      "episode: 349\t steps: 02083\t total steps:645831\t epsilon: 0.01\n",
      "episode: 350\t steps: 00449\t total steps:646279\t epsilon: 0.01\n",
      "Evaluation: 7\t average reward: -10000.0\n",
      "episode: 351\t steps: 00733\t total steps:647011\t epsilon: 0.01\n",
      "episode: 352\t steps: 00489\t total steps:647499\t epsilon: 0.01\n",
      "episode: 353\t steps: 00829\t total steps:648327\t epsilon: 0.01\n",
      "episode: 354\t steps: 00555\t total steps:648881\t epsilon: 0.01\n",
      "episode: 355\t steps: 01965\t total steps:650845\t epsilon: 0.01\n",
      "episode: 356\t steps: 00815\t total steps:651659\t epsilon: 0.01\n",
      "episode: 357\t steps: 01585\t total steps:653243\t epsilon: 0.01\n",
      "episode: 358\t steps: 00521\t total steps:653763\t epsilon: 0.01\n",
      "episode: 359\t steps: 01315\t total steps:655077\t epsilon: 0.01\n",
      "episode: 360\t steps: 00729\t total steps:655805\t epsilon: 0.01\n",
      "episode: 361\t steps: 00749\t total steps:656553\t epsilon: 0.01\n",
      "episode: 362\t steps: 01951\t total steps:658503\t epsilon: 0.01\n",
      "episode: 363\t steps: 00691\t total steps:659193\t epsilon: 0.01\n",
      "episode: 364\t steps: 02189\t total steps:661381\t epsilon: 0.01\n",
      "episode: 365\t steps: 00225\t total steps:661605\t epsilon: 0.01\n",
      "episode: 366\t steps: 01447\t total steps:663051\t epsilon: 0.01\n",
      "episode: 367\t steps: 01345\t total steps:664395\t epsilon: 0.01\n",
      "episode: 368\t steps: 00253\t total steps:664647\t epsilon: 0.01\n",
      "episode: 369\t steps: 00483\t total steps:665129\t epsilon: 0.01\n",
      "episode: 370\t steps: 00523\t total steps:665651\t epsilon: 0.01\n",
      "episode: 371\t steps: 02313\t total steps:667963\t epsilon: 0.01\n",
      "episode: 372\t steps: 00247\t total steps:668209\t epsilon: 0.01\n",
      "episode: 373\t steps: 00549\t total steps:668757\t epsilon: 0.01\n",
      "episode: 374\t steps: 01039\t total steps:669795\t epsilon: 0.01\n",
      "episode: 375\t steps: 00779\t total steps:670573\t epsilon: 0.01\n",
      "episode: 376\t steps: 00395\t total steps:670967\t epsilon: 0.01\n",
      "episode: 377\t steps: 00663\t total steps:671629\t epsilon: 0.01\n",
      "episode: 378\t steps: 02225\t total steps:673853\t epsilon: 0.01\n",
      "episode: 379\t steps: 00573\t total steps:674425\t epsilon: 0.01\n",
      "episode: 380\t steps: 00777\t total steps:675201\t epsilon: 0.01\n",
      "episode: 381\t steps: 00565\t total steps:675765\t epsilon: 0.01\n",
      "episode: 382\t steps: 01777\t total steps:677541\t epsilon: 0.01\n",
      "episode: 383\t steps: 00337\t total steps:677877\t epsilon: 0.01\n",
      "episode: 384\t steps: 00417\t total steps:678293\t epsilon: 0.01\n",
      "episode: 385\t steps: 00833\t total steps:679125\t epsilon: 0.01\n",
      "episode: 386\t steps: 01097\t total steps:680221\t epsilon: 0.01\n",
      "episode: 387\t steps: 00707\t total steps:680927\t epsilon: 0.01\n",
      "episode: 388\t steps: 04081\t total steps:685007\t epsilon: 0.01\n",
      "episode: 389\t steps: 00767\t total steps:685773\t epsilon: 0.01\n",
      "episode: 390\t steps: 00395\t total steps:686167\t epsilon: 0.01\n",
      "episode: 391\t steps: 02277\t total steps:688443\t epsilon: 0.01\n",
      "episode: 392\t steps: 00993\t total steps:689435\t epsilon: 0.01\n",
      "episode: 393\t steps: 00883\t total steps:690317\t epsilon: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 394\t steps: 01219\t total steps:691535\t epsilon: 0.01\n",
      "episode: 395\t steps: 00509\t total steps:692043\t epsilon: 0.01\n",
      "episode: 396\t steps: 00609\t total steps:692651\t epsilon: 0.01\n",
      "episode: 397\t steps: 00977\t total steps:693627\t epsilon: 0.01\n",
      "episode: 398\t steps: 01105\t total steps:694731\t epsilon: 0.01\n",
      "episode: 399\t steps: 02583\t total steps:697313\t epsilon: 0.01\n",
      "episode: 400\t steps: 02849\t total steps:700161\t epsilon: 0.01\n",
      "Evaluation: 8\t average reward: -10000.0\n",
      "episode: 401\t steps: 00333\t total steps:700493\t epsilon: 0.01\n",
      "episode: 402\t steps: 01063\t total steps:701555\t epsilon: 0.01\n",
      "episode: 403\t steps: 01045\t total steps:702599\t epsilon: 0.01\n",
      "episode: 404\t steps: 02317\t total steps:704915\t epsilon: 0.01\n",
      "episode: 405\t steps: 00637\t total steps:705551\t epsilon: 0.01\n",
      "episode: 406\t steps: 00803\t total steps:706353\t epsilon: 0.01\n",
      "episode: 407\t steps: 00781\t total steps:707133\t epsilon: 0.01\n",
      "episode: 408\t steps: 00733\t total steps:707865\t epsilon: 0.01\n",
      "episode: 409\t steps: 01329\t total steps:709193\t epsilon: 0.01\n",
      "episode: 410\t steps: 00597\t total steps:709789\t epsilon: 0.01\n",
      "episode: 411\t steps: 01253\t total steps:711041\t epsilon: 0.01\n",
      "episode: 412\t steps: 01417\t total steps:712457\t epsilon: 0.01\n",
      "episode: 413\t steps: 01239\t total steps:713695\t epsilon: 0.01\n",
      "episode: 414\t steps: 00693\t total steps:714387\t epsilon: 0.01\n",
      "episode: 415\t steps: 02127\t total steps:716513\t epsilon: 0.01\n",
      "episode: 416\t steps: 01037\t total steps:717549\t epsilon: 0.01\n",
      "episode: 417\t steps: 00553\t total steps:718101\t epsilon: 0.01\n",
      "episode: 418\t steps: 00989\t total steps:719089\t epsilon: 0.01\n",
      "episode: 419\t steps: 00415\t total steps:719503\t epsilon: 0.01\n",
      "episode: 420\t steps: 01049\t total steps:720551\t epsilon: 0.01\n",
      "episode: 421\t steps: 00453\t total steps:721003\t epsilon: 0.01\n",
      "episode: 422\t steps: 01129\t total steps:722131\t epsilon: 0.01\n",
      "episode: 423\t steps: 03727\t total steps:725857\t epsilon: 0.01\n",
      "episode: 424\t steps: 01033\t total steps:726889\t epsilon: 0.01\n",
      "episode: 425\t steps: 02273\t total steps:729161\t epsilon: 0.01\n",
      "episode: 426\t steps: 01207\t total steps:730367\t epsilon: 0.01\n",
      "episode: 427\t steps: 00747\t total steps:731113\t epsilon: 0.01\n",
      "episode: 428\t steps: 00517\t total steps:731629\t epsilon: 0.01\n",
      "episode: 429\t steps: 01487\t total steps:733115\t epsilon: 0.01\n",
      "episode: 430\t steps: 00435\t total steps:733549\t epsilon: 0.01\n",
      "episode: 431\t steps: 01089\t total steps:734637\t epsilon: 0.01\n",
      "episode: 432\t steps: 02277\t total steps:736913\t epsilon: 0.01\n",
      "episode: 433\t steps: 00917\t total steps:737829\t epsilon: 0.01\n",
      "episode: 434\t steps: 01035\t total steps:738863\t epsilon: 0.01\n",
      "episode: 435\t steps: 00263\t total steps:739125\t epsilon: 0.01\n",
      "episode: 436\t steps: 01319\t total steps:740443\t epsilon: 0.01\n",
      "episode: 437\t steps: 01165\t total steps:741607\t epsilon: 0.01\n",
      "episode: 438\t steps: 02467\t total steps:744073\t epsilon: 0.01\n",
      "episode: 439\t steps: 01283\t total steps:745355\t epsilon: 0.01\n",
      "episode: 440\t steps: 01295\t total steps:746649\t epsilon: 0.01\n",
      "episode: 441\t steps: 01367\t total steps:748015\t epsilon: 0.01\n",
      "episode: 442\t steps: 00617\t total steps:748631\t epsilon: 0.01\n",
      "episode: 443\t steps: 00651\t total steps:749281\t epsilon: 0.01\n",
      "episode: 444\t steps: 00925\t total steps:750205\t epsilon: 0.01\n",
      "episode: 445\t steps: 00583\t total steps:750787\t epsilon: 0.01\n",
      "episode: 446\t steps: 01453\t total steps:752239\t epsilon: 0.01\n",
      "episode: 447\t steps: 00833\t total steps:753071\t epsilon: 0.01\n",
      "episode: 448\t steps: 00213\t total steps:753283\t epsilon: 0.01\n",
      "episode: 449\t steps: 00763\t total steps:754045\t epsilon: 0.01\n",
      "episode: 450\t steps: 00569\t total steps:754613\t epsilon: 0.01\n",
      "Evaluation: 9\t average reward: -10000.0\n",
      "episode: 451\t steps: 01471\t total steps:756083\t epsilon: 0.01\n",
      "episode: 452\t steps: 00683\t total steps:756765\t epsilon: 0.01\n",
      "episode: 453\t steps: 00783\t total steps:757547\t epsilon: 0.01\n",
      "episode: 454\t steps: 00679\t total steps:758225\t epsilon: 0.01\n",
      "episode: 455\t steps: 01405\t total steps:759629\t epsilon: 0.01\n",
      "episode: 456\t steps: 01201\t total steps:760829\t epsilon: 0.01\n",
      "episode: 457\t steps: 02057\t total steps:762885\t epsilon: 0.01\n",
      "episode: 458\t steps: 00343\t total steps:763227\t epsilon: 0.01\n",
      "episode: 459\t steps: 00673\t total steps:763899\t epsilon: 0.01\n",
      "episode: 460\t steps: 00241\t total steps:764139\t epsilon: 0.01\n",
      "episode: 461\t steps: 02867\t total steps:767005\t epsilon: 0.01\n",
      "episode: 462\t steps: 01581\t total steps:768585\t epsilon: 0.01\n",
      "episode: 463\t steps: 01287\t total steps:769871\t epsilon: 0.01\n",
      "episode: 464\t steps: 00795\t total steps:770665\t epsilon: 0.01\n",
      "episode: 465\t steps: 00495\t total steps:771159\t epsilon: 0.01\n",
      "episode: 466\t steps: 00229\t total steps:771387\t epsilon: 0.01\n",
      "episode: 467\t steps: 00737\t total steps:772123\t epsilon: 0.01\n",
      "episode: 468\t steps: 01145\t total steps:773267\t epsilon: 0.01\n",
      "episode: 469\t steps: 00239\t total steps:773505\t epsilon: 0.01\n",
      "episode: 470\t steps: 01341\t total steps:774845\t epsilon: 0.01\n",
      "episode: 471\t steps: 01177\t total steps:776021\t epsilon: 0.01\n",
      "episode: 472\t steps: 00455\t total steps:776475\t epsilon: 0.01\n",
      "episode: 473\t steps: 01109\t total steps:777583\t epsilon: 0.01\n",
      "episode: 474\t steps: 00317\t total steps:777899\t epsilon: 0.01\n",
      "episode: 475\t steps: 00787\t total steps:778685\t epsilon: 0.01\n",
      "episode: 476\t steps: 00673\t total steps:779357\t epsilon: 0.01\n",
      "episode: 477\t steps: 02831\t total steps:782187\t epsilon: 0.01\n",
      "episode: 478\t steps: 00371\t total steps:782557\t epsilon: 0.01\n",
      "episode: 479\t steps: 00459\t total steps:783015\t epsilon: 0.01\n",
      "episode: 480\t steps: 00337\t total steps:783351\t epsilon: 0.01\n",
      "episode: 481\t steps: 00529\t total steps:783879\t epsilon: 0.01\n",
      "episode: 482\t steps: 00861\t total steps:784739\t epsilon: 0.01\n",
      "episode: 483\t steps: 01447\t total steps:786185\t epsilon: 0.01\n",
      "episode: 484\t steps: 00305\t total steps:786489\t epsilon: 0.01\n",
      "episode: 485\t steps: 00221\t total steps:786709\t epsilon: 0.01\n",
      "episode: 486\t steps: 00431\t total steps:787139\t epsilon: 0.01\n",
      "episode: 487\t steps: 03833\t total steps:790971\t epsilon: 0.01\n",
      "episode: 488\t steps: 00889\t total steps:791859\t epsilon: 0.01\n",
      "episode: 489\t steps: 00453\t total steps:792311\t epsilon: 0.01\n",
      "episode: 490\t steps: 00665\t total steps:792975\t epsilon: 0.01\n",
      "episode: 491\t steps: 00371\t total steps:793345\t epsilon: 0.01\n",
      "episode: 492\t steps: 01019\t total steps:794363\t epsilon: 0.01\n",
      "episode: 493\t steps: 00391\t total steps:794753\t epsilon: 0.01\n",
      "episode: 494\t steps: 00433\t total steps:795185\t epsilon: 0.01\n",
      "episode: 495\t steps: 00373\t total steps:795557\t epsilon: 0.01\n",
      "episode: 496\t steps: 00777\t total steps:796333\t epsilon: 0.01\n",
      "episode: 497\t steps: 00629\t total steps:796961\t epsilon: 0.01\n",
      "episode: 498\t steps: 01409\t total steps:798369\t epsilon: 0.01\n",
      "episode: 499\t steps: 02321\t total steps:800689\t epsilon: 0.01\n",
      "episode: 500\t steps: 00637\t total steps:801325\t epsilon: 0.01\n",
      "Evaluation: 10\t average reward: -10000.0\n",
      "episode: 501\t steps: 00899\t total steps:802223\t epsilon: 0.01\n",
      "episode: 502\t steps: 01121\t total steps:803343\t epsilon: 0.01\n",
      "episode: 503\t steps: 00309\t total steps:803651\t epsilon: 0.01\n",
      "episode: 504\t steps: 01179\t total steps:804829\t epsilon: 0.01\n",
      "episode: 505\t steps: 02145\t total steps:806973\t epsilon: 0.01\n",
      "episode: 506\t steps: 00549\t total steps:807521\t epsilon: 0.01\n",
      "episode: 507\t steps: 00241\t total steps:807761\t epsilon: 0.01\n",
      "episode: 508\t steps: 01385\t total steps:809145\t epsilon: 0.01\n",
      "episode: 509\t steps: 00903\t total steps:810047\t epsilon: 0.01\n",
      "episode: 510\t steps: 01347\t total steps:811393\t epsilon: 0.01\n",
      "episode: 511\t steps: 00693\t total steps:812085\t epsilon: 0.01\n",
      "episode: 512\t steps: 01011\t total steps:813095\t epsilon: 0.01\n",
      "episode: 513\t steps: 00937\t total steps:814031\t epsilon: 0.01\n",
      "episode: 514\t steps: 00413\t total steps:814443\t epsilon: 0.01\n",
      "episode: 515\t steps: 01487\t total steps:815929\t epsilon: 0.01\n",
      "episode: 516\t steps: 00393\t total steps:816321\t epsilon: 0.01\n",
      "episode: 517\t steps: 00571\t total steps:816891\t epsilon: 0.01\n",
      "episode: 518\t steps: 01055\t total steps:817945\t epsilon: 0.01\n",
      "episode: 519\t steps: 01571\t total steps:819515\t epsilon: 0.01\n",
      "episode: 520\t steps: 01087\t total steps:820601\t epsilon: 0.01\n",
      "episode: 521\t steps: 00767\t total steps:821367\t epsilon: 0.01\n",
      "episode: 522\t steps: 00511\t total steps:821877\t epsilon: 0.01\n",
      "episode: 523\t steps: 01527\t total steps:823403\t epsilon: 0.01\n",
      "episode: 524\t steps: 00491\t total steps:823893\t epsilon: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 525\t steps: 01105\t total steps:824997\t epsilon: 0.01\n",
      "episode: 526\t steps: 04251\t total steps:829247\t epsilon: 0.01\n",
      "episode: 527\t steps: 00225\t total steps:829471\t epsilon: 0.01\n",
      "episode: 528\t steps: 00465\t total steps:829935\t epsilon: 0.01\n",
      "episode: 529\t steps: 00795\t total steps:830729\t epsilon: 0.01\n",
      "episode: 530\t steps: 01117\t total steps:831845\t epsilon: 0.01\n",
      "episode: 531\t steps: 00377\t total steps:832221\t epsilon: 0.01\n",
      "episode: 532\t steps: 00669\t total steps:832889\t epsilon: 0.01\n",
      "episode: 533\t steps: 02139\t total steps:835027\t epsilon: 0.01\n",
      "episode: 534\t steps: 00523\t total steps:835549\t epsilon: 0.01\n",
      "episode: 535\t steps: 00295\t total steps:835843\t epsilon: 0.01\n",
      "episode: 536\t steps: 01139\t total steps:836981\t epsilon: 0.01\n",
      "episode: 537\t steps: 01143\t total steps:838123\t epsilon: 0.01\n",
      "episode: 538\t steps: 01037\t total steps:839159\t epsilon: 0.01\n",
      "episode: 539\t steps: 00559\t total steps:839717\t epsilon: 0.01\n",
      "episode: 540\t steps: 00617\t total steps:840333\t epsilon: 0.01\n",
      "episode: 541\t steps: 01133\t total steps:841465\t epsilon: 0.01\n",
      "episode: 542\t steps: 00367\t total steps:841831\t epsilon: 0.01\n",
      "episode: 543\t steps: 00659\t total steps:842489\t epsilon: 0.01\n",
      "episode: 544\t steps: 00717\t total steps:843205\t epsilon: 0.01\n",
      "episode: 545\t steps: 00491\t total steps:843695\t epsilon: 0.01\n",
      "episode: 546\t steps: 00733\t total steps:844427\t epsilon: 0.01\n",
      "episode: 547\t steps: 00415\t total steps:844841\t epsilon: 0.01\n",
      "episode: 548\t steps: 00373\t total steps:845213\t epsilon: 0.01\n",
      "episode: 549\t steps: 01753\t total steps:846965\t epsilon: 0.01\n",
      "episode: 550\t steps: 01613\t total steps:848577\t epsilon: 0.01\n",
      "Evaluation: 11\t average reward: -10000.0\n",
      "episode: 551\t steps: 01287\t total steps:849863\t epsilon: 0.01\n",
      "episode: 552\t steps: 00663\t total steps:850525\t epsilon: 0.01\n",
      "episode: 553\t steps: 00739\t total steps:851263\t epsilon: 0.01\n",
      "episode: 554\t steps: 00929\t total steps:852191\t epsilon: 0.01\n",
      "episode: 555\t steps: 00763\t total steps:852953\t epsilon: 0.01\n",
      "episode: 556\t steps: 01507\t total steps:854459\t epsilon: 0.01\n",
      "episode: 557\t steps: 02505\t total steps:856963\t epsilon: 0.01\n",
      "episode: 558\t steps: 01919\t total steps:858881\t epsilon: 0.01\n",
      "episode: 559\t steps: 00573\t total steps:859453\t epsilon: 0.01\n",
      "episode: 560\t steps: 00973\t total steps:860425\t epsilon: 0.01\n",
      "episode: 561\t steps: 00689\t total steps:861113\t epsilon: 0.01\n",
      "episode: 562\t steps: 00361\t total steps:861473\t epsilon: 0.01\n",
      "episode: 563\t steps: 00857\t total steps:862329\t epsilon: 0.01\n",
      "episode: 564\t steps: 00531\t total steps:862859\t epsilon: 0.01\n",
      "episode: 565\t steps: 00861\t total steps:863719\t epsilon: 0.01\n",
      "episode: 566\t steps: 01363\t total steps:865081\t epsilon: 0.01\n",
      "episode: 567\t steps: 01121\t total steps:866201\t epsilon: 0.01\n",
      "episode: 568\t steps: 00787\t total steps:866987\t epsilon: 0.01\n",
      "episode: 569\t steps: 00395\t total steps:867381\t epsilon: 0.01\n",
      "episode: 570\t steps: 00597\t total steps:867977\t epsilon: 0.01\n",
      "episode: 571\t steps: 00957\t total steps:868933\t epsilon: 0.01\n",
      "episode: 572\t steps: 01875\t total steps:870807\t epsilon: 0.01\n",
      "episode: 573\t steps: 01087\t total steps:871893\t epsilon: 0.01\n",
      "episode: 574\t steps: 00203\t total steps:872095\t epsilon: 0.01\n",
      "episode: 575\t steps: 00241\t total steps:872335\t epsilon: 0.01\n",
      "episode: 576\t steps: 02019\t total steps:874353\t epsilon: 0.01\n",
      "episode: 577\t steps: 00601\t total steps:874953\t epsilon: 0.01\n",
      "episode: 578\t steps: 00479\t total steps:875431\t epsilon: 0.01\n",
      "episode: 579\t steps: 00369\t total steps:875799\t epsilon: 0.01\n",
      "episode: 580\t steps: 01331\t total steps:877129\t epsilon: 0.01\n",
      "episode: 581\t steps: 01397\t total steps:878525\t epsilon: 0.01\n",
      "episode: 582\t steps: 01479\t total steps:880003\t epsilon: 0.01\n",
      "episode: 583\t steps: 01023\t total steps:881025\t epsilon: 0.01\n",
      "episode: 584\t steps: 00533\t total steps:881557\t epsilon: 0.01\n",
      "episode: 585\t steps: 00213\t total steps:881769\t epsilon: 0.01\n",
      "episode: 586\t steps: 00417\t total steps:882185\t epsilon: 0.01\n",
      "episode: 587\t steps: 00593\t total steps:882777\t epsilon: 0.01\n",
      "episode: 588\t steps: 00425\t total steps:883201\t epsilon: 0.01\n",
      "episode: 589\t steps: 00447\t total steps:883647\t epsilon: 0.01\n",
      "episode: 590\t steps: 00523\t total steps:884169\t epsilon: 0.01\n",
      "episode: 591\t steps: 00639\t total steps:884807\t epsilon: 0.01\n",
      "episode: 592\t steps: 00843\t total steps:885649\t epsilon: 0.01\n",
      "episode: 593\t steps: 00383\t total steps:886031\t epsilon: 0.01\n",
      "episode: 594\t steps: 00539\t total steps:886569\t epsilon: 0.01\n",
      "episode: 595\t steps: 01299\t total steps:887867\t epsilon: 0.01\n",
      "episode: 596\t steps: 00775\t total steps:888641\t epsilon: 0.01\n",
      "episode: 597\t steps: 00931\t total steps:889571\t epsilon: 0.01\n",
      "episode: 598\t steps: 00323\t total steps:889893\t epsilon: 0.01\n",
      "episode: 599\t steps: 01311\t total steps:891203\t epsilon: 0.01\n",
      "episode: 600\t steps: 00689\t total steps:891891\t epsilon: 0.01\n",
      "Evaluation: 12\t average reward: -10000.0\n",
      "episode: 601\t steps: 00617\t total steps:892507\t epsilon: 0.01\n",
      "episode: 602\t steps: 00341\t total steps:892847\t epsilon: 0.01\n",
      "episode: 603\t steps: 00843\t total steps:893689\t epsilon: 0.01\n",
      "episode: 604\t steps: 00925\t total steps:894613\t epsilon: 0.01\n",
      "episode: 605\t steps: 00929\t total steps:895541\t epsilon: 0.01\n",
      "episode: 606\t steps: 00343\t total steps:895883\t epsilon: 0.01\n",
      "episode: 607\t steps: 02117\t total steps:897999\t epsilon: 0.01\n",
      "episode: 608\t steps: 00929\t total steps:898927\t epsilon: 0.01\n",
      "episode: 609\t steps: 00243\t total steps:899169\t epsilon: 0.01\n",
      "episode: 610\t steps: 00777\t total steps:899945\t epsilon: 0.01\n",
      "episode: 611\t steps: 00831\t total steps:900775\t epsilon: 0.01\n",
      "episode: 612\t steps: 01023\t total steps:901797\t epsilon: 0.01\n",
      "episode: 613\t steps: 01521\t total steps:903317\t epsilon: 0.01\n",
      "episode: 614\t steps: 00479\t total steps:903795\t epsilon: 0.01\n",
      "episode: 615\t steps: 00539\t total steps:904333\t epsilon: 0.01\n",
      "episode: 616\t steps: 00211\t total steps:904543\t epsilon: 0.01\n",
      "episode: 617\t steps: 00891\t total steps:905433\t epsilon: 0.01\n",
      "episode: 618\t steps: 00737\t total steps:906169\t epsilon: 0.01\n",
      "episode: 619\t steps: 02031\t total steps:908199\t epsilon: 0.01\n",
      "episode: 620\t steps: 00395\t total steps:908593\t epsilon: 0.01\n",
      "episode: 621\t steps: 01289\t total steps:909881\t epsilon: 0.01\n",
      "episode: 622\t steps: 02655\t total steps:912535\t epsilon: 0.01\n",
      "episode: 623\t steps: 02121\t total steps:914655\t epsilon: 0.01\n",
      "episode: 624\t steps: 00417\t total steps:915071\t epsilon: 0.01\n",
      "episode: 625\t steps: 01305\t total steps:916375\t epsilon: 0.01\n",
      "episode: 626\t steps: 00819\t total steps:917193\t epsilon: 0.01\n",
      "episode: 627\t steps: 00273\t total steps:917465\t epsilon: 0.01\n",
      "episode: 628\t steps: 01033\t total steps:918497\t epsilon: 0.01\n",
      "episode: 629\t steps: 01201\t total steps:919697\t epsilon: 0.01\n",
      "episode: 630\t steps: 01293\t total steps:920989\t epsilon: 0.01\n",
      "episode: 631\t steps: 01671\t total steps:922659\t epsilon: 0.01\n",
      "episode: 632\t steps: 00251\t total steps:922909\t epsilon: 0.01\n",
      "episode: 633\t steps: 02311\t total steps:925219\t epsilon: 0.01\n",
      "episode: 634\t steps: 00945\t total steps:926163\t epsilon: 0.01\n",
      "episode: 635\t steps: 00573\t total steps:926735\t epsilon: 0.01\n",
      "episode: 636\t steps: 02075\t total steps:928809\t epsilon: 0.01\n",
      "episode: 637\t steps: 00971\t total steps:929779\t epsilon: 0.01\n",
      "episode: 638\t steps: 00245\t total steps:930023\t epsilon: 0.01\n",
      "episode: 639\t steps: 03091\t total steps:933113\t epsilon: 0.01\n",
      "episode: 640\t steps: 01719\t total steps:934831\t epsilon: 0.01\n",
      "episode: 641\t steps: 01119\t total steps:935949\t epsilon: 0.01\n",
      "episode: 642\t steps: 01221\t total steps:937169\t epsilon: 0.01\n",
      "episode: 643\t steps: 00367\t total steps:937535\t epsilon: 0.01\n",
      "episode: 644\t steps: 01295\t total steps:938829\t epsilon: 0.01\n",
      "episode: 645\t steps: 01791\t total steps:940619\t epsilon: 0.01\n",
      "episode: 646\t steps: 00781\t total steps:941399\t epsilon: 0.01\n",
      "episode: 647\t steps: 00567\t total steps:941965\t epsilon: 0.01\n",
      "episode: 648\t steps: 02129\t total steps:944093\t epsilon: 0.01\n",
      "episode: 649\t steps: 00507\t total steps:944599\t epsilon: 0.01\n",
      "episode: 650\t steps: 00305\t total steps:944903\t epsilon: 0.01\n",
      "Evaluation: 13\t average reward: -10000.0\n",
      "episode: 651\t steps: 02011\t total steps:946913\t epsilon: 0.01\n",
      "episode: 652\t steps: 00887\t total steps:947799\t epsilon: 0.01\n",
      "episode: 653\t steps: 00509\t total steps:948307\t epsilon: 0.01\n",
      "episode: 654\t steps: 00651\t total steps:948957\t epsilon: 0.01\n",
      "episode: 655\t steps: 00723\t total steps:949679\t epsilon: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 656\t steps: 00547\t total steps:950225\t epsilon: 0.01\n",
      "episode: 657\t steps: 00835\t total steps:951059\t epsilon: 0.01\n",
      "episode: 658\t steps: 01695\t total steps:952753\t epsilon: 0.01\n",
      "episode: 659\t steps: 00515\t total steps:953267\t epsilon: 0.01\n",
      "episode: 660\t steps: 00723\t total steps:953989\t epsilon: 0.01\n",
      "episode: 661\t steps: 00783\t total steps:954771\t epsilon: 0.01\n",
      "episode: 662\t steps: 00939\t total steps:955709\t epsilon: 0.01\n",
      "episode: 663\t steps: 00321\t total steps:956029\t epsilon: 0.01\n",
      "episode: 664\t steps: 00481\t total steps:956509\t epsilon: 0.01\n",
      "episode: 665\t steps: 01047\t total steps:957555\t epsilon: 0.01\n",
      "episode: 666\t steps: 00491\t total steps:958045\t epsilon: 0.01\n",
      "episode: 667\t steps: 00381\t total steps:958425\t epsilon: 0.01\n",
      "episode: 668\t steps: 00259\t total steps:958683\t epsilon: 0.01\n",
      "episode: 669\t steps: 00431\t total steps:959113\t epsilon: 0.01\n",
      "episode: 670\t steps: 01709\t total steps:960821\t epsilon: 0.01\n",
      "episode: 671\t steps: 00205\t total steps:961025\t epsilon: 0.01\n",
      "episode: 672\t steps: 00713\t total steps:961737\t epsilon: 0.01\n",
      "episode: 673\t steps: 02493\t total steps:964229\t epsilon: 0.01\n",
      "episode: 674\t steps: 00311\t total steps:964539\t epsilon: 0.01\n",
      "episode: 675\t steps: 00431\t total steps:964969\t epsilon: 0.01\n",
      "episode: 676\t steps: 01021\t total steps:965989\t epsilon: 0.01\n",
      "episode: 677\t steps: 00789\t total steps:966777\t epsilon: 0.01\n",
      "episode: 678\t steps: 00779\t total steps:967555\t epsilon: 0.01\n",
      "episode: 679\t steps: 01153\t total steps:968707\t epsilon: 0.01\n",
      "episode: 680\t steps: 01355\t total steps:970061\t epsilon: 0.01\n",
      "episode: 681\t steps: 00825\t total steps:970885\t epsilon: 0.01\n",
      "episode: 682\t steps: 00971\t total steps:971855\t epsilon: 0.01\n",
      "episode: 683\t steps: 00601\t total steps:972455\t epsilon: 0.01\n",
      "episode: 684\t steps: 00353\t total steps:972807\t epsilon: 0.01\n",
      "episode: 685\t steps: 01535\t total steps:974341\t epsilon: 0.01\n",
      "episode: 686\t steps: 03507\t total steps:977847\t epsilon: 0.01\n",
      "episode: 687\t steps: 00609\t total steps:978455\t epsilon: 0.01\n",
      "episode: 688\t steps: 01343\t total steps:979797\t epsilon: 0.01\n",
      "episode: 689\t steps: 00743\t total steps:980539\t epsilon: 0.01\n",
      "episode: 690\t steps: 00651\t total steps:981189\t epsilon: 0.01\n",
      "episode: 691\t steps: 00681\t total steps:981869\t epsilon: 0.01\n",
      "episode: 692\t steps: 00491\t total steps:982359\t epsilon: 0.01\n",
      "episode: 693\t steps: 01161\t total steps:983519\t epsilon: 0.01\n",
      "episode: 694\t steps: 00577\t total steps:984095\t epsilon: 0.01\n",
      "episode: 695\t steps: 00805\t total steps:984899\t epsilon: 0.01\n",
      "episode: 696\t steps: 00401\t total steps:985299\t epsilon: 0.01\n",
      "episode: 697\t steps: 01707\t total steps:987005\t epsilon: 0.01\n",
      "episode: 698\t steps: 00569\t total steps:987573\t epsilon: 0.01\n",
      "episode: 699\t steps: 00519\t total steps:988091\t epsilon: 0.01\n",
      "episode: 700\t steps: 01433\t total steps:989523\t epsilon: 0.01\n",
      "Evaluation: 14\t average reward: -10000.0\n",
      "episode: 701\t steps: 03531\t total steps:993053\t epsilon: 0.01\n",
      "episode: 702\t steps: 01261\t total steps:994313\t epsilon: 0.01\n",
      "episode: 703\t steps: 00683\t total steps:994995\t epsilon: 0.01\n",
      "episode: 704\t steps: 00345\t total steps:995339\t epsilon: 0.01\n",
      "episode: 705\t steps: 00853\t total steps:996191\t epsilon: 0.01\n",
      "episode: 706\t steps: 00981\t total steps:997171\t epsilon: 0.01\n",
      "episode: 707\t steps: 00735\t total steps:997905\t epsilon: 0.01\n",
      "episode: 708\t steps: 00403\t total steps:998307\t epsilon: 0.01\n",
      "episode: 709\t steps: 00713\t total steps:999019\t epsilon: 0.01\n",
      "episode: 710\t steps: 01395\t total steps:1000413\t epsilon: 0.01\n",
      "episode: 711\t steps: 01123\t total steps:1001535\t epsilon: 0.01\n",
      "episode: 712\t steps: 00733\t total steps:1002267\t epsilon: 0.01\n",
      "episode: 713\t steps: 01213\t total steps:1003479\t epsilon: 0.01\n",
      "episode: 714\t steps: 03713\t total steps:1007191\t epsilon: 0.01\n",
      "episode: 715\t steps: 00405\t total steps:1007595\t epsilon: 0.01\n",
      "episode: 716\t steps: 01307\t total steps:1008901\t epsilon: 0.01\n",
      "episode: 717\t steps: 00475\t total steps:1009375\t epsilon: 0.01\n",
      "episode: 718\t steps: 01569\t total steps:1010943\t epsilon: 0.01\n",
      "episode: 719\t steps: 01561\t total steps:1012503\t epsilon: 0.01\n",
      "episode: 720\t steps: 01001\t total steps:1013503\t epsilon: 0.01\n",
      "episode: 721\t steps: 00807\t total steps:1014309\t epsilon: 0.01\n",
      "episode: 722\t steps: 00935\t total steps:1015243\t epsilon: 0.01\n",
      "episode: 723\t steps: 00757\t total steps:1015999\t epsilon: 0.01\n",
      "episode: 724\t steps: 00803\t total steps:1016801\t epsilon: 0.01\n",
      "episode: 725\t steps: 01251\t total steps:1018051\t epsilon: 0.01\n",
      "episode: 726\t steps: 00741\t total steps:1018791\t epsilon: 0.01\n",
      "episode: 727\t steps: 00349\t total steps:1019139\t epsilon: 0.01\n",
      "episode: 728\t steps: 00971\t total steps:1020109\t epsilon: 0.01\n",
      "episode: 729\t steps: 00729\t total steps:1020837\t epsilon: 0.01\n",
      "episode: 730\t steps: 00429\t total steps:1021265\t epsilon: 0.01\n",
      "episode: 731\t steps: 00223\t total steps:1021487\t epsilon: 0.01\n",
      "episode: 732\t steps: 01409\t total steps:1022895\t epsilon: 0.01\n",
      "episode: 733\t steps: 00305\t total steps:1023199\t epsilon: 0.01\n",
      "episode: 734\t steps: 01625\t total steps:1024823\t epsilon: 0.01\n",
      "episode: 735\t steps: 01215\t total steps:1026037\t epsilon: 0.01\n",
      "episode: 736\t steps: 02253\t total steps:1028289\t epsilon: 0.01\n",
      "episode: 737\t steps: 01061\t total steps:1029349\t epsilon: 0.01\n",
      "episode: 738\t steps: 02049\t total steps:1031397\t epsilon: 0.01\n",
      "episode: 739\t steps: 01031\t total steps:1032427\t epsilon: 0.01\n",
      "episode: 740\t steps: 00701\t total steps:1033127\t epsilon: 0.01\n",
      "episode: 741\t steps: 01597\t total steps:1034723\t epsilon: 0.01\n",
      "episode: 742\t steps: 01877\t total steps:1036599\t epsilon: 0.01\n",
      "episode: 743\t steps: 01193\t total steps:1037791\t epsilon: 0.01\n",
      "episode: 744\t steps: 00575\t total steps:1038365\t epsilon: 0.01\n",
      "episode: 745\t steps: 00707\t total steps:1039071\t epsilon: 0.01\n",
      "episode: 746\t steps: 00911\t total steps:1039981\t epsilon: 0.01\n",
      "episode: 747\t steps: 01997\t total steps:1041977\t epsilon: 0.01\n",
      "episode: 748\t steps: 00565\t total steps:1042541\t epsilon: 0.01\n",
      "episode: 749\t steps: 01349\t total steps:1043889\t epsilon: 0.01\n",
      "episode: 750\t steps: 00623\t total steps:1044511\t epsilon: 0.01\n",
      "Evaluation: 15\t average reward: -10000.0\n",
      "episode: 751\t steps: 00433\t total steps:1044943\t epsilon: 0.01\n",
      "episode: 752\t steps: 01035\t total steps:1045977\t epsilon: 0.01\n",
      "episode: 753\t steps: 00475\t total steps:1046451\t epsilon: 0.01\n",
      "episode: 754\t steps: 00425\t total steps:1046875\t epsilon: 0.01\n",
      "episode: 755\t steps: 01555\t total steps:1048429\t epsilon: 0.01\n",
      "episode: 756\t steps: 00591\t total steps:1049019\t epsilon: 0.01\n",
      "episode: 757\t steps: 01393\t total steps:1050411\t epsilon: 0.01\n",
      "episode: 758\t steps: 00529\t total steps:1050939\t epsilon: 0.01\n",
      "episode: 759\t steps: 01725\t total steps:1052663\t epsilon: 0.01\n",
      "episode: 760\t steps: 01591\t total steps:1054253\t epsilon: 0.01\n",
      "episode: 761\t steps: 00495\t total steps:1054747\t epsilon: 0.01\n",
      "episode: 762\t steps: 00257\t total steps:1055003\t epsilon: 0.01\n",
      "episode: 763\t steps: 00459\t total steps:1055461\t epsilon: 0.01\n",
      "episode: 764\t steps: 00727\t total steps:1056187\t epsilon: 0.01\n",
      "episode: 765\t steps: 00709\t total steps:1056895\t epsilon: 0.01\n",
      "episode: 766\t steps: 01149\t total steps:1058043\t epsilon: 0.01\n",
      "episode: 767\t steps: 03159\t total steps:1061201\t epsilon: 0.01\n",
      "episode: 768\t steps: 00523\t total steps:1061723\t epsilon: 0.01\n",
      "episode: 769\t steps: 01553\t total steps:1063275\t epsilon: 0.01\n",
      "episode: 770\t steps: 00495\t total steps:1063769\t epsilon: 0.01\n",
      "episode: 771\t steps: 02139\t total steps:1065907\t epsilon: 0.01\n",
      "episode: 772\t steps: 00609\t total steps:1066515\t epsilon: 0.01\n",
      "episode: 773\t steps: 01579\t total steps:1068093\t epsilon: 0.01\n",
      "episode: 774\t steps: 00869\t total steps:1068961\t epsilon: 0.01\n",
      "episode: 775\t steps: 00365\t total steps:1069325\t epsilon: 0.01\n",
      "episode: 776\t steps: 00937\t total steps:1070261\t epsilon: 0.01\n",
      "episode: 777\t steps: 01115\t total steps:1071375\t epsilon: 0.01\n",
      "episode: 778\t steps: 00961\t total steps:1072335\t epsilon: 0.01\n",
      "episode: 779\t steps: 00961\t total steps:1073295\t epsilon: 0.01\n",
      "episode: 780\t steps: 01083\t total steps:1074377\t epsilon: 0.01\n",
      "episode: 781\t steps: 00849\t total steps:1075225\t epsilon: 0.01\n",
      "episode: 782\t steps: 00693\t total steps:1075917\t epsilon: 0.01\n",
      "episode: 783\t steps: 00581\t total steps:1076497\t epsilon: 0.01\n",
      "episode: 784\t steps: 00651\t total steps:1077147\t epsilon: 0.01\n",
      "episode: 785\t steps: 00747\t total steps:1077893\t epsilon: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 786\t steps: 02265\t total steps:1080157\t epsilon: 0.01\n",
      "episode: 787\t steps: 00439\t total steps:1080595\t epsilon: 0.01\n",
      "episode: 788\t steps: 00821\t total steps:1081415\t epsilon: 0.01\n",
      "episode: 789\t steps: 01659\t total steps:1083073\t epsilon: 0.01\n",
      "episode: 790\t steps: 01535\t total steps:1084607\t epsilon: 0.01\n",
      "episode: 791\t steps: 01427\t total steps:1086033\t epsilon: 0.01\n",
      "episode: 792\t steps: 01175\t total steps:1087207\t epsilon: 0.01\n",
      "episode: 793\t steps: 00387\t total steps:1087593\t epsilon: 0.01\n",
      "episode: 794\t steps: 01417\t total steps:1089009\t epsilon: 0.01\n",
      "episode: 795\t steps: 02871\t total steps:1091879\t epsilon: 0.01\n",
      "episode: 796\t steps: 01039\t total steps:1092917\t epsilon: 0.01\n",
      "episode: 797\t steps: 01221\t total steps:1094137\t epsilon: 0.01\n",
      "episode: 798\t steps: 00387\t total steps:1094523\t epsilon: 0.01\n",
      "episode: 799\t steps: 00583\t total steps:1095105\t epsilon: 0.01\n",
      "episode: 800\t steps: 01203\t total steps:1096307\t epsilon: 0.01\n",
      "Evaluation: 16\t average reward: -10000.0\n",
      "episode: 801\t steps: 00373\t total steps:1096679\t epsilon: 0.01\n",
      "episode: 802\t steps: 02067\t total steps:1098745\t epsilon: 0.01\n",
      "episode: 803\t steps: 02345\t total steps:1101089\t epsilon: 0.01\n",
      "episode: 804\t steps: 00393\t total steps:1101481\t epsilon: 0.01\n",
      "episode: 805\t steps: 00433\t total steps:1101913\t epsilon: 0.01\n",
      "episode: 806\t steps: 01737\t total steps:1103649\t epsilon: 0.01\n",
      "episode: 807\t steps: 00391\t total steps:1104039\t epsilon: 0.01\n",
      "episode: 808\t steps: 01145\t total steps:1105183\t epsilon: 0.01\n",
      "episode: 809\t steps: 01857\t total steps:1107039\t epsilon: 0.01\n",
      "episode: 810\t steps: 00351\t total steps:1107389\t epsilon: 0.01\n",
      "episode: 811\t steps: 01835\t total steps:1109223\t epsilon: 0.01\n",
      "episode: 812\t steps: 00299\t total steps:1109521\t epsilon: 0.01\n",
      "episode: 813\t steps: 00443\t total steps:1109963\t epsilon: 0.01\n",
      "episode: 814\t steps: 01603\t total steps:1111565\t epsilon: 0.01\n",
      "episode: 815\t steps: 00239\t total steps:1111803\t epsilon: 0.01\n",
      "episode: 816\t steps: 00179\t total steps:1111981\t epsilon: 0.01\n",
      "episode: 817\t steps: 00791\t total steps:1112771\t epsilon: 0.01\n",
      "episode: 818\t steps: 01645\t total steps:1114415\t epsilon: 0.01\n",
      "episode: 819\t steps: 01451\t total steps:1115865\t epsilon: 0.01\n",
      "episode: 820\t steps: 02347\t total steps:1118211\t epsilon: 0.01\n",
      "episode: 821\t steps: 00889\t total steps:1119099\t epsilon: 0.01\n",
      "episode: 822\t steps: 00679\t total steps:1119777\t epsilon: 0.01\n",
      "episode: 823\t steps: 00587\t total steps:1120363\t epsilon: 0.01\n",
      "episode: 824\t steps: 00227\t total steps:1120589\t epsilon: 0.01\n",
      "episode: 825\t steps: 02617\t total steps:1123205\t epsilon: 0.01\n",
      "episode: 826\t steps: 00767\t total steps:1123971\t epsilon: 0.01\n",
      "episode: 827\t steps: 00981\t total steps:1124951\t epsilon: 0.01\n",
      "episode: 828\t steps: 00433\t total steps:1125383\t epsilon: 0.01\n",
      "episode: 829\t steps: 00235\t total steps:1125617\t epsilon: 0.01\n",
      "episode: 830\t steps: 02031\t total steps:1127647\t epsilon: 0.01\n",
      "episode: 831\t steps: 01013\t total steps:1128659\t epsilon: 0.01\n",
      "episode: 832\t steps: 03993\t total steps:1132651\t epsilon: 0.01\n",
      "episode: 833\t steps: 00471\t total steps:1133121\t epsilon: 0.01\n",
      "episode: 834\t steps: 00453\t total steps:1133573\t epsilon: 0.01\n",
      "episode: 835\t steps: 01461\t total steps:1135033\t epsilon: 0.01\n",
      "episode: 836\t steps: 01713\t total steps:1136745\t epsilon: 0.01\n",
      "episode: 837\t steps: 00713\t total steps:1137457\t epsilon: 0.01\n",
      "episode: 838\t steps: 01857\t total steps:1139313\t epsilon: 0.01\n",
      "episode: 839\t steps: 01761\t total steps:1141073\t epsilon: 0.01\n",
      "episode: 840\t steps: 00261\t total steps:1141333\t epsilon: 0.01\n",
      "episode: 841\t steps: 01895\t total steps:1143227\t epsilon: 0.01\n",
      "episode: 842\t steps: 03493\t total steps:1146719\t epsilon: 0.01\n",
      "episode: 843\t steps: 00891\t total steps:1147609\t epsilon: 0.01\n",
      "episode: 844\t steps: 00761\t total steps:1148369\t epsilon: 0.01\n",
      "episode: 845\t steps: 00321\t total steps:1148689\t epsilon: 0.01\n",
      "episode: 846\t steps: 00341\t total steps:1149029\t epsilon: 0.01\n",
      "episode: 847\t steps: 00465\t total steps:1149493\t epsilon: 0.01\n",
      "episode: 848\t steps: 00189\t total steps:1149681\t epsilon: 0.01\n",
      "episode: 849\t steps: 00653\t total steps:1150333\t epsilon: 0.01\n",
      "episode: 850\t steps: 00369\t total steps:1150701\t epsilon: 0.01\n",
      "Evaluation: 17\t average reward: -10000.0\n",
      "episode: 851\t steps: 01053\t total steps:1151753\t epsilon: 0.01\n",
      "episode: 852\t steps: 00673\t total steps:1152425\t epsilon: 0.01\n",
      "episode: 853\t steps: 01185\t total steps:1153609\t epsilon: 0.01\n",
      "episode: 854\t steps: 00633\t total steps:1154241\t epsilon: 0.01\n",
      "episode: 855\t steps: 01059\t total steps:1155299\t epsilon: 0.01\n",
      "episode: 856\t steps: 01637\t total steps:1156935\t epsilon: 0.01\n",
      "episode: 857\t steps: 00561\t total steps:1157495\t epsilon: 0.01\n",
      "episode: 858\t steps: 00227\t total steps:1157721\t epsilon: 0.01\n",
      "episode: 859\t steps: 00763\t total steps:1158483\t epsilon: 0.01\n",
      "episode: 860\t steps: 01987\t total steps:1160469\t epsilon: 0.01\n",
      "episode: 861\t steps: 01435\t total steps:1161903\t epsilon: 0.01\n",
      "episode: 862\t steps: 00439\t total steps:1162341\t epsilon: 0.01\n",
      "episode: 863\t steps: 00783\t total steps:1163123\t epsilon: 0.01\n",
      "episode: 864\t steps: 01521\t total steps:1164643\t epsilon: 0.01\n",
      "episode: 865\t steps: 02701\t total steps:1167343\t epsilon: 0.01\n",
      "episode: 866\t steps: 01589\t total steps:1168931\t epsilon: 0.01\n",
      "episode: 867\t steps: 01217\t total steps:1170147\t epsilon: 0.01\n",
      "episode: 868\t steps: 00857\t total steps:1171003\t epsilon: 0.01\n",
      "episode: 869\t steps: 01205\t total steps:1172207\t epsilon: 0.01\n",
      "episode: 870\t steps: 00455\t total steps:1172661\t epsilon: 0.01\n",
      "episode: 871\t steps: 00951\t total steps:1173611\t epsilon: 0.01\n",
      "episode: 872\t steps: 00177\t total steps:1173787\t epsilon: 0.01\n",
      "episode: 873\t steps: 00579\t total steps:1174365\t epsilon: 0.01\n",
      "episode: 874\t steps: 01693\t total steps:1176057\t epsilon: 0.01\n",
      "episode: 875\t steps: 00505\t total steps:1176561\t epsilon: 0.01\n",
      "episode: 876\t steps: 04027\t total steps:1180587\t epsilon: 0.01\n",
      "episode: 877\t steps: 01267\t total steps:1181853\t epsilon: 0.01\n",
      "episode: 878\t steps: 01111\t total steps:1182963\t epsilon: 0.01\n",
      "episode: 879\t steps: 00531\t total steps:1183493\t epsilon: 0.01\n",
      "episode: 880\t steps: 01229\t total steps:1184721\t epsilon: 0.01\n",
      "episode: 881\t steps: 00287\t total steps:1185007\t epsilon: 0.01\n",
      "episode: 882\t steps: 00731\t total steps:1185737\t epsilon: 0.01\n",
      "episode: 883\t steps: 01723\t total steps:1187459\t epsilon: 0.01\n",
      "episode: 884\t steps: 00739\t total steps:1188197\t epsilon: 0.01\n",
      "episode: 885\t steps: 00449\t total steps:1188645\t epsilon: 0.01\n",
      "episode: 886\t steps: 00897\t total steps:1189541\t epsilon: 0.01\n",
      "episode: 887\t steps: 01251\t total steps:1190791\t epsilon: 0.01\n",
      "episode: 888\t steps: 01425\t total steps:1192215\t epsilon: 0.01\n",
      "episode: 889\t steps: 00259\t total steps:1192473\t epsilon: 0.01\n",
      "episode: 890\t steps: 03227\t total steps:1195699\t epsilon: 0.01\n",
      "episode: 891\t steps: 00739\t total steps:1196437\t epsilon: 0.01\n",
      "episode: 892\t steps: 01297\t total steps:1197733\t epsilon: 0.01\n",
      "episode: 893\t steps: 01837\t total steps:1199569\t epsilon: 0.01\n",
      "episode: 894\t steps: 00765\t total steps:1200333\t epsilon: 0.01\n",
      "episode: 895\t steps: 02789\t total steps:1203121\t epsilon: 0.01\n",
      "episode: 896\t steps: 00881\t total steps:1204001\t epsilon: 0.01\n",
      "episode: 897\t steps: 03327\t total steps:1207327\t epsilon: 0.01\n",
      "episode: 898\t steps: 01827\t total steps:1209153\t epsilon: 0.01\n",
      "episode: 899\t steps: 00491\t total steps:1209643\t epsilon: 0.01\n",
      "episode: 900\t steps: 01181\t total steps:1210823\t epsilon: 0.01\n",
      "Evaluation: 18\t average reward: -10000.0\n",
      "episode: 901\t steps: 00241\t total steps:1211063\t epsilon: 0.01\n",
      "episode: 902\t steps: 00969\t total steps:1212031\t epsilon: 0.01\n",
      "episode: 903\t steps: 00411\t total steps:1212441\t epsilon: 0.01\n",
      "episode: 904\t steps: 00787\t total steps:1213227\t epsilon: 0.01\n",
      "episode: 905\t steps: 00693\t total steps:1213919\t epsilon: 0.01\n",
      "episode: 906\t steps: 00639\t total steps:1214557\t epsilon: 0.01\n",
      "episode: 907\t steps: 01213\t total steps:1215769\t epsilon: 0.01\n",
      "episode: 908\t steps: 01017\t total steps:1216785\t epsilon: 0.01\n",
      "episode: 909\t steps: 00391\t total steps:1217175\t epsilon: 0.01\n",
      "episode: 910\t steps: 00367\t total steps:1217541\t epsilon: 0.01\n",
      "episode: 911\t steps: 00289\t total steps:1217829\t epsilon: 0.01\n",
      "episode: 912\t steps: 00779\t total steps:1218607\t epsilon: 0.01\n",
      "episode: 913\t steps: 00687\t total steps:1219293\t epsilon: 0.01\n",
      "episode: 914\t steps: 00417\t total steps:1219709\t epsilon: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 915\t steps: 00571\t total steps:1220279\t epsilon: 0.01\n",
      "episode: 916\t steps: 01343\t total steps:1221621\t epsilon: 0.01\n",
      "episode: 917\t steps: 00737\t total steps:1222357\t epsilon: 0.01\n",
      "episode: 918\t steps: 00797\t total steps:1223153\t epsilon: 0.01\n",
      "episode: 919\t steps: 00649\t total steps:1223801\t epsilon: 0.01\n",
      "episode: 920\t steps: 00513\t total steps:1224313\t epsilon: 0.01\n",
      "episode: 921\t steps: 00289\t total steps:1224601\t epsilon: 0.01\n",
      "episode: 922\t steps: 00523\t total steps:1225123\t epsilon: 0.01\n",
      "episode: 923\t steps: 01841\t total steps:1226963\t epsilon: 0.01\n",
      "episode: 924\t steps: 00703\t total steps:1227665\t epsilon: 0.01\n",
      "episode: 925\t steps: 01087\t total steps:1228751\t epsilon: 0.01\n",
      "episode: 926\t steps: 01611\t total steps:1230361\t epsilon: 0.01\n",
      "episode: 927\t steps: 00919\t total steps:1231279\t epsilon: 0.01\n",
      "episode: 928\t steps: 01689\t total steps:1232967\t epsilon: 0.01\n",
      "episode: 929\t steps: 02349\t total steps:1235315\t epsilon: 0.01\n",
      "episode: 930\t steps: 00767\t total steps:1236081\t epsilon: 0.01\n",
      "episode: 931\t steps: 01777\t total steps:1237857\t epsilon: 0.01\n",
      "episode: 932\t steps: 01453\t total steps:1239309\t epsilon: 0.01\n",
      "episode: 933\t steps: 00215\t total steps:1239523\t epsilon: 0.01\n",
      "episode: 934\t steps: 02281\t total steps:1241803\t epsilon: 0.01\n",
      "episode: 935\t steps: 00427\t total steps:1242229\t epsilon: 0.01\n",
      "episode: 936\t steps: 00607\t total steps:1242835\t epsilon: 0.01\n",
      "episode: 937\t steps: 00785\t total steps:1243619\t epsilon: 0.01\n",
      "episode: 938\t steps: 00491\t total steps:1244109\t epsilon: 0.01\n",
      "episode: 939\t steps: 00253\t total steps:1244361\t epsilon: 0.01\n",
      "episode: 940\t steps: 01953\t total steps:1246313\t epsilon: 0.01\n",
      "episode: 941\t steps: 00277\t total steps:1246589\t epsilon: 0.01\n",
      "episode: 942\t steps: 00593\t total steps:1247181\t epsilon: 0.01\n",
      "episode: 943\t steps: 00659\t total steps:1247839\t epsilon: 0.01\n",
      "episode: 944\t steps: 03719\t total steps:1251557\t epsilon: 0.01\n",
      "episode: 945\t steps: 00293\t total steps:1251849\t epsilon: 0.01\n",
      "episode: 946\t steps: 01471\t total steps:1253319\t epsilon: 0.01\n",
      "episode: 947\t steps: 01111\t total steps:1254429\t epsilon: 0.01\n",
      "episode: 948\t steps: 00679\t total steps:1255107\t epsilon: 0.01\n",
      "episode: 949\t steps: 03579\t total steps:1258685\t epsilon: 0.01\n",
      "episode: 950\t steps: 00465\t total steps:1259149\t epsilon: 0.01\n",
      "Evaluation: 19\t average reward: -10000.0\n",
      "episode: 951\t steps: 01157\t total steps:1260305\t epsilon: 0.01\n",
      "episode: 952\t steps: 00505\t total steps:1260809\t epsilon: 0.01\n",
      "episode: 953\t steps: 01467\t total steps:1262275\t epsilon: 0.01\n",
      "episode: 954\t steps: 00411\t total steps:1262685\t epsilon: 0.01\n",
      "episode: 955\t steps: 00573\t total steps:1263257\t epsilon: 0.01\n",
      "episode: 956\t steps: 00359\t total steps:1263615\t epsilon: 0.01\n",
      "episode: 957\t steps: 00279\t total steps:1263893\t epsilon: 0.01\n",
      "episode: 958\t steps: 01175\t total steps:1265067\t epsilon: 0.01\n",
      "episode: 959\t steps: 02289\t total steps:1267355\t epsilon: 0.01\n",
      "episode: 960\t steps: 01705\t total steps:1269059\t epsilon: 0.01\n",
      "episode: 961\t steps: 00997\t total steps:1270055\t epsilon: 0.01\n",
      "episode: 962\t steps: 01999\t total steps:1272053\t epsilon: 0.01\n",
      "episode: 963\t steps: 00761\t total steps:1272813\t epsilon: 0.01\n",
      "episode: 964\t steps: 00911\t total steps:1273723\t epsilon: 0.01\n",
      "episode: 965\t steps: 00301\t total steps:1274023\t epsilon: 0.01\n",
      "episode: 966\t steps: 00657\t total steps:1274679\t epsilon: 0.01\n",
      "episode: 967\t steps: 01801\t total steps:1276479\t epsilon: 0.01\n",
      "episode: 968\t steps: 01673\t total steps:1278151\t epsilon: 0.01\n",
      "episode: 969\t steps: 00559\t total steps:1278709\t epsilon: 0.01\n",
      "episode: 970\t steps: 00721\t total steps:1279429\t epsilon: 0.01\n",
      "episode: 971\t steps: 03623\t total steps:1283051\t epsilon: 0.01\n",
      "episode: 972\t steps: 01669\t total steps:1284719\t epsilon: 0.01\n",
      "episode: 973\t steps: 01659\t total steps:1286377\t epsilon: 0.01\n",
      "episode: 974\t steps: 00637\t total steps:1287013\t epsilon: 0.01\n",
      "episode: 975\t steps: 00417\t total steps:1287429\t epsilon: 0.01\n",
      "episode: 976\t steps: 01447\t total steps:1288875\t epsilon: 0.01\n",
      "episode: 977\t steps: 01197\t total steps:1290071\t epsilon: 0.01\n",
      "episode: 978\t steps: 00523\t total steps:1290593\t epsilon: 0.01\n",
      "episode: 979\t steps: 00293\t total steps:1290885\t epsilon: 0.01\n",
      "episode: 980\t steps: 00747\t total steps:1291631\t epsilon: 0.01\n",
      "episode: 981\t steps: 00491\t total steps:1292121\t epsilon: 0.01\n",
      "episode: 982\t steps: 01587\t total steps:1293707\t epsilon: 0.01\n",
      "episode: 983\t steps: 01313\t total steps:1295019\t epsilon: 0.01\n",
      "episode: 984\t steps: 01023\t total steps:1296041\t epsilon: 0.01\n",
      "episode: 985\t steps: 00343\t total steps:1296383\t epsilon: 0.01\n",
      "episode: 986\t steps: 02165\t total steps:1298547\t epsilon: 0.01\n",
      "episode: 987\t steps: 02305\t total steps:1300851\t epsilon: 0.01\n",
      "episode: 988\t steps: 00507\t total steps:1301357\t epsilon: 0.01\n",
      "episode: 989\t steps: 01173\t total steps:1302529\t epsilon: 0.01\n",
      "episode: 990\t steps: 01413\t total steps:1303941\t epsilon: 0.01\n",
      "episode: 991\t steps: 00587\t total steps:1304527\t epsilon: 0.01\n",
      "episode: 992\t steps: 00693\t total steps:1305219\t epsilon: 0.01\n",
      "episode: 993\t steps: 01039\t total steps:1306257\t epsilon: 0.01\n",
      "episode: 994\t steps: 00395\t total steps:1306651\t epsilon: 0.01\n",
      "episode: 995\t steps: 01879\t total steps:1308529\t epsilon: 0.01\n",
      "episode: 996\t steps: 00753\t total steps:1309281\t epsilon: 0.01\n",
      "episode: 997\t steps: 01965\t total steps:1311245\t epsilon: 0.01\n",
      "episode: 998\t steps: 02917\t total steps:1314161\t epsilon: 0.01\n",
      "episode: 999\t steps: 02361\t total steps:1316521\t epsilon: 0.01\n",
      "Evaluation: 19\t average reward: -10000.0\n",
      "episode: 1000\t steps: 00547\t total steps:1317067\t epsilon: 0.01\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'q_measures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(best_policy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Prioritized_DDQN_MLP.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/steps_Prioritized_DDQN_MLP.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, total_steps_list)\n\u001b[0;32m---> 44\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/q_values_Prioritized_DDQN_MLP.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mq_measures\u001b[49m)\n\u001b[1;32m     45\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/eval_Prioritized_DDQN_MLP.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, evaluations)\n\u001b[1;32m     47\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(total_steps_list)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, total_steps_list, zorder\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluations\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_measures' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "n_training_episodes = 1000\n",
    "gamma = 0.99\n",
    "learning_rate = 0.00025/4  # 0.1\n",
    "max_training_steps = 10000\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon_max = 1\n",
    "epsilon_min = 0.01\n",
    "epsilon_frame = 500000\n",
    "\n",
    "# replay memory parameters\n",
    "replay_size = 100000\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# fixed target network\n",
    "fixed_target = True\n",
    "copy_target = 30000\n",
    "\n",
    "\n",
    "debug = True\n",
    "double = True\n",
    "prioritized = True\n",
    "\n",
    "env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "\n",
    "\n",
    "car = TrainMountainCar(n_training_episodes=n_training_episodes, gamma=gamma, learning_rate=learning_rate,\n",
    "                       epsilon_max=epsilon_max, epsilon_min=epsilon_min, epsilon_frame=epsilon_frame,\n",
    "                       max_steps=max_training_steps, batch_size=batch_size, fixed_target=fixed_target,\n",
    "                       copy_target=copy_target, replay_size=replay_size, double=double, prioritized=prioritized,\n",
    "                       debug=debug)\n",
    "\n",
    "total_rewards, total_steps_list, best_policy, evaluations = car.train()\n",
    "\n",
    "torch.save(best_policy, 'data/Prioritized_DDQN_MLP.pth')\n",
    "np.savetxt(f'data/steps_Prioritized_DDQN_MLP.txt', total_steps_list)\n",
    "np.savetxt(f'data/q_values_Prioritized_DDQN_MLP.txt', q_measures)\n",
    "np.savetxt(f'data/eval_Prioritized_DDQN_MLP.txt', evaluations)\n",
    "\n",
    "plt.plot(np.arange(len(total_steps_list)) + 1, total_steps_list, zorder=0, label='evaluations')\n",
    "x = np.arange(50, n_training_episodes+1, 50)\n",
    "plt.scatter(x, [-e for e in evaluations], color='r', marker='x', zorder=1, label='evaluations')\n",
    "N = 10\n",
    "steps_mean = running_mean(total_steps_list, N)\n",
    "plt.plot(np.arange(len(steps_mean)) + 1, steps_mean, zorder=0, label='running average')\n",
    "plt.legend()\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps')\n",
    "plt.title('Steps per Episode - Prioritized_DDQN_MLP')\n",
    "plt.savefig('plots/steps_Prioritized_DDQN_MLP.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a349d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
