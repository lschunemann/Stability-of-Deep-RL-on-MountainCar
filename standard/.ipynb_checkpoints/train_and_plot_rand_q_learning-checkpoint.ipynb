{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f97e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from helper import initialize_grids, initialize_q_table, initialize_state_dict, initialize_random_start, \\\n",
    "    epsilon_greedy_policy, get_closest_in_grid, plot_rewards, plot_steps, evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "def train(q, rand_init=True):\n",
    "    # Initialize variables to track rewards\n",
    "    reward_list = []\n",
    "    avg_reward_list = []\n",
    "    total_steps = []\n",
    "    file = open('trace/trace_train.txt', 'w')\n",
    "\n",
    "    for episode in range(n_training_episodes):\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "        state = env.reset()\n",
    "        if rand_init:\n",
    "            state = initialize_random_start(grid_x, grid_v)\n",
    "        steps = 0\n",
    "        tot_reward, reward = 0, 0\n",
    "        terminated = False\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            # Choose the action At using epsilon greedy policy\n",
    "            action = epsilon_greedy_policy(q, state, epsilon, grid_x, grid_v, state_to_qtable, env)\n",
    "\n",
    "            file.write(f'{state[0]},{state[1]},{action}\\n')\n",
    "\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            s = state_to_qtable[get_closest_in_grid(state, grid_x, grid_v)]\n",
    "            ns = state_to_qtable[get_closest_in_grid(new_state, grid_x, grid_v)]\n",
    "\n",
    "            # Calculate current learning rate\n",
    "            lr = max(min_lr, initial_lr * np.exp(-k * episode))\n",
    "\n",
    "            # Update Q table\n",
    "            q[s][action] = q[s][action] + lr * (reward + gamma * np.max(q[ns]) - q[s][action])\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            # If done, finish the episode\n",
    "            if terminated:  # or truncated:\n",
    "                total_steps.append(steps)\n",
    "                break\n",
    "\n",
    "            # Our state is the new state\n",
    "            state = new_state\n",
    "\n",
    "            # Update total reward\n",
    "            tot_reward += reward\n",
    "\n",
    "            # Track rewards\n",
    "            reward_list.append(tot_reward)\n",
    "\n",
    "        if (episode + 1) % 10 == 0:\n",
    "            avg_reward = np.mean(reward_list)\n",
    "            avg_reward_list.append(avg_reward)\n",
    "            reward_list = []\n",
    "            print(f\"episode: {episode}\\t average reward: {avg_reward}\\t avg steps: {np.mean(total_steps[-10:])}\"\n",
    "                  f\"\\t lr: {lr}\\t epsilon: {epsilon}\")\n",
    "\n",
    "    return q, avg_reward_list, total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8b58f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\lenna\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9\t average reward: -5000.5\t avg steps: nan\t lr: 0.19910202196591412\t epsilon: 0.9914883598342394\n",
      "episode: 19\t average reward: -4557.308114536639\t avg steps: 6863.0\t lr: 0.1981089964885801\t epsilon: 0.9821203941306657\n",
      "episode: 29\t average reward: -4365.029278453155\t avg steps: 5977.0\t lr: 0.1971209237464765\t epsilon: 0.9728456412432746\n",
      "episode: 39\t average reward: -3751.307521902795\t avg steps: 5594.1\t lr: 0.19613777903773325\t epsilon: 0.9636631736890484\n",
      "episode: 49\t average reward: -4739.215335731415\t avg steps: 4405.7\t lr: 0.19515953778368147\t epsilon: 0.9545720732135796\n",
      "episode: 59\t average reward: -3868.677663332836\t avg steps: 5098.3\t lr: 0.19418617552823886\t epsilon: 0.9455714306992448\n",
      "episode: 69\t average reward: -4235.458823688006\t avg steps: 5245.5\t lr: 0.19321766793729833\t epsilon: 0.9366603460742918\n",
      "episode: 79\t average reward: -3988.238947022798\t avg steps: 5752.9\t lr: 0.19225399079811967\t epsilon: 0.9278379282228324\n",
      "episode: 89\t average reward: -4052.8162255645493\t avg steps: 5597.0\t lr: 0.19129512001872417\t epsilon: 0.9191032948957294\n",
      "episode: 99\t average reward: -4189.602592404761\t avg steps: 5547.5\t lr: 0.19034103162729243\t epsilon: 0.9104555726223711\n",
      "episode: 109\t average reward: -3706.0918984280534\t avg steps: 6510.8\t lr: 0.18939170177156503\t epsilon: 0.9018938966233236\n",
      "episode: 119\t average reward: -3657.2682492683175\t avg steps: 5349.9\t lr: 0.18844710671824602\t epsilon: 0.8934174107238526\n",
      "episode: 129\t average reward: -3261.918599935107\t avg steps: 4928.4\t lr: 0.18750722285240995\t epsilon: 0.885025267268304\n",
      "episode: 139\t average reward: -2670.06067399123\t avg steps: 4060.4\t lr: 0.1865720266769112\t epsilon: 0.8767166270353389\n",
      "episode: 149\t average reward: -2668.852992610143\t avg steps: 2833.6\t lr: 0.1856414948117967\t epsilon: 0.8684906591540104\n",
      "episode: 159\t average reward: -2060.2051304784704\t avg steps: 3384.7\t lr: 0.1847156039937213\t epsilon: 0.860346541020675\n",
      "episode: 169\t average reward: -3375.321618788903\t avg steps: 3481.5\t lr: 0.18379433107536636\t epsilon: 0.8522834582167327\n",
      "episode: 179\t average reward: -2179.7830664810303\t avg steps: 3448.6\t lr: 0.18287765302486092\t epsilon: 0.8443006044271837\n",
      "episode: 189\t average reward: -1363.2883289865872\t avg steps: 2148.2\t lr: 0.181965546925206\t epsilon: 0.836397181359997\n",
      "episode: 199\t average reward: -1840.2697997174437\t avg steps: 2407.6\t lr: 0.1810579899737016\t epsilon: 0.8285723986662793\n",
      "episode: 209\t average reward: -2782.4717748323387\t avg steps: 3125.0\t lr: 0.18015495948137664\t epsilon: 0.8208254738612408\n",
      "episode: 219\t average reward: -1163.267492789232\t avg steps: 1873.2\t lr: 0.1792564328724218\t epsilon: 0.8131556322459452\n",
      "episode: 229\t average reward: -926.5178892023596\t avg steps: 1560.6\t lr: 0.17836238768362506\t epsilon: 0.8055621068298392\n",
      "episode: 239\t average reward: -1206.0060176125244\t avg steps: 2045.0\t lr: 0.1774728015638101\t epsilon: 0.7980441382540535\n",
      "episode: 249\t average reward: -764.797139786724\t avg steps: 1210.7\t lr: 0.17658765227327766\t epsilon: 0.7906009747154654\n",
      "episode: 259\t average reward: -1160.648498694517\t avg steps: 1839.4\t lr: 0.1757069176832493\t epsilon: 0.7832318718915182\n",
      "episode: 269\t average reward: -1220.6000385969992\t avg steps: 2073.7\t lr: 0.17483057577531444\t epsilon: 0.775936092865789\n",
      "episode: 279\t average reward: -665.4938485373189\t avg steps: 1098.3\t lr: 0.17395860464087973\t epsilon: 0.768712908054295\n",
      "episode: 289\t average reward: -694.5012392597489\t avg steps: 1211.4\t lr: 0.17309098248062138\t epsilon: 0.7615615951325359\n",
      "episode: 299\t average reward: -721.8278391297182\t avg steps: 1214.4\t lr: 0.17222768760394022\t epsilon: 0.75448143896326\n",
      "episode: 309\t average reward: -698.0478745703027\t avg steps: 1193.7\t lr: 0.17136869842841937\t epsilon: 0.7474717315249502\n",
      "episode: 319\t average reward: -690.8538164088769\t avg steps: 1190.6\t lr: 0.17051399347928467\t epsilon: 0.7405317718410214\n",
      "episode: 329\t average reward: -552.5722158677343\t avg steps: 962.7\t lr: 0.1696635513888679\t epsilon: 0.7336608659097217\n",
      "episode: 339\t average reward: -446.4742805052741\t avg steps: 768.9\t lr: 0.16881735089607253\t epsilon: 0.7268583266347322\n",
      "episode: 349\t average reward: -768.9219951246953\t avg steps: 1067.6\t lr: 0.1679753708458421\t epsilon: 0.7201234737564566\n",
      "episode: 359\t average reward: -717.1044030866999\t avg steps: 1102.5\t lr: 0.16713759018863156\t epsilon: 0.7134556337839949\n",
      "episode: 369\t average reward: -593.6104933606823\t avg steps: 927.3\t lr: 0.16630398797988083\t epsilon: 0.7068541399277931\n",
      "episode: 379\t average reward: -336.9502947267803\t avg steps: 628.7\t lr: 0.16547454337949125\t epsilon: 0.7003183320329643\n",
      "episode: 389\t average reward: -392.1236190742554\t avg steps: 716.1\t lr: 0.16464923565130463\t epsilon: 0.6938475565132726\n",
      "episode: 399\t average reward: -361.0649954968478\t avg steps: 667.2\t lr: 0.1638280441625848\t epsilon: 0.6874411662857736\n",
      "episode: 409\t average reward: -920.8135020433825\t avg steps: 1273.4\t lr: 0.16301094838350175\t epsilon: 0.6810985207061059\n",
      "episode: 419\t average reward: -425.9834188709041\t avg steps: 760.9\t lr: 0.16219792788661846\t epsilon: 0.6748189855044261\n",
      "episode: 429\t average reward: -713.6179342240493\t avg steps: 1168.6\t lr: 0.16138896234638012\t epsilon: 0.6686019327219809\n",
      "episode: 439\t average reward: -372.0967536600891\t avg steps: 629.4\t lr: 0.16058403153860615\t epsilon: 0.6624467406483112\n",
      "episode: 449\t average reward: -908.8694938176197\t avg steps: 1036.2\t lr: 0.15978311533998438\t epsilon: 0.6563527937590804\n",
      "episode: 459\t average reward: -573.2805926846959\t avg steps: 966.1\t lr: 0.15898619372756817\t epsilon: 0.6503194826545211\n",
      "episode: 469\t average reward: -421.0886947312682\t avg steps: 756.4\t lr: 0.1581932467782757\t epsilon: 0.6443462039984952\n",
      "episode: 479\t average reward: -369.48223350253807\t avg steps: 651.1\t lr: 0.15740425466839192\t epsilon: 0.6384323604581593\n",
      "episode: 489\t average reward: -377.13451813321774\t avg steps: 693.1\t lr: 0.15661919767307297\t epsilon: 0.6325773606442311\n",
      "episode: 499\t average reward: -624.2622950819672\t avg steps: 946.5\t lr: 0.1558380561658531\t epsilon: 0.6267806190518502\n",
      "episode: 509\t average reward: -453.36218130311613\t avg steps: 707.0\t lr: 0.15506081061815397\t epsilon: 0.6210415560020265\n",
      "episode: 519\t average reward: -382.88528301886794\t avg steps: 663.5\t lr: 0.15428744159879637\t epsilon: 0.6153595975836726\n",
      "episode: 529\t average reward: -304.38968128191584\t avg steps: 568.9\t lr: 0.15351792977351458\t epsilon: 0.6097341755962116\n",
      "episode: 539\t average reward: -308.5840676771237\t avg steps: 568.4\t lr: 0.15275225590447283\t epsilon: 0.6041647274927568\n",
      "episode: 549\t average reward: -358.12701189643104\t avg steps: 572.6\t lr: 0.15199040084978455\t epsilon: 0.598650696323857\n",
      "episode: 559\t average reward: -309.0511154048832\t avg steps: 570.3\t lr: 0.1512323455630337\t epsilon: 0.5931915306817999\n",
      "episode: 569\t average reward: -400.38699593623005\t avg steps: 640.8\t lr: 0.15047807109279862\t epsilon: 0.587786684645472\n",
      "episode: 579\t average reward: -401.45870099811947\t avg steps: 692.3\t lr: 0.14972755858217826\t epsilon: 0.5824356177257659\n",
      "episode: 589\t average reward: -214.88\t avg steps: 406.0\t lr: 0.14898078926832076\t epsilon: 0.5771377948115302\n",
      "episode: 599\t average reward: -236.2657971666292\t avg steps: 445.7\t lr: 0.1482377444819544\t epsilon: 0.5718926861160586\n",
      "episode: 609\t average reward: -365.45231296402056\t avg steps: 526.3\t lr: 0.14749840564692082\t epsilon: 0.5666997671241104\n",
      "episode: 619\t average reward: -254.15040735324837\t avg steps: 479.7\t lr: 0.1467627542797106\t epsilon: 0.5615585185394595\n",
      "episode: 629\t average reward: -304.73037228160706\t avg steps: 543.6\t lr: 0.1460307719890013\t epsilon: 0.5564684262329626\n",
      "episode: 639\t average reward: -362.91294604378555\t avg steps: 581.1\t lr: 0.14530244047519747\t epsilon: 0.5514289811911474\n",
      "episode: 649\t average reward: -793.1899786780384\t avg steps: 939.0\t lr: 0.1445777415299734\t epsilon: 0.54643967946531\n",
      "episode: 659\t average reward: -275.6110784889411\t avg steps: 511.9\t lr: 0.14385665703581765\t epsilon: 0.5415000221211206\n",
      "episode: 669\t average reward: -257.8664707117363\t avg steps: 477.3\t lr: 0.14313916896558035\t epsilon: 0.5366095151887278\n",
      "episode: 679\t average reward: -174.8758865248227\t avg steps: 339.4\t lr: 0.14242525938202236\t epsilon: 0.5317676696133632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 689\t average reward: -263.78660915999177\t avg steps: 487.9\t lr: 0.14171491043736692\t epsilon: 0.5269740012064343\n",
      "episode: 699\t average reward: -292.64963346269946\t avg steps: 464.8\t lr: 0.14100810437285335\t epsilon: 0.5222280305971058\n",
      "episode: 709\t average reward: -247.85723556132382\t avg steps: 463.3\t lr: 0.14030482351829335\t epsilon: 0.5175292831843616\n",
      "episode: 719\t average reward: -329.49413833528723\t avg steps: 512.8\t lr: 0.1396050502916288\t epsilon: 0.512877289089545\n",
      "episode: 729\t average reward: -373.0449685534591\t avg steps: 637.0\t lr: 0.13890876719849268\t epsilon: 0.5082715831093696\n",
      "episode: 739\t average reward: -224.2089150134705\t avg steps: 409.3\t lr: 0.13821595683177135\t epsilon: 0.5037117046693995\n",
      "episode: 749\t average reward: -234.81237911025144\t avg steps: 414.6\t lr: 0.13752660187116958\t epsilon: 0.49919719777799054\n",
      "episode: 759\t average reward: -233.53235225414622\t avg steps: 429.1\t lr: 0.13684068508277744\t epsilon: 0.4947276109806917\n",
      "episode: 769\t average reward: -173.50599161174355\t avg steps: 334.8\t lr: 0.13615818931863946\t epsilon: 0.49030249731509845\n",
      "episode: 779\t average reward: -190.14758198999445\t avg steps: 360.8\t lr: 0.13547909751632603\t epsilon: 0.48592141426615676\n",
      "episode: 789\t average reward: -183.98923817615406\t avg steps: 354.1\t lr: 0.13480339269850675\t epsilon: 0.48158392372191067\n",
      "episode: 799\t average reward: -182.67408536585367\t avg steps: 329.0\t lr: 0.13413105797252592\t epsilon: 0.47728959192969134\n",
      "episode: 809\t average reward: -163.41663979361496\t avg steps: 311.1\t lr: 0.1334620765299804\t epsilon: 0.4730379894527407\n",
      "episode: 819\t average reward: -289.8683831101957\t avg steps: 486.5\t lr: 0.1327964316462993\t epsilon: 0.46882869112726827\n",
      "episode: 829\t average reward: -260.14493712773\t avg steps: 454.3\t lr: 0.13213410668032585\t epsilon: 0.4646612760199336\n",
      "episode: 839\t average reward: -247.08738963097124\t avg steps: 442.7\t lr: 0.1314750850739014\t epsilon: 0.4605353273857532\n",
      "episode: 849\t average reward: -314.58952637658837\t avg steps: 520.4\t lr: 0.13081935035145145\t epsilon: 0.45645043262642526\n",
      "episode: 859\t average reward: -404.42320877613986\t avg steps: 584.4\t lr: 0.1301668861195738\t epsilon: 0.4524061832490697\n",
      "episode: 869\t average reward: -406.68592618144186\t avg steps: 580.8\t lr: 0.12951767606662867\t epsilon: 0.4484021748253787\n",
      "episode: 879\t average reward: -284.9793638773192\t avg steps: 529.2\t lr: 0.12887170396233094\t epsilon: 0.44443800695117325\n",
      "episode: 889\t average reward: -212.9733086680761\t avg steps: 379.4\t lr: 0.12822895365734432\t epsilon: 0.44051328320636224\n",
      "episode: 899\t average reward: -177.94135429262394\t avg steps: 331.8\t lr: 0.12758940908287775\t epsilon: 0.4366276111153007\n",
      "episode: 909\t average reward: -231.0686482661005\t avg steps: 424.9\t lr: 0.12695305425028353\t epsilon: 0.43278060210754143\n",
      "episode: 919\t average reward: -412.87278376896364\t avg steps: 548.1\t lr: 0.12631987325065772\t epsilon: 0.42897187147897786\n",
      "episode: 929\t average reward: -196.07656163626314\t avg steps: 362.8\t lr: 0.12568985025444232\t epsilon: 0.4252010383533731\n",
      "episode: 939\t average reward: -207.63814244716932\t avg steps: 384.3\t lr: 0.12506296951102966\t epsilon: 0.42146772564427226\n",
      "episode: 949\t average reward: -208.53820512820513\t avg steps: 391.0\t lr: 0.12443921534836844\t epsilon: 0.4177715600172933\n",
      "episode: 959\t average reward: -215.13037670317928\t avg steps: 375.3\t lr: 0.12381857217257218\t epsilon: 0.4141121718527934\n",
      "episode: 969\t average reward: -196.19343741730617\t avg steps: 378.9\t lr: 0.1232010244675291\t epsilon: 0.41048919520890664\n",
      "episode: 979\t average reward: -173.73507917174177\t avg steps: 329.4\t lr: 0.12258655679451445\t epsilon: 0.4069022677849494\n",
      "episode: 989\t average reward: -221.85020352781547\t avg steps: 369.5\t lr: 0.12197515379180437\t epsilon: 0.40335103088519025\n",
      "episode: 999\t average reward: -216.20484881503677\t avg steps: 368.1\t lr: 0.12136680017429198\t epsilon: 0.3998351293829797\n",
      "episode: 1009\t average reward: -221.65622688039457\t avg steps: 406.5\t lr: 0.12076148073310511\t epsilon: 0.39635421168523777\n",
      "episode: 1019\t average reward: -261.9750634957285\t avg steps: 434.1\t lr: 0.12015918033522627\t epsilon: 0.3929079296972938\n",
      "episode: 1029\t average reward: -324.4534035656402\t avg steps: 494.6\t lr: 0.1195598839231141\t epsilon: 0.3894959387880772\n",
      "episode: 1039\t average reward: -155.79305740987985\t avg steps: 300.6\t lr: 0.11896357651432708\t epsilon: 0.3861178977556536\n",
      "episode: 1049\t average reward: -334.2952092406741\t avg steps: 529.1\t lr: 0.11837024320114893\t epsilon: 0.38277346879310464\n",
      "episode: 1059\t average reward: -197.04890829694324\t avg steps: 344.5\t lr: 0.11777986915021595\t epsilon: 0.37946231745474723\n",
      "episode: 1069\t average reward: -198.63857102986324\t avg steps: 359.3\t lr: 0.11719243960214609\t epsilon: 0.37618411262268814\n",
      "episode: 1079\t average reward: -173.41804788213628\t avg steps: 326.8\t lr: 0.11660793987117007\t epsilon: 0.3729385264737123\n",
      "episode: 1089\t average reward: -212.60877403846155\t avg steps: 333.8\t lr: 0.11602635534476416\t epsilon: 0.36972523444650013\n",
      "episode: 1099\t average reward: -191.53748590755356\t avg steps: 355.8\t lr: 0.1154476714832849\t epsilon: 0.36654391520917123\n",
      "episode: 1109\t average reward: -214.94211458948612\t avg steps: 339.6\t lr: 0.11487187381960565\t epsilon: 0.36339425062715075\n",
      "episode: 1119\t average reward: -144.55889815150417\t avg steps: 276.9\t lr: 0.1142989479587548\t epsilon: 0.3602759257313557\n",
      "episode: 1129\t average reward: -140.68085106382978\t avg steps: 264.2\t lr: 0.11372887957755598\t epsilon: 0.35718862868669793\n",
      "episode: 1139\t average reward: -136.41469102215314\t avg steps: 258.3\t lr: 0.11316165442427001\t epsilon: 0.3541320507609002\n",
      "episode: 1149\t average reward: -152.76043805612593\t avg steps: 293.2\t lr: 0.11259725831823847\t epsilon: 0.35110588629362277\n",
      "episode: 1159\t average reward: -129.35157810627248\t avg steps: 251.3\t lr: 0.11203567714952932\t epsilon: 0.3481098326658971\n",
      "episode: 1169\t average reward: -131.0119236883943\t avg steps: 252.6\t lr: 0.11147689687858411\t epsilon: 0.3451435902698638\n",
      "episode: 1179\t average reward: -120.457805907173\t avg steps: 238.0\t lr: 0.11092090353586698\t epsilon: 0.3422068624788112\n",
      "episode: 1189\t average reward: -118.54159369527146\t avg steps: 229.4\t lr: 0.11036768322151534\t epsilon: 0.339299355617513\n",
      "episode: 1199\t average reward: -129.61175020542316\t avg steps: 244.4\t lr: 0.10981722210499259\t epsilon: 0.3364207789328602\n",
      "episode: 1209\t average reward: -152.2901536312849\t avg steps: 287.4\t lr: 0.10926950642474212\t epsilon: 0.3335708445647855\n",
      "episode: 1219\t average reward: -184.15951293759514\t avg steps: 329.5\t lr: 0.10872452248784337\t epsilon: 0.330749267517477\n",
      "episode: 1229\t average reward: -127.59428571428572\t avg steps: 246.0\t lr: 0.10818225666966959\t epsilon: 0.3279557656308788\n",
      "episode: 1239\t average reward: -135.87689969604864\t avg steps: 264.2\t lr: 0.10764269541354701\t epsilon: 0.32519005955247426\n",
      "episode: 1249\t average reward: -130.76370280146162\t avg steps: 247.3\t lr: 0.10710582523041619\t epsilon: 0.32245187270935083\n",
      "episode: 1259\t average reward: -136.28710644677662\t avg steps: 267.8\t lr: 0.10657163269849457\t epsilon: 0.3197409312805423\n",
      "episode: 1269\t average reward: -117.41288045875606\t avg steps: 227.7\t lr: 0.10604010446294099\t epsilon: 0.3170569641696466\n",
      "episode: 1279\t average reward: -192.37135199523527\t avg steps: 336.8\t lr: 0.10551122723552193\t epsilon: 0.3143997029777162\n",
      "episode: 1289\t average reward: -150.29626972740314\t avg steps: 279.8\t lr: 0.10498498779427917\t epsilon: 0.3117688819764174\n",
      "episode: 1299\t average reward: -173.72218607677294\t avg steps: 308.4\t lr: 0.1044613729831992\t epsilon: 0.30916423808145765\n",
      "episode: 1309\t average reward: -159.9017517136329\t avg steps: 263.6\t lr: 0.10394036971188453\t epsilon: 0.30658551082627694\n",
      "episode: 1319\t average reward: -122.10662224073303\t avg steps: 241.1\t lr: 0.10342196495522621\t epsilon: 0.30403244233600085\n",
      "episode: 1329\t average reward: -115.7864164432529\t avg steps: 224.8\t lr: 0.10290614575307833\t epsilon: 0.30150477730165276\n",
      "episode: 1339\t average reward: -137.04727733220767\t avg steps: 237.9\t lr: 0.10239289920993398\t epsilon: 0.29900226295462284\n",
      "episode: 1349\t average reward: -137.6655303030303\t avg steps: 265.0\t lr: 0.10188221249460286\t epsilon: 0.296524649041391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1359\t average reward: -140.35737586081913\t avg steps: 276.9\t lr: 0.10137407283989047\t epsilon: 0.2940716877985012\n",
      "episode: 1369\t average reward: -307.97703788748566\t avg steps: 436.5\t lr: 0.10086846754227896\t epsilon: 0.2916431339277849\n",
      "episode: 1379\t average reward: -172.42777413000655\t avg steps: 305.6\t lr: 0.10036538396160961\t epsilon: 0.28923874457183135\n",
      "episode: 1389\t average reward: -121.45701943844493\t avg steps: 232.5\t lr: 0.09986480952076665\t epsilon: 0.28685827928970137\n",
      "episode: 1399\t average reward: -125.73900414937759\t avg steps: 242.0\t lr: 0.099366731705363\t epsilon: 0.2845015000328828\n",
      "episode: 1409\t average reward: -115.49582947173309\t avg steps: 216.8\t lr: 0.09887113806342734\t epsilon: 0.2821681711214862\n",
      "episode: 1419\t average reward: -141.91647940074907\t avg steps: 268.0\t lr: 0.09837801620509283\t epsilon: 0.27985805922067575\n",
      "episode: 1429\t average reward: -191.1558516801854\t avg steps: 346.2\t lr: 0.0978873538022873\t epsilon: 0.27757093331733645\n",
      "episode: 1439\t average reward: -130.42338204592903\t avg steps: 240.5\t lr: 0.09739913858842512\t epsilon: 0.275306564696972\n",
      "episode: 1449\t average reward: -170.9714566929134\t avg steps: 305.8\t lr: 0.09691335835810053\t epsilon: 0.2730647269208333\n",
      "episode: 1459\t average reward: -151.41845720324056\t avg steps: 284.9\t lr: 0.09643000096678246\t epsilon: 0.27084519580327454\n",
      "episode: 1469\t average reward: -158.09220092531393\t avg steps: 303.6\t lr: 0.09594905433051097\t epsilon: 0.26864774938933444\n",
      "episode: 1479\t average reward: -133.03219624377155\t avg steps: 261.9\t lr: 0.0954705064255951\t epsilon: 0.26647216793254036\n",
      "episode: 1489\t average reward: -120.46189868028948\t avg steps: 235.9\t lr: 0.09499434528831228\t epsilon: 0.2643182338729335\n",
      "episode: 1499\t average reward: -157.38733125649014\t avg steps: 289.9\t lr: 0.0945205590146093\t epsilon: 0.2621857318153132\n",
      "episode: 1509\t average reward: -115.49316277018086\t avg steps: 227.7\t lr: 0.09404913575980464\t epsilon: 0.26007444850769634\n",
      "episode: 1519\t average reward: -133.38897396630935\t avg steps: 262.2\t lr: 0.09358006373829236\t epsilon: 0.2579841728199929\n",
      "episode: 1529\t average reward: -123.05809128630706\t avg steps: 242.0\t lr: 0.09311333122324751\t epsilon: 0.25591469572289227\n",
      "episode: 1539\t average reward: -120.23083511777303\t avg steps: 234.5\t lr: 0.09264892654633292\t epsilon: 0.25386581026696003\n",
      "episode: 1549\t average reward: -117.7604970008569\t avg steps: 234.4\t lr: 0.09218683809740744\t epsilon: 0.2518373115619432\n",
      "episode: 1559\t average reward: -134.18745098039216\t avg steps: 256.0\t lr: 0.09172705432423578\t epsilon: 0.2498289967562809\n",
      "episode: 1569\t average reward: -103.15473209814722\t avg steps: 200.7\t lr: 0.0912695637321997\t epsilon: 0.24784066501681895\n",
      "episode: 1579\t average reward: -109.76962616822429\t avg steps: 215.0\t lr: 0.09081435488401055\t epsilon: 0.24587211750872645\n",
      "episode: 1589\t average reward: -116.45729303547964\t avg steps: 229.3\t lr: 0.09036141639942341\t epsilon: 0.24392315737561215\n",
      "episode: 1599\t average reward: -122.72538860103627\t avg steps: 232.6\t lr: 0.0899107369549526\t epsilon: 0.24199358971983853\n",
      "episode: 1609\t average reward: -113.96336996336996\t avg steps: 219.4\t lr: 0.08946230528358849\t epsilon: 0.24008322158303214\n",
      "episode: 1619\t average reward: -112.87059899405578\t avg steps: 219.7\t lr: 0.089016110174516\t epsilon: 0.23819186192678726\n",
      "episode: 1629\t average reward: -143.41856866537717\t avg steps: 259.5\t lr: 0.08857214047283411\t epsilon: 0.23631932161356212\n",
      "episode: 1639\t average reward: -123.6308610400682\t avg steps: 235.6\t lr: 0.08813038507927717\t epsilon: 0.2344654133877649\n",
      "episode: 1649\t average reward: -141.62151850438764\t avg steps: 263.1\t lr: 0.08769083294993736\t epsilon: 0.23262995185702823\n",
      "episode: 1659\t average reward: -132.89157597742846\t avg steps: 249.1\t lr: 0.08725347309598853\t epsilon: 0.23081275347366936\n",
      "episode: 1669\t average reward: -122.02205558006176\t avg steps: 227.7\t lr: 0.08681829458341156\t epsilon: 0.22901363651633566\n",
      "episode: 1679\t average reward: -103.88111888111888\t avg steps: 201.2\t lr: 0.08638528653272096\t epsilon: 0.2272324210718321\n",
      "episode: 1689\t average reward: -117.17046979865772\t avg steps: 224.5\t lr: 0.08595443811869291\t epsilon: 0.22546892901712995\n",
      "episode: 1699\t average reward: -89.01264367816091\t avg steps: 175.0\t lr: 0.08552573857009463\t epsilon: 0.22372298400155405\n",
      "episode: 1709\t average reward: -109.85931945149822\t avg steps: 197.9\t lr: 0.08509917716941506\t epsilon: 0.221994411429148\n",
      "episode: 1719\t average reward: -112.84582542694497\t avg steps: 211.8\t lr: 0.084674743252597\t epsilon: 0.22028303844121394\n",
      "episode: 1729\t average reward: -106.13917781079742\t avg steps: 202.9\t lr: 0.08425242620877038\t epsilon: 0.21858869389902708\n",
      "episode: 1739\t average reward: -124.52392120075046\t avg steps: 214.2\t lr: 0.08383221547998715\t epsilon: 0.21691120836672112\n",
      "episode: 1749\t average reward: -121.29045817570407\t avg steps: 238.9\t lr: 0.08341410056095716\t epsilon: 0.21525041409434498\n",
      "episode: 1759\t average reward: -114.00224921277552\t avg steps: 223.3\t lr: 0.0829980709987857\t epsilon: 0.21360614500108743\n",
      "episode: 1769\t average reward: -108.78986517898652\t avg steps: 216.1\t lr: 0.08258411639271203\t epsilon: 0.21197823665866888\n",
      "episode: 1779\t average reward: -118.48292469352015\t avg steps: 229.4\t lr: 0.08217222639384943\t epsilon: 0.21036652627489855\n",
      "episode: 1789\t average reward: -127.68822820409802\t avg steps: 249.9\t lr: 0.08176239070492648\t epsilon: 0.20877085267739492\n",
      "episode: 1799\t average reward: -120.64080944350759\t avg steps: 238.2\t lr: 0.08135459908002964\t epsilon: 0.20719105629746848\n",
      "episode: 1809\t average reward: -215.382183908046\t avg steps: 314.2\t lr: 0.080948841324347\t epsilon: 0.20562697915416478\n",
      "episode: 1819\t average reward: -113.66309412861138\t avg steps: 215.6\t lr: 0.08054510729391356\t epsilon: 0.2040784648384661\n",
      "episode: 1829\t average reward: -116.8089986766652\t avg steps: 227.7\t lr: 0.08014338689535754\t epsilon: 0.20254535849765037\n",
      "episode: 1839\t average reward: -125.27646062658764\t avg steps: 237.2\t lr: 0.07974367008564803\t epsilon: 0.20102750681980602\n",
      "episode: 1849\t average reward: -99.45184799583551\t avg steps: 193.1\t lr: 0.07934594687184399\t epsilon: 0.19952475801850028\n",
      "episode: 1859\t average reward: -113.8807129798903\t avg steps: 219.8\t lr: 0.07895020731084433\t epsilon: 0.19803696181760078\n",
      "episode: 1869\t average reward: -101.7642149191445\t avg steps: 192.7\t lr: 0.07855644150913944\t epsilon: 0.1965639694362476\n",
      "episode: 1879\t average reward: -115.86632270168856\t avg steps: 214.2\t lr: 0.07816463962256379\t epsilon: 0.1951056335739751\n",
      "episode: 1889\t average reward: -138.80616570327552\t avg steps: 260.5\t lr: 0.07777479185604975\t epsilon: 0.19366180839598174\n",
      "episode: 1899\t average reward: -117.40469738030714\t avg steps: 222.4\t lr: 0.0773868884633829\t epsilon: 0.19223234951854656\n",
      "episode: 1909\t average reward: -99.86317477284874\t avg steps: 188.1\t lr: 0.07700091974695822\t epsilon: 0.19081711399459056\n",
      "episode: 1919\t average reward: -107.35764944275583\t avg steps: 198.4\t lr: 0.07661687605753766\t epsilon: 0.189415960299382\n",
      "episode: 1929\t average reward: -102.22977178423237\t avg steps: 193.8\t lr: 0.07623474779400902\t epsilon: 0.18802874831638383\n",
      "episode: 1939\t average reward: -100.55688311688311\t avg steps: 193.5\t lr: 0.07585452540314577\t epsilon: 0.18665533932324158\n",
      "episode: 1949\t average reward: -108.08191126279864\t avg steps: 206.1\t lr: 0.07547619937936838\t epsilon: 0.18529559597791145\n",
      "episode: 1959\t average reward: -107.7593220338983\t avg steps: 207.5\t lr: 0.07509976026450652\t epsilon: 0.18394938230492586\n",
      "episode: 1969\t average reward: -108.2209358417752\t avg steps: 208.3\t lr: 0.0747251986475627\t epsilon: 0.18261656368179557\n",
      "episode: 1979\t average reward: -104.35372069317023\t avg steps: 197.2\t lr: 0.07435250516447704\t epsilon: 0.18129700682554767\n",
      "episode: 1989\t average reward: -108.62345679012346\t avg steps: 211.6\t lr: 0.07398167049789302\t epsilon: 0.17999057977939686\n",
      "episode: 1999\t average reward: -105.72065955383123\t avg steps: 207.2\t lr: 0.07361268537692466\t epsilon: 0.17869715189954982\n",
      "episode: 2009\t average reward: -103.88943731490622\t avg steps: 203.6\t lr: 0.07324554057692471\t epsilon: 0.17741659384214076\n",
      "episode: 2019\t average reward: -116.79560735096369\t avg steps: 224.1\t lr: 0.07288022691925407\t epsilon: 0.17614877755029668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2029\t average reward: -120.71721132897603\t avg steps: 230.5\t lr: 0.07251673527105228\t epsilon: 0.17489357624133203\n",
      "episode: 2039\t average reward: -127.6517269736842\t avg steps: 244.2\t lr: 0.07215505654500913\t epsilon: 0.1736508643940698\n",
      "episode: 2049\t average reward: -90.45444319460067\t avg steps: 178.8\t lr: 0.07179518169913772\t epsilon: 0.17242051773628975\n",
      "episode: 2059\t average reward: -113.96134606639382\t avg steps: 220.9\t lr: 0.07143710173654812\t epsilon: 0.17120241323230073\n",
      "episode: 2069\t average reward: -107.57509505703422\t avg steps: 211.4\t lr: 0.07108080770522261\t epsilon: 0.16999642907063733\n",
      "episode: 2079\t average reward: -107.24735322425408\t avg steps: 208.8\t lr: 0.07072629069779186\t epsilon: 0.16880244465187827\n",
      "episode: 2089\t average reward: -113.23722789871168\t avg steps: 226.1\t lr: 0.07037354185131224\t epsilon: 0.16762034057658687\n",
      "episode: 2099\t average reward: -99.47013388259526\t avg steps: 195.2\t lr: 0.07002255234704417\t epsilon: 0.16644999863337032\n",
      "episode: 2109\t average reward: -102.05656565656565\t avg steps: 199.0\t lr: 0.0696733134102318\t epsilon: 0.16529130178705917\n",
      "episode: 2119\t average reward: -102.1895947973987\t avg steps: 200.9\t lr: 0.06932581630988349\t epsilon: 0.16414413416700305\n",
      "episode: 2129\t average reward: -124.81443298969072\t avg steps: 243.5\t lr: 0.06898005235855367\t epsilon: 0.16300838105548415\n",
      "episode: 2139\t average reward: -123.53925527142216\t avg steps: 223.9\t lr: 0.06863601291212551\t epsilon: 0.1618839288762447\n",
      "episode: 2149\t average reward: -180.14831369362048\t avg steps: 247.1\t lr: 0.06829368936959497\t epsilon: 0.16077066518312982\n",
      "episode: 2159\t average reward: -113.25873465533522\t avg steps: 212.8\t lr: 0.06795307317285562\t epsilon: 0.1596684786488424\n",
      "episode: 2169\t average reward: -129.81791544579323\t avg steps: 239.9\t lr: 0.06761415580648482\t epsilon: 0.15857725905381062\n",
      "episode: 2179\t average reward: -110.55172413793103\t avg steps: 206.9\t lr: 0.06727692879753076\t epsilon: 0.15749689727516558\n",
      "episode: 2189\t average reward: -91.08934517203107\t avg steps: 181.2\t lr: 0.06694138371530065\t epsilon: 0.15642728527582905\n",
      "episode: 2199\t average reward: -96.83589200635257\t avg steps: 189.9\t lr: 0.06660751217114995\t epsilon: 0.15536831609370985\n",
      "episode: 2209\t average reward: -106.9990342829551\t avg steps: 208.1\t lr: 0.06627530581827266\t epsilon: 0.1543198838310072\n",
      "episode: 2219\t average reward: -99.94359515023721\t avg steps: 190.7\t lr: 0.0659447563514927\t epsilon: 0.15328188364362122\n",
      "episode: 2229\t average reward: -113.61035294117647\t avg steps: 213.5\t lr: 0.06561585550705612\t epsilon: 0.1522542117306681\n",
      "episode: 2239\t average reward: -135.41573516766982\t avg steps: 233.6\t lr: 0.06528859506242474\t epsilon: 0.1512367653241002\n",
      "episode: 2249\t average reward: -194.76562014299037\t avg steps: 322.7\t lr: 0.06496296683607035\t epsilon: 0.15022944267842891\n",
      "episode: 2259\t average reward: -176.2101593625498\t avg steps: 302.2\t lr: 0.06463896268727036\t epsilon: 0.14923214306055035\n",
      "episode: 2269\t average reward: -104.3937875751503\t avg steps: 200.6\t lr: 0.06431657451590417\t epsilon: 0.14824476673967152\n",
      "episode: 2279\t average reward: -118.78245137946631\t avg steps: 222.1\t lr: 0.0639957942622507\t epsilon: 0.1472672149773376\n",
      "episode: 2289\t average reward: -141.09590100541377\t avg steps: 259.6\t lr: 0.0636766139067869\t epsilon: 0.14629939001755765\n",
      "episode: 2299\t average reward: -107.85988753514526\t avg steps: 214.4\t lr: 0.06335902546998727\t epsilon: 0.14534119507702928\n",
      "episode: 2309\t average reward: -124.29715229054891\t avg steps: 243.3\t lr: 0.06304302101212433\t epsilon: 0.14439253433545982\n",
      "episode: 2319\t average reward: -171.4804177545692\t avg steps: 269.1\t lr: 0.06272859263307021\t epsilon: 0.14345331292598465\n",
      "episode: 2329\t average reward: -138.7125\t avg steps: 257.0\t lr: 0.06241573247209901\t epsilon: 0.14252343692568004\n",
      "episode: 2339\t average reward: -108.10654205607477\t avg steps: 215.0\t lr: 0.06210443270769044\t epsilon: 0.1416028133461712\n",
      "episode: 2349\t average reward: -110.45071068317286\t avg steps: 219.1\t lr: 0.06179468555733417\t epsilon: 0.14069135012433284\n",
      "episode: 2359\t average reward: -122.67965188561956\t avg steps: 242.3\t lr: 0.061486483277335316\t epsilon: 0.13978895611308334\n",
      "episode: 2369\t average reward: -125.15923824959481\t avg steps: 247.8\t lr: 0.0611798181626208\t epsilon: 0.13889554107226948\n",
      "episode: 2379\t average reward: -181.4986338797814\t avg steps: 293.8\t lr: 0.060874682546546835\t epsilon: 0.13801101565964274\n",
      "episode: 2389\t average reward: -157.42119847592656\t avg steps: 289.7\t lr: 0.06057106880070706\t epsilon: 0.1371352914219247\n",
      "episode: 2399\t average reward: -121.11871567384875\t avg steps: 237.7\t lr: 0.06026896933474207\t epsilon: 0.1362682807859619\n",
      "episode: 2409\t average reward: -123.26395300041963\t avg steps: 239.3\t lr: 0.059968376596149446\t epsilon: 0.1354098970499681\n",
      "episode: 2419\t average reward: -125.21434528773979\t avg steps: 240.8\t lr: 0.05966928307009509\t epsilon: 0.13456005437485452\n",
      "episode: 2429\t average reward: -106.12205882352941\t avg steps: 205.0\t lr: 0.05937168127922526\t epsilon: 0.13371866777564528\n",
      "episode: 2439\t average reward: -119.3265833692374\t avg steps: 233.1\t lr: 0.059075563783479695\t epsilon: 0.13288565311297945\n",
      "episode: 2449\t average reward: -111.65501165501165\t avg steps: 215.5\t lr: 0.058780923179905575\t epsilon: 0.13206092708469655\n",
      "episode: 2459\t average reward: -99.47077244258872\t avg steps: 192.6\t lr: 0.05848775210247245\t epsilon: 0.1312444072175064\n",
      "episode: 2469\t average reward: -96.55753646677472\t avg steps: 186.1\t lr: 0.05819604322188813\t epsilon: 0.13043601185874193\n",
      "episode: 2479\t average reward: -94.77831978319783\t avg steps: 185.5\t lr: 0.057905789245415396\t epsilon: 0.12963566016819356\n",
      "episode: 2489\t average reward: -88.63182346109176\t avg steps: 173.2\t lr: 0.05761698291668974\t epsilon: 0.12884327211002528\n",
      "episode: 2499\t average reward: -88.20745920745921\t avg steps: 172.6\t lr: 0.05732961701553788\t epsilon: 0.12805876844477093\n",
      "episode: 2509\t average reward: -84.00122699386503\t avg steps: 164.0\t lr: 0.05704368435779733\t epsilon: 0.1272820707214103\n",
      "episode: 2519\t average reward: -75.11732605729877\t avg steps: 147.6\t lr: 0.056759177795136756\t epsilon: 0.1265131012695237\n",
      "episode: 2529\t average reward: -79.33566878980892\t avg steps: 158.0\t lr: 0.056476090214877275\t epsilon: 0.1257517831915252\n",
      "episode: 2539\t average reward: -77.11601845748187\t avg steps: 152.7\t lr: 0.05619441453981461\t epsilon: 0.12499804035497253\n",
      "episode: 2549\t average reward: -80.30443037974683\t avg steps: 159.0\t lr: 0.05591414372804226\t epsilon: 0.12425179738495397\n",
      "episode: 2559\t average reward: -76.38190286094478\t avg steps: 151.3\t lr: 0.055635270772775296\t epsilon: 0.12351297965655057\n",
      "episode: 2569\t average reward: -73.60444136016655\t avg steps: 145.1\t lr: 0.05535778870217533\t epsilon: 0.12278151328737388\n",
      "episode: 2579\t average reward: -77.05669083717864\t avg steps: 152.7\t lr: 0.055081690579176126\t epsilon: 0.12205732513017736\n",
      "episode: 2589\t average reward: -75.75973154362416\t avg steps: 150.0\t lr: 0.054806969501310254\t epsilon: 0.12134034276554186\n",
      "episode: 2599\t average reward: -76.10881174899866\t avg steps: 150.8\t lr: 0.05453361860053644\t epsilon: 0.12063049449463337\n",
      "episode: 2609\t average reward: -75.53396099529253\t avg steps: 149.7\t lr: 0.05426163104306794\t epsilon: 0.1199277093320333\n",
      "episode: 2619\t average reward: -81.78017241379311\t avg steps: 163.4\t lr: 0.05399100002920163\t epsilon: 0.11923191699863972\n",
      "episode: 2629\t average reward: -80.89167188478397\t avg steps: 160.7\t lr: 0.05372171879314811\t epsilon: 0.11854304791463946\n",
      "episode: 2639\t average reward: -80.92839352428393\t avg steps: 161.6\t lr: 0.053453780602862405\t epsilon: 0.11786103319255004\n",
      "episode: 2649\t average reward: -80.73503740648378\t avg steps: 161.4\t lr: 0.053187178759875844\t epsilon: 0.11718580463033096\n",
      "episode: 2659\t average reward: -82.96703980099502\t avg steps: 161.8\t lr: 0.05292190659912843\t epsilon: 0.11651729470456323\n",
      "episode: 2669\t average reward: -85.78871548619448\t avg steps: 167.6\t lr: 0.05265795748880236\t epsilon: 0.11585543656369726\n",
      "episode: 2679\t average reward: -123.03419203747073\t avg steps: 214.5\t lr: 0.052395324830156104\t epsilon: 0.11520016402136735\n",
      "episode: 2689\t average reward: -100.7002624671916\t avg steps: 191.5\t lr: 0.05213400205735953\t epsilon: 0.11455141154977325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2699\t average reward: -96.04777777777778\t avg steps: 181.0\t lr: 0.05187398263732972\t epsilon: 0.11390911427312714\n",
      "episode: 2709\t average reward: -91.3257790368272\t avg steps: 177.5\t lr: 0.0516152600695676\t epsilon: 0.11327320796116609\n",
      "episode: 2719\t average reward: -105.43724696356276\t avg steps: 198.6\t lr: 0.051357827885995515\t epsilon: 0.11264362902272904\n",
      "episode: 2729\t average reward: -78.87841352405722\t avg steps: 154.8\t lr: 0.05110167965079546\t epsilon: 0.11202031449939742\n",
      "episode: 2739\t average reward: -114.14400757934628\t avg steps: 212.1\t lr: 0.05084680896024825\t epsilon: 0.11140320205919955\n",
      "episode: 2749\t average reward: -170.3913498430415\t avg steps: 287.7\t lr: 0.0505932094425733\t epsilon: 0.11079222999037708\n",
      "episode: 2759\t average reward: -119.13796133567662\t avg steps: 228.6\t lr: 0.05034087475776949\t epsilon: 0.11018733719521402\n",
      "episode: 2769\t average reward: -86.98892128279883\t avg steps: 172.5\t lr: 0.05008979859745653\t epsilon: 0.10958846318392676\n",
      "episode: 2779\t average reward: -86.5552308591467\t avg steps: 172.1\t lr: 0.04983997468471737\t epsilon: 0.10899554806861511\n",
      "episode: 2789\t average reward: -83.41898428053204\t avg steps: 166.4\t lr: 0.04959139677394114\t epsilon: 0.10840853255727342\n",
      "episode: 2799\t average reward: -77.16982364467668\t avg steps: 154.1\t lr: 0.049344058650667176\t epsilon: 0.10782735794786144\n",
      "episode: 2809\t average reward: -89.7378362907842\t avg steps: 175.7\t lr: 0.049097954131429464\t epsilon: 0.10725196612243384\n",
      "episode: 2819\t average reward: -75.82269979852249\t avg steps: 149.9\t lr: 0.04885307706360223\t epsilon: 0.10668229954132863\n",
      "episode: 2829\t average reward: -84.76909307875896\t avg steps: 168.6\t lr: 0.04860942132524602\t epsilon: 0.10611830123741295\n",
      "episode: 2839\t average reward: -84.11131167268351\t avg steps: 167.2\t lr: 0.048366980824954685\t epsilon: 0.10555991481038643\n",
      "episode: 2849\t average reward: -83.13500305436774\t avg steps: 164.7\t lr: 0.048125749501703084\t epsilon: 0.10500708442114101\n",
      "episode: 2859\t average reward: -80.0559085133418\t avg steps: 158.4\t lr: 0.04788572132469559\t epsilon: 0.10445975478617713\n",
      "episode: 2869\t average reward: -84.54308252427184\t avg steps: 165.8\t lr: 0.04764689029321525\t epsilon: 0.10391787117207511\n",
      "episode: 2879\t average reward: -76.8907284768212\t avg steps: 152.0\t lr: 0.04740925043647386\t epsilon: 0.10338137939002204\n",
      "episode: 2889\t average reward: -80.05551969012267\t avg steps: 155.9\t lr: 0.0471727958134626\t epsilon: 0.10285022579039257\n",
      "episode: 2899\t average reward: -86.34382422802851\t avg steps: 169.4\t lr: 0.046937520512803615\t epsilon: 0.10232435725738417\n",
      "episode: 2909\t average reward: -84.79066985645933\t avg steps: 168.2\t lr: 0.0467034186526021\t epsilon: 0.10180372120370526\n",
      "episode: 2919\t average reward: -84.90920024052916\t avg steps: 167.3\t lr: 0.04647048438029938\t epsilon: 0.10128826556531666\n",
      "episode: 2929\t average reward: -87.44851657940663\t avg steps: 172.9\t lr: 0.046238711872526504\t epsilon: 0.10077793879622493\n",
      "episode: 2939\t average reward: -85.46654825340438\t avg steps: 169.9\t lr: 0.04600809533495871\t epsilon: 0.10027268986332792\n",
      "episode: 2949\t average reward: -87.54608294930875\t avg steps: 174.6\t lr: 0.04577862900217056\t epsilon: 0.09977246824131131\n",
      "episode: 2959\t average reward: -91.165371809101\t avg steps: 181.2\t lr: 0.04555030713749175\t epsilon: 0.099277223907596\n",
      "episode: 2969\t average reward: -87.89318706697459\t avg steps: 174.2\t lr: 0.0453231240328638\t epsilon: 0.09878690733733596\n",
      "episode: 2979\t average reward: -84.22675464907019\t avg steps: 167.7\t lr: 0.04509707400869725\t epsilon: 0.09830146949846552\n",
      "episode: 2989\t average reward: -91.81838316722038\t avg steps: 181.6\t lr: 0.04487215141372973\t epsilon: 0.09782086184679631\n",
      "episode: 2999\t average reward: -84.05288461538461\t avg steps: 167.4\t lr: 0.04464835062488464\t epsilon: 0.0973450363211626\n",
      "episode: 3009\t average reward: -90.18647887323944\t avg steps: 178.5\t lr: 0.044425666047130614\t epsilon: 0.09687394533861537\n",
      "episode: 3019\t average reward: -93.27615298087738\t avg steps: 178.8\t lr: 0.0442040921133416\t epsilon: 0.09640754178966374\n",
      "episode: 3029\t average reward: -84.01677651288196\t avg steps: 167.9\t lr: 0.043983623284157725\t epsilon: 0.09594577903356416\n",
      "episode: 3039\t average reward: -88.72291904218928\t avg steps: 176.4\t lr: 0.04376425404784676\t epsilon: 0.09548861089365619\n",
      "episode: 3049\t average reward: -94.85138121546962\t avg steps: 182.0\t lr: 0.043545978920166394\t epsilon: 0.09503599165274493\n",
      "episode: 3059\t average reward: -95.51549755301795\t avg steps: 184.9\t lr: 0.04332879244422704\t epsilon: 0.09458787604852902\n",
      "episode: 3069\t average reward: -95.32247557003258\t avg steps: 185.2\t lr: 0.04311268919035551\t epsilon: 0.09414421926907468\n",
      "episode: 3079\t average reward: -91.4177428411005\t avg steps: 179.1\t lr: 0.04289766375595919\t epsilon: 0.09370497694833418\n",
      "episode: 3089\t average reward: -93.00667037242913\t avg steps: 180.9\t lr: 0.04268371076539103\t epsilon: 0.0932701051617095\n",
      "episode: 3099\t average reward: -121.55679287305122\t avg steps: 225.5\t lr: 0.042470824869815106\t epsilon: 0.0928395604216595\n",
      "episode: 3109\t average reward: -82.9751213592233\t avg steps: 165.8\t lr: 0.042259000747072964\t epsilon: 0.09241329967335143\n",
      "episode: 3119\t average reward: -101.71435977190254\t avg steps: 193.9\t lr: 0.04204823310155048\t epsilon: 0.09199128029035522\n",
      "episode: 3129\t average reward: -122.37688219663418\t avg steps: 226.8\t lr: 0.04183851666404556\t epsilon: 0.09157346007038092\n",
      "episode: 3139\t average reward: -87.21678321678321\t avg steps: 172.6\t lr: 0.041629846191636316\t epsilon: 0.0911597972310583\n",
      "episode: 3149\t average reward: -86.30094228504123\t avg steps: 170.8\t lr: 0.041422216467550094\t epsilon: 0.09075025040575874\n",
      "episode: 3159\t average reward: -102.42280524722503\t avg steps: 199.2\t lr: 0.04121562230103297\t epsilon: 0.09034477863945839\n",
      "episode: 3169\t average reward: -96.5219957081545\t avg steps: 187.4\t lr: 0.04101005852722003\t epsilon: 0.08994334138464277\n",
      "episode: 3179\t average reward: -104.3382862803368\t avg steps: 202.9\t lr: 0.04080552000700619\t epsilon: 0.08954589849725184\n",
      "episode: 3189\t average reward: -88.83295324971493\t avg steps: 176.4\t lr: 0.04060200162691784\t epsilon: 0.08915241023266567\n",
      "episode: 3199\t average reward: -88.07541738629821\t avg steps: 174.7\t lr: 0.040399498298984836\t epsilon: 0.08876283724172987\n",
      "episode: 3209\t average reward: -91.80941828254848\t avg steps: 181.5\t lr: 0.04019800496061346\t epsilon: 0.08837714056682072\n",
      "episode: 3219\t average reward: -86.20823529411764\t avg steps: 171.0\t lr: 0.03999751657445974\t epsilon: 0.08799528163794931\n",
      "episode: 3229\t average reward: -93.87777777777778\t avg steps: 181.0\t lr: 0.03979802812830358\t epsilon: 0.08761722226890453\n",
      "episode: 3239\t average reward: -89.26704545454545\t avg steps: 177.0\t lr: 0.03959953463492346\t epsilon: 0.08724292465343444\n",
      "episode: 3249\t average reward: -79.57844387755102\t avg steps: 157.8\t lr: 0.03940203113197168\t epsilon: 0.08687235136146554\n",
      "episode: 3259\t average reward: -83.42215384615385\t avg steps: 163.5\t lr: 0.039205512681850394\t epsilon: 0.08650546533535988\n",
      "episode: 3269\t average reward: -87.83638511518015\t avg steps: 170.3\t lr: 0.0390099743715881\t epsilon: 0.08614222988620907\n",
      "episode: 3279\t average reward: -91.86324786324786\t avg steps: 176.5\t lr: 0.03881541131271688\t epsilon: 0.0857826086901655\n",
      "episode: 3289\t average reward: -77.74622950819672\t avg steps: 153.5\t lr: 0.03862181864115011\t epsilon: 0.0854265657848099\n",
      "episode: 3299\t average reward: -80.12065698041692\t avg steps: 159.3\t lr: 0.03842919151706092\t epsilon: 0.085074065565555\n",
      "episode: 3309\t average reward: -87.92149970708846\t avg steps: 171.7\t lr: 0.03823752512476118\t epsilon: 0.08472507278208513\n",
      "episode: 3319\t average reward: -93.09547461368653\t avg steps: 182.2\t lr: 0.038046814672581114\t epsilon: 0.08437955253483115\n",
      "episode: 3329\t average reward: -80.20979899497488\t avg steps: 160.2\t lr: 0.037857055392749445\t epsilon: 0.08403747027148037\n",
      "episode: 3339\t average reward: -83.8220747889023\t avg steps: 166.8\t lr: 0.037668242541274335\t epsilon: 0.0836987917835214\n",
      "episode: 3349\t average reward: -75.23457627118644\t avg steps: 148.5\t lr: 0.03748037139782463\t epsilon: 0.08336348320282319\n",
      "episode: 3359\t average reward: -76.16266666666667\t avg steps: 151.0\t lr: 0.03729343726561199\t epsilon: 0.08303151099824826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3369\t average reward: -89.1455733808675\t avg steps: 169.3\t lr: 0.03710743547127335\t epsilon: 0.08270284197229949\n",
      "episode: 3379\t average reward: -73.54584221748401\t avg steps: 141.7\t lr: 0.03692236136475418\t epsilon: 0.08237744325780044\n",
      "episode: 3389\t average reward: -78.70950819672132\t avg steps: 153.5\t lr: 0.03673821031919216\t epsilon: 0.08205528231460844\n",
      "episode: 3399\t average reward: -81.64505978602895\t avg steps: 159.9\t lr: 0.03655497773080158\t epsilon: 0.08173632692636074\n",
      "episode: 3409\t average reward: -79.2939649578196\t avg steps: 155.1\t lr: 0.03637265901875817\t epsilon: 0.0814205451972527\n",
      "episode: 3419\t average reward: -82.0834890965732\t avg steps: 161.5\t lr: 0.036191249625084645\t epsilon: 0.08110790554884825\n",
      "episode: 3429\t average reward: -80.17473287240729\t avg steps: 160.1\t lr: 0.03601074501453671\t epsilon: 0.08079837671692203\n",
      "episode: 3439\t average reward: -85.45843373493976\t avg steps: 167.0\t lr: 0.03583114067448969\t epsilon: 0.08049192774833291\n",
      "episode: 3449\t average reward: -86.3746167995095\t avg steps: 164.1\t lr: 0.035652432114825744\t epsilon: 0.08018852799792864\n",
      "episode: 3459\t average reward: -72.19208633093525\t avg steps: 140.0\t lr: 0.03547461486782157\t epsilon: 0.07988814712548135\n",
      "episode: 3469\t average reward: -73.61678321678322\t avg steps: 144.0\t lr: 0.03529768448803674\t epsilon: 0.0795907550926535\n",
      "episode: 3479\t average reward: -78.99406332453826\t avg steps: 152.6\t lr: 0.03512163655220251\t epsilon: 0.07929632215999394\n",
      "episode: 3489\t average reward: -78.46178548490687\t avg steps: 156.7\t lr: 0.03494646665911136\t epsilon: 0.07900481888396407\n",
      "episode: 3499\t average reward: -77.89213775178688\t avg steps: 154.9\t lr: 0.0347721704295068\t epsilon: 0.07871621611399335\n",
      "episode: 3509\t average reward: -78.24435847840103\t avg steps: 156.1\t lr: 0.03459874350597405\t epsilon: 0.0784304849895643\n",
      "episode: 3519\t average reward: -78.23628147191737\t avg steps: 155.9\t lr: 0.03442618155283095\t epsilon: 0.07814759693732634\n",
      "episode: 3529\t average reward: -83.22526446795271\t avg steps: 161.7\t lr: 0.03425448025601971\t epsilon: 0.07786752366823854\n",
      "episode: 3539\t average reward: -84.32752179327522\t avg steps: 161.6\t lr: 0.034083635322998955\t epsilon: 0.07759023717474058\n",
      "episode: 3549\t average reward: -75.47689216342934\t avg steps: 150.3\t lr: 0.03391364248263647\t epsilon: 0.07731570972795203\n",
      "episode: 3559\t average reward: -77.74724562540506\t avg steps: 155.3\t lr: 0.03374449748510239\t epsilon: 0.07704391387489944\n",
      "episode: 3569\t average reward: -80.40601503759399\t avg steps: 160.6\t lr: 0.03357619610176296\t epsilon: 0.07677482243577101\n",
      "episode: 3579\t average reward: -83.66979949874687\t avg steps: 160.6\t lr: 0.033408734125074835\t epsilon: 0.07650840850119858\n",
      "episode: 3589\t average reward: -78.12701482914248\t avg steps: 156.1\t lr: 0.033242107368479885\t epsilon: 0.07624464542956669\n",
      "episode: 3599\t average reward: -76.3249001331558\t avg steps: 151.2\t lr: 0.033076311666300505\t epsilon: 0.07598350684434836\n",
      "episode: 3609\t average reward: -76.01342281879195\t avg steps: 150.0\t lr: 0.03291134287363551\t epsilon: 0.07572496663146747\n",
      "episode: 3619\t average reward: -76.13164893617021\t avg steps: 151.4\t lr: 0.03274719686625648\t epsilon: 0.07546899893668725\n",
      "episode: 3629\t average reward: -77.61031331592689\t avg steps: 154.2\t lr: 0.032583869540504705\t epsilon: 0.07521557816302496\n",
      "episode: 3639\t average reward: -77.7633289986996\t avg steps: 154.8\t lr: 0.0324213568131885\t epsilon: 0.074964678968192\n",
      "episode: 3649\t average reward: -82.90828025477707\t avg steps: 158.0\t lr: 0.03225965462148126\t epsilon: 0.07471627626205986\n",
      "episode: 3659\t average reward: -91.27800586510264\t avg steps: 171.5\t lr: 0.032098758922819735\t epsilon: 0.07447034520415086\n",
      "episode: 3669\t average reward: -74.93432633716994\t avg steps: 148.7\t lr: 0.0319386656948031\t epsilon: 0.07422686120115432\n",
      "episode: 3679\t average reward: -75.01826792963465\t avg steps: 148.8\t lr: 0.0317793709350923\t epsilon: 0.07398579990446699\n",
      "episode: 3689\t average reward: -77.30218281036835\t avg steps: 147.6\t lr: 0.031620870661310065\t epsilon: 0.07374713720775837\n",
      "episode: 3699\t average reward: -136.8759018759019\t avg steps: 208.9\t lr: 0.03146316091094128\t epsilon: 0.07351084924455985\n",
      "episode: 3709\t average reward: -119.51669758812616\t avg steps: 216.6\t lr: 0.03130623774123398\t epsilon: 0.07327691238587825\n",
      "episode: 3719\t average reward: -107.66248746238716\t avg steps: 200.4\t lr: 0.03115009722910074\t epsilon: 0.0730453032378327\n",
      "episode: 3729\t average reward: -109.69577598481253\t avg steps: 211.7\t lr: 0.03099473547102063\t epsilon: 0.07281599863931543\n",
      "episode: 3739\t average reward: -116.19848484848485\t avg steps: 199.0\t lr: 0.03084014858294161\t epsilon: 0.07258897565967548\n",
      "episode: 3749\t average reward: -82.90056639395847\t avg steps: 159.9\t lr: 0.03068633270018342\t epsilon: 0.07236421159642571\n",
      "episode: 3759\t average reward: -89.84451038575668\t avg steps: 169.5\t lr: 0.03053328397734098\t epsilon: 0.0721416839729725\n",
      "episode: 3769\t average reward: -91.37564322469983\t avg steps: 175.9\t lr: 0.030380998588188247\t epsilon: 0.07192137053636805\n",
      "episode: 3779\t average reward: -86.0346062052506\t avg steps: 168.6\t lr: 0.030229472725582573\t epsilon: 0.07170324925508509\n",
      "episode: 3789\t average reward: -78.88165680473372\t avg steps: 153.1\t lr: 0.030078702601369484\t epsilon: 0.07148729831681375\n",
      "episode: 3799\t average reward: -84.49938650306748\t avg steps: 164.0\t lr: 0.029928684446288035\t epsilon: 0.07127349612628023\n",
      "episode: 3809\t average reward: -77.73373173970784\t avg steps: 151.6\t lr: 0.02977941450987653\t epsilon: 0.0710618213030873\n",
      "episode: 3819\t average reward: -74.27914951989025\t avg steps: 146.8\t lr: 0.02963088906037878\t epsilon: 0.07085225267957629\n",
      "episode: 3829\t average reward: -79.25978191148172\t avg steps: 156.9\t lr: 0.029483104384650818\t epsilon: 0.07064476929871014\n",
      "episode: 3839\t average reward: -79.83269961977186\t avg steps: 158.8\t lr: 0.029336056788068055\t epsilon: 0.07043935041197791\n",
      "episode: 3849\t average reward: -77.77784974093264\t avg steps: 155.4\t lr: 0.02918974259443291\t epsilon: 0.07023597547731972\n",
      "episode: 3859\t average reward: -81.49720670391062\t avg steps: 162.1\t lr: 0.02904415814588293\t epsilon: 0.07003462415707262\n",
      "episode: 3869\t average reward: -77.93571428571428\t avg steps: 155.0\t lr: 0.028899299802799313\t epsilon: 0.0698352763159368\n",
      "episode: 3879\t average reward: -71.39267767408471\t avg steps: 140.3\t lr: 0.02875516394371594\t epsilon: 0.06963791201896205\n",
      "episode: 3889\t average reward: -75.9395567494963\t avg steps: 149.9\t lr: 0.028611746965228824\t epsilon: 0.06944251152955416\n",
      "episode: 3899\t average reward: -75.19782460910945\t avg steps: 148.1\t lr: 0.02846904528190604\t epsilon: 0.06924905530750139\n",
      "episode: 3909\t average reward: -77.59961064243997\t avg steps: 155.1\t lr: 0.02832705532619806\t epsilon: 0.06905752400702028\n",
      "episode: 3919\t average reward: -77.42225113858166\t avg steps: 154.7\t lr: 0.02818577354834861\t epsilon: 0.06886789847482122\n",
      "episode: 3929\t average reward: -77.40262295081968\t avg steps: 153.5\t lr: 0.028045196416305873\t epsilon: 0.06868015974819293\n",
      "episode: 3939\t average reward: -79.08538163001293\t avg steps: 155.6\t lr: 0.02790532041563424\t epsilon: 0.06849428905310631\n",
      "episode: 3949\t average reward: -87.23914336704343\t avg steps: 169.1\t lr: 0.027766142049426398\t epsilon: 0.06831026780233695\n",
      "episode: 3959\t average reward: -78.90599455040872\t avg steps: 147.8\t lr: 0.02762765783821594\t epsilon: 0.06812807759360645\n",
      "episode: 3969\t average reward: -80.01736334405145\t avg steps: 156.5\t lr: 0.02748986431989039\t epsilon: 0.0679477002077421\n",
      "episode: 3979\t average reward: -76.21819425444596\t avg steps: 147.2\t lr: 0.027352758049604593\t epsilon: 0.06776911760685496\n",
      "episode: 3989\t average reward: -90.13949483352468\t avg steps: 175.2\t lr: 0.02721633559969467\t epsilon: 0.06759231193253618\n",
      "episode: 3999\t average reward: -91.09909909909909\t avg steps: 167.5\t lr: 0.027080593559592248\t epsilon: 0.06741726550407094\n",
      "episode: 4009\t average reward: -183.43854875283446\t avg steps: 221.5\t lr: 0.02694552853573927\t epsilon: 0.06724396081667056\n",
      "episode: 4019\t average reward: -76.88381464069846\t avg steps: 149.9\t lr: 0.026811137151503097\t epsilon: 0.06707238053972185\n",
      "episode: 4029\t average reward: -80.6484076433121\t avg steps: 158.0\t lr: 0.02667741604709213\t epsilon: 0.06690250751505415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4039\t average reward: -86.57913887204366\t avg steps: 165.9\t lr: 0.02654436187947179\t epsilon: 0.06673432475522344\n",
      "episode: 4049\t average reward: -90.00519630484989\t avg steps: 174.2\t lr: 0.026411971322280944\t epsilon: 0.06656781544181353\n",
      "episode: 4059\t average reward: -81.62430598396053\t avg steps: 163.1\t lr: 0.026280241065748795\t epsilon: 0.06640296292375439\n",
      "episode: 4069\t average reward: -78.83873056994818\t avg steps: 155.4\t lr: 0.026149167816612046\t epsilon: 0.06623975071565681\n",
      "episode: 4079\t average reward: -81.54579439252336\t avg steps: 161.5\t lr: 0.02601874829803266\t epsilon: 0.06607816249616397\n",
      "episode: 4089\t average reward: -83.83018867924528\t avg steps: 165.3\t lr: 0.02588897924951585\t epsilon: 0.06591818210631922\n",
      "episode: 4099\t average reward: -83.74728588661037\t avg steps: 166.8\t lr: 0.025759857426828677\t epsilon: 0.06575979354795033\n",
      "episode: 4109\t average reward: -80.80474111041796\t avg steps: 161.3\t lr: 0.02563137960191883\t epsilon: 0.06560298098206944\n",
      "episode: 4119\t average reward: -79.97166246851386\t avg steps: 159.8\t lr: 0.02550354256283401\t epsilon: 0.06544772872728928\n",
      "episode: 4129\t average reward: -79.6662452591656\t avg steps: 159.2\t lr: 0.025376343113641554\t epsilon: 0.065294021258255\n",
      "episode: 4139\t average reward: -78.54294871794872\t avg steps: 157.0\t lr: 0.025249778074348635\t epsilon: 0.06514184320409161\n",
      "episode: 4149\t average reward: -83.88519637462235\t avg steps: 166.5\t lr: 0.025123844280822667\t epsilon: 0.06499117934686686\n",
      "episode: 4159\t average reward: -81.64598997493734\t avg steps: 160.6\t lr: 0.02499853858471226\t epsilon: 0.0648420146200695\n",
      "episode: 4169\t average reward: -83.20233702337023\t avg steps: 163.6\t lr: 0.024873857853368465\t epsilon: 0.06469433410710253\n",
      "episode: 4179\t average reward: -76.91753926701571\t avg steps: 153.8\t lr: 0.02474979896976653\t epsilon: 0.06454812303979159\n",
      "episode: 4189\t average reward: -86.17581120943953\t avg steps: 170.5\t lr: 0.02462635883242789\t epsilon: 0.06440336679690811\n",
      "episode: 4199\t average reward: -85.4377605717689\t avg steps: 168.9\t lr: 0.02450353435534269\t epsilon: 0.06426005090270716\n",
      "episode: 4209\t average reward: -81.9863608183509\t avg steps: 162.3\t lr: 0.024381322467892583\t epsilon: 0.06411816102547989\n",
      "episode: 4219\t average reward: -87.17550058892814\t avg steps: 170.8\t lr: 0.02425972011477405\t epsilon: 0.06397768297612036\n",
      "episode: 4229\t average reward: -86.8407494145199\t avg steps: 171.8\t lr: 0.024138724255921916\t epsilon: 0.06383860270670653\n",
      "episode: 4239\t average reward: -108.02013778484367\t avg steps: 189.7\t lr: 0.0240183318664334\t epsilon: 0.0637009063090956\n",
      "episode: 4249\t average reward: -82.51321450522434\t avg steps: 163.7\t lr: 0.023898539936492505\t epsilon: 0.06356458001353302\n",
      "episode: 4259\t average reward: -86.96774193548387\t avg steps: 171.5\t lr: 0.023779345471294733\t epsilon: 0.06342961018727565\n",
      "episode: 4269\t average reward: -81.39332096474953\t avg steps: 162.7\t lr: 0.023660745490972256\t epsilon: 0.06329598333322839\n",
      "episode: 4279\t average reward: -80.540675844806\t avg steps: 160.8\t lr: 0.023542737030519387\t epsilon: 0.06316368608859449\n",
      "episode: 4289\t average reward: -82.57291666666667\t avg steps: 164.2\t lr: 0.023425317139718464\t epsilon: 0.06303270522353921\n",
      "episode: 4299\t average reward: -81.10018668326073\t avg steps: 161.7\t lr: 0.023308482883066094\t epsilon: 0.0629030276398669\n",
      "episode: 4309\t average reward: -80.0606826801517\t avg steps: 159.2\t lr: 0.023192231339699797\t epsilon: 0.06277464036971114\n",
      "episode: 4319\t average reward: -78.19625564880567\t avg steps: 155.9\t lr: 0.02307655960332492\t epsilon: 0.06264753057423793\n",
      "episode: 4329\t average reward: -81.44789081885857\t avg steps: 162.2\t lr: 0.022961464782142033\t epsilon: 0.06252168554236179\n",
      "episode: 4339\t average reward: -88.6354415274463\t avg steps: 168.6\t lr: 0.0228469439987746\t epsilon: 0.06239709268947464\n",
      "episode: 4349\t average reward: -86.86401425178147\t avg steps: 169.4\t lr: 0.02273299439019709\t epsilon: 0.062273739556187396\n",
      "episode: 4359\t average reward: -81.5577043044292\t avg steps: 161.3\t lr: 0.02261961310766335\t epsilon: 0.06215161380708392\n",
      "episode: 4369\t average reward: -82.42082563154652\t avg steps: 163.3\t lr: 0.022506797316635407\t epsilon: 0.06203070322948753\n",
      "episode: 4379\t average reward: -80.00575815738964\t avg steps: 157.3\t lr: 0.022394544196712596\t epsilon: 0.0619109957322397\n",
      "episode: 4389\t average reward: -80.0063051702396\t avg steps: 159.6\t lr: 0.0222828509415611\t epsilon: 0.061792479344490975\n",
      "episode: 4399\t average reward: -81.32585669781932\t avg steps: 161.5\t lr: 0.022171714758843705\t epsilon: 0.06167514221450379\n",
      "episode: 4409\t average reward: -79.8749198203977\t avg steps: 156.9\t lr: 0.022061132870150064\t epsilon: 0.06155897260846737\n",
      "episode: 4419\t average reward: -86.01244813278008\t avg steps: 169.7\t lr: 0.021951102510927183\t epsilon: 0.0614439589093243\n",
      "episode: 4429\t average reward: -78.84122919334187\t avg steps: 157.2\t lr: 0.021841620930410373\t epsilon: 0.06133008961560884\n",
      "episode: 4439\t average reward: -79.32867132867133\t avg steps: 158.3\t lr: 0.02173268539155441\t epsilon: 0.06121735334029671\n",
      "episode: 4449\t average reward: -82.17599502487562\t avg steps: 161.8\t lr: 0.021624293170965144\t epsilon: 0.06110573880966643\n",
      "episode: 4459\t average reward: -81.23872180451127\t avg steps: 160.6\t lr: 0.02151644155883141\t epsilon: 0.060995234862171926\n",
      "episode: 4469\t average reward: -89.239092495637\t avg steps: 172.9\t lr: 0.021409127858857305\t epsilon: 0.06088583044732637\n",
      "episode: 4479\t average reward: -80.93886462882097\t avg steps: 161.3\t lr: 0.02130234938819473\t epsilon: 0.060777514624597115\n",
      "episode: 4489\t average reward: -79.6768253968254\t avg steps: 158.5\t lr: 0.02119610347737636\t epsilon: 0.0606702765623116\n",
      "episode: 4499\t average reward: -80.91869918699187\t avg steps: 160.9\t lr: 0.02109038747024889\t epsilon: 0.06056410553657425\n",
      "episode: 4509\t average reward: -80.17888748419722\t avg steps: 159.2\t lr: 0.020985198723906626\t epsilon: 0.060458990930193995\n",
      "episode: 4519\t average reward: -86.97897196261682\t avg steps: 172.2\t lr: 0.020880534608625448\t epsilon: 0.06035492223162262\n",
      "episode: 4529\t average reward: -79.63757115749526\t avg steps: 159.1\t lr: 0.020776392507797014\t epsilon: 0.06025188903390354\n",
      "episode: 4539\t average reward: -84.89712918660287\t avg steps: 168.2\t lr: 0.02067276981786338\t epsilon: 0.06014988103363112\n",
      "episode: 4549\t average reward: -84.27942063971032\t avg steps: 166.7\t lr: 0.02056966394825189\t epsilon: 0.060048888029920325\n",
      "episode: 4559\t average reward: -88.3136574074074\t avg steps: 173.8\t lr: 0.020467072321310453\t epsilon: 0.05994889992338662\n",
      "episode: 4569\t average reward: -89.91873589164786\t avg steps: 178.2\t lr: 0.02036499237224304\t epsilon: 0.059849906715136035\n",
      "episode: 4579\t average reward: -88.34192439862542\t avg steps: 175.6\t lr: 0.020263421549045618\t epsilon: 0.05975189850576525\n",
      "episode: 4589\t average reward: -82.3997555012225\t avg steps: 164.6\t lr: 0.020162357312442297\t epsilon: 0.05965486549437164\n",
      "episode: 4599\t average reward: -83.28036253776435\t avg steps: 166.5\t lr: 0.020061797135821915\t epsilon: 0.05955879797757322\n",
      "episode: 4609\t average reward: -84.52389486260454\t avg steps: 168.4\t lr: 0.019961738505174822\t epsilon: 0.059463686348538256\n",
      "episode: 4619\t average reward: -81.9419394688079\t avg steps: 162.9\t lr: 0.019862178919030027\t epsilon: 0.05936952109602457\n",
      "episode: 4629\t average reward: -83.20716889428918\t avg steps: 165.6\t lr: 0.019763115888392694\t epsilon: 0.05927629280342844\n",
      "episode: 4639\t average reward: -83.82466747279322\t avg steps: 166.4\t lr: 0.019664546936681904\t epsilon: 0.05918399214784294\n",
      "episode: 4649\t average reward: -84.32170775706554\t avg steps: 167.3\t lr: 0.019566469599668734\t epsilon: 0.05909260989912557\n",
      "episode: 4659\t average reward: -85.06674612634089\t avg steps: 168.8\t lr: 0.019468881425414638\t epsilon: 0.05900213691897531\n",
      "episode: 4669\t average reward: -80.29229797979798\t avg steps: 159.4\t lr: 0.019371779974210177\t epsilon: 0.05891256416001875\n",
      "episode: 4679\t average reward: -84.25914817036593\t avg steps: 167.7\t lr: 0.019275162818514022\t epsilon: 0.058823882664905354\n",
      "episode: 4689\t average reward: -80.12633563796355\t avg steps: 160.1\t lr: 0.01917902754289225\t epsilon: 0.05873608356541171\n",
      "episode: 4699\t average reward: -80.80922693266832\t avg steps: 161.4\t lr: 0.01908337174395796\t epsilon: 0.05864915808155471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4709\t average reward: -79.91861198738171\t avg steps: 159.5\t lr: 0.018988193030311185\t epsilon: 0.05856309752071351\n",
      "episode: 4719\t average reward: -93.94698660714286\t avg steps: 180.2\t lr: 0.018893489022479143\t epsilon: 0.058477893276760326\n",
      "episode: 4729\t average reward: -78.05912930474334\t avg steps: 154.9\t lr: 0.018799257352856702\t epsilon: 0.058393536829199746\n",
      "episode: 4739\t average reward: -81.4669163545568\t avg steps: 161.2\t lr: 0.01870549566564721\t epsilon: 0.058310019742316734\n",
      "episode: 4749\t average reward: -84.71978021978022\t avg steps: 164.8\t lr: 0.018612201616803607\t epsilon: 0.058227333664332984\n",
      "episode: 4759\t average reward: -80.63276836158192\t avg steps: 160.3\t lr: 0.018519372873969802\t epsilon: 0.0581454703265718\n",
      "episode: 4769\t average reward: -81.24811557788945\t avg steps: 160.2\t lr: 0.018427007116422405\t epsilon: 0.058064421542631195\n",
      "episode: 4779\t average reward: -90.57289879931389\t avg steps: 175.9\t lr: 0.01833510203501266\t epsilon: 0.057984179207565226\n",
      "episode: 4789\t average reward: -86.19075829383887\t avg steps: 169.8\t lr: 0.01824365533210874\t epsilon: 0.05790473529707352\n",
      "episode: 4799\t average reward: -92.38392857142857\t avg steps: 180.2\t lr: 0.01815266472153831\t epsilon: 0.05782608186669881\n",
      "episode: 4809\t average reward: -81.72111801242237\t avg steps: 162.0\t lr: 0.018062127928531378\t epsilon: 0.05774821105103254\n",
      "episode: 4819\t average reward: -78.53831294269156\t avg steps: 156.3\t lr: 0.017972042689663396\t epsilon: 0.057671115062928234\n",
      "episode: 4829\t average reward: -83.23715170278638\t avg steps: 162.5\t lr: 0.0178824067527987\t epsilon: 0.05759478619272284\n",
      "episode: 4839\t average reward: -83.86131386861314\t avg steps: 165.4\t lr: 0.017793217877034192\t epsilon: 0.05751921680746572\n",
      "episode: 4849\t average reward: -86.38655462184875\t avg steps: 167.6\t lr: 0.01770447383264335\t epsilon: 0.057444399350155384\n",
      "episode: 4859\t average reward: -75.79959239130434\t avg steps: 148.2\t lr: 0.01761617240102043\t epsilon: 0.05737032633898376\n",
      "episode: 4869\t average reward: -86.36\t avg steps: 166.0\t lr: 0.017528311374625048\t epsilon: 0.05729699036658799\n",
      "episode: 4879\t average reward: -84.35995009357455\t avg steps: 161.3\t lr: 0.017440888556926958\t epsilon: 0.05722438409930971\n",
      "episode: 4889\t average reward: -80.41377132027796\t avg steps: 159.3\t lr: 0.017353901762351177\t epsilon: 0.05715250027646172\n",
      "episode: 4899\t average reward: -114.44116310767834\t avg steps: 221.1\t lr: 0.017267348816223303\t epsilon: 0.0570813317096018\n",
      "episode: 4909\t average reward: -99.27600627286984\t avg steps: 192.3\t lr: 0.01718122755471518\t epsilon: 0.05701087128181397\n",
      "episode: 4919\t average reward: -115.01205357142857\t avg steps: 225.0\t lr: 0.017095535824790772\t epsilon: 0.05694111194699674\n",
      "episode: 4929\t average reward: -114.71792618629173\t avg steps: 228.6\t lr: 0.017010271484152385\t epsilon: 0.056872046729158486\n",
      "episode: 4939\t average reward: -107.05660377358491\t avg steps: 202.4\t lr: 0.016925432401187056\t epsilon: 0.05680366872171987\n",
      "episode: 4949\t average reward: -76.61416280608869\t avg steps: 152.1\t lr: 0.016841016454913284\t epsilon: 0.05673597108682318\n",
      "episode: 4959\t average reward: -79.51592356687898\t avg steps: 158.0\t lr: 0.016757021534928022\t epsilon: 0.056668947054648484\n",
      "episode: 4969\t average reward: -75.20816326530613\t avg steps: 148.0\t lr: 0.016673445541353898\t epsilon: 0.05660258992273674\n",
      "episode: 4979\t average reward: -75.62709590878605\t avg steps: 150.1\t lr: 0.01659028638478672\t epsilon: 0.05653689305531944\n",
      "episode: 4989\t average reward: -70.2368804664723\t avg steps: 138.2\t lr: 0.016507541986243237\t epsilon: 0.056471849882655106\n",
      "episode: 4999\t average reward: -80.2235824742268\t avg steps: 156.2\t lr: 0.016425210277109182\t epsilon: 0.05640745390037226\n",
      "episode: 5009\t average reward: -71.32858161083392\t avg steps: 141.3\t lr: 0.016343289199087525\t epsilon: 0.05634369866881901\n",
      "episode: 5019\t average reward: -75.47319034852546\t avg steps: 150.2\t lr: 0.01626177670414707\t epsilon: 0.05628057781241908\n",
      "episode: 5029\t average reward: -72.63719298245614\t avg steps: 143.5\t lr: 0.016180670754471185\t epsilon: 0.05621808501903423\n",
      "episode: 5039\t average reward: -75.59838274932615\t avg steps: 149.4\t lr: 0.016099969322406902\t epsilon: 0.05615621403933303\n",
      "episode: 5049\t average reward: -71.41535150645625\t avg steps: 140.4\t lr: 0.016019670390414215\t epsilon: 0.05609495868616596\n",
      "episode: 5059\t average reward: -72.83932346723044\t avg steps: 142.9\t lr: 0.015939771951015657\t epsilon: 0.05603431283394666\n",
      "episode: 5069\t average reward: -77.08167330677291\t avg steps: 151.6\t lr: 0.015860272006746067\t epsilon: 0.05597427041803936\n",
      "episode: 5079\t average reward: -76.24391891891892\t avg steps: 149.0\t lr: 0.015781168570102706\t epsilon: 0.055914825434152444\n",
      "episode: 5089\t average reward: -77.47182175622542\t avg steps: 153.6\t lr: 0.015702459663495524\t epsilon: 0.055855971937737975\n",
      "episode: 5099\t average reward: -83.22\t avg steps: 166.0\t lr: 0.015624143319197776\t epsilon: 0.055797704043397275\n",
      "episode: 5109\t average reward: -75.6849593495935\t avg steps: 148.6\t lr: 0.015546217579296764\t epsilon: 0.055740015924292355\n",
      "episode: 5119\t average reward: -80.0727969348659\t avg steps: 157.6\t lr: 0.015468680495644935\t epsilon: 0.05568290181156322\n",
      "episode: 5129\t average reward: -91.98125\t avg steps: 177.0\t lr: 0.015391530129811152\t epsilon: 0.05562635599375101\n",
      "episode: 5139\t average reward: -80.4105534105534\t avg steps: 156.4\t lr: 0.015314764553032266\t epsilon: 0.05557037281622682\n",
      "episode: 5149\t average reward: -114.85500515995872\t avg steps: 194.8\t lr: 0.015238381846164845\t epsilon: 0.05551494668062625\n",
      "episode: 5159\t average reward: -77.97124183006535\t avg steps: 154.0\t lr: 0.01516238009963725\t epsilon: 0.05546007204428955\n",
      "episode: 5169\t average reward: -79.22350674373796\t avg steps: 156.7\t lr: 0.015086757413401842\t epsilon: 0.055405743419707346\n",
      "episode: 5179\t average reward: -76.50501002004007\t avg steps: 150.7\t lr: 0.015011511896887549\t epsilon: 0.05535195537397192\n",
      "episode: 5189\t average reward: -77.96854521625164\t avg steps: 153.6\t lr: 0.014936641668952526\t epsilon: 0.055298702528233865\n",
      "episode: 5199\t average reward: -83.16940889701402\t avg steps: 165.1\t lr: 0.014862144857837179\t epsilon: 0.05524597955716423\n",
      "episode: 5209\t average reward: -80.84571062740076\t avg steps: 157.2\t lr: 0.014788019601117343\t epsilon: 0.055193781188421984\n",
      "episode: 5219\t average reward: -78.09210526315789\t avg steps: 153.0\t lr: 0.014714264045657746\t epsilon: 0.05514210220212674\n",
      "episode: 5229\t average reward: -76.09336941813261\t avg steps: 148.8\t lr: 0.014640876347565666\t epsilon: 0.055090937430336814\n",
      "episode: 5239\t average reward: -77.18259162303664\t avg steps: 153.8\t lr: 0.014567854672144817\t epsilon: 0.055040281756532375\n",
      "episode: 5249\t average reward: -76.41924851680949\t avg steps: 152.7\t lr: 0.014495197193849516\t epsilon: 0.05499013011510385\n",
      "episode: 5259\t average reward: -77.40456026058632\t avg steps: 154.5\t lr: 0.014422902096239013\t epsilon: 0.054940477490845276\n",
      "episode: 5269\t average reward: -77.73424301494477\t avg steps: 154.9\t lr: 0.014350967571932117\t epsilon: 0.05489131891845287\n",
      "episode: 5279\t average reward: -78.32303732303733\t avg steps: 156.4\t lr: 0.014279391822561965\t epsilon: 0.05484264948202843\n",
      "episode: 5289\t average reward: -77.70454545454545\t avg steps: 155.0\t lr: 0.014208173058731097\t epsilon: 0.054794464314587746\n",
      "episode: 5299\t average reward: -77.36351791530944\t avg steps: 154.5\t lr: 0.014137309499966702\t epsilon: 0.054746758597573913\n",
      "episode: 5309\t average reward: -73.26089965397924\t avg steps: 145.5\t lr: 0.014066799374676128\t epsilon: 0.05469952756037549\n",
      "episode: 5319\t average reward: -73.70413793103448\t avg steps: 146.0\t lr: 0.013996640920102568\t epsilon: 0.05465276647984938\n",
      "episode: 5329\t average reward: -71.72921108742004\t avg steps: 141.7\t lr: 0.013926832382281006\t epsilon: 0.054606470679848584\n",
      "episode: 5339\t average reward: -72.2655921513665\t avg steps: 143.7\t lr: 0.01385737201599435\t epsilon: 0.054560635530754506\n",
      "episode: 5349\t average reward: -72.91829608938548\t avg steps: 144.2\t lr: 0.013788258084729839\t epsilon: 0.054515256449014046\n",
      "episode: 5359\t average reward: -76.24487094639312\t avg steps: 152.1\t lr: 0.013719488860635582\t epsilon: 0.054470328896681214\n",
      "episode: 5369\t average reward: -73.49065743944637\t avg steps: 145.5\t lr: 0.0136510626244774\t epsilon: 0.05442584838096334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5379\t average reward: -75.5954454119223\t avg steps: 150.3\t lr: 0.013582977665595818\t epsilon: 0.05438181045377178\n",
      "episode: 5389\t average reward: -76.85507246376811\t avg steps: 152.8\t lr: 0.01351523228186333\t epsilon: 0.05433821071127712\n",
      "episode: 5399\t average reward: -75.50503018108652\t avg steps: 150.1\t lr: 0.013447824779641805\t epsilon: 0.05429504479346877\n",
      "episode: 5409\t average reward: -74.05223367697594\t avg steps: 146.5\t lr: 0.013380753473740181\t epsilon: 0.054252308383718986\n",
      "episode: 5419\t average reward: -73.96978021978022\t avg steps: 146.6\t lr: 0.013314016687372308\t epsilon: 0.05420999720835117\n",
      "episode: 5429\t average reward: -78.51579626047712\t avg steps: 156.1\t lr: 0.013247612752115065\t epsilon: 0.05416810703621254\n",
      "episode: 5439\t average reward: -74.3828178694158\t avg steps: 146.5\t lr: 0.013181540007866605\t epsilon: 0.05412663367825096\n",
      "episode: 5449\t average reward: -77.41858932102835\t avg steps: 152.7\t lr: 0.013115796802804884\t epsilon: 0.054085572987096084\n",
      "episode: 5459\t average reward: -73.17482517482517\t avg steps: 144.0\t lr: 0.013050381493346336\t epsilon: 0.05404492085664457\n",
      "episode: 5469\t average reward: -72.07399425287356\t avg steps: 140.2\t lr: 0.01298529244410484\t epsilon: 0.0540046732216495\n",
      "episode: 5479\t average reward: -75.21191135734072\t avg steps: 145.4\t lr: 0.012920528027850764\t epsilon: 0.053964826057313835\n",
      "episode: 5489\t average reward: -72.58707865168539\t avg steps: 143.4\t lr: 0.01285608662547033\t epsilon: 0.05392537537888793\n",
      "episode: 5499\t average reward: -182.08946412352407\t avg steps: 221.2\t lr: 0.012791966625925112\t epsilon: 0.053886317241271076\n",
      "episode: 5509\t average reward: -81.50162443144899\t avg steps: 154.9\t lr: 0.0127281664262118\t epsilon: 0.05384764773861695\n",
      "episode: 5519\t average reward: -72.82857142857142\t avg steps: 137.5\t lr: 0.012664684431322066\t epsilon: 0.053809363003943074\n",
      "episode: 5529\t average reward: -62.86104218362283\t avg steps: 121.9\t lr: 0.012601519054202738\t epsilon: 0.05377145920874407\n",
      "episode: 5539\t average reward: -93.12006861063465\t avg steps: 175.9\t lr: 0.01253866871571609\t epsilon: 0.05373393256260884\n",
      "episode: 5549\t average reward: -84.70080197409007\t avg steps: 163.1\t lr: 0.01247613184460039\t epsilon: 0.05369677931284149\n",
      "episode: 5559\t average reward: -73.20477568740955\t avg steps: 139.2\t lr: 0.012413906877430608\t epsilon: 0.05365999574408608\n",
      "episode: 5569\t average reward: -75.66315049226442\t avg steps: 143.2\t lr: 0.01235199225857932\t epsilon: 0.053623578177955086\n",
      "episode: 5579\t average reward: -91.52832305103757\t avg steps: 179.3\t lr: 0.01229038644017783\t epsilon: 0.05358752297266155\n",
      "episode: 5589\t average reward: -77.4235294117647\t avg steps: 145.5\t lr: 0.012229087882077464\t epsilon: 0.05355182652265488\n",
      "episode: 5599\t average reward: -75.63055555555556\t avg steps: 145.0\t lr: 0.012168095051811087\t epsilon: 0.05351648525826035\n",
      "episode: 5609\t average reward: -67.8216810683425\t avg steps: 128.3\t lr: 0.01210740642455476\t epsilon: 0.053481495645322064\n",
      "episode: 5619\t average reward: -76.24\t avg steps: 143.5\t lr: 0.012047020483089643\t epsilon: 0.05344685418484956\n",
      "episode: 5629\t average reward: -73.05650929899856\t avg steps: 140.8\t lr: 0.011986935717764047\t epsilon: 0.05341255741266793\n",
      "episode: 5639\t average reward: -75.16830294530155\t avg steps: 143.6\t lr: 0.011927150626455722\t epsilon: 0.05337860189907138\n",
      "episode: 5649\t average reward: -72.08014705882353\t avg steps: 137.0\t lr: 0.011867663714534262\t epsilon: 0.05334498424848024\n",
      "episode: 5659\t average reward: -75.76939203354297\t avg steps: 144.1\t lr: 0.011808473494823774\t epsilon: 0.053311701099101445\n",
      "episode: 5669\t average reward: -78.75151108126259\t avg steps: 149.9\t lr: 0.011749578487565679\t epsilon: 0.053278749122592325\n",
      "episode: 5679\t average reward: -90.6168009205984\t avg steps: 174.8\t lr: 0.011690977220381732\t epsilon: 0.05324612502372776\n",
      "episode: 5689\t average reward: -88.07628128724673\t avg steps: 168.8\t lr: 0.011632668228237204\t epsilon: 0.05321382554007068\n",
      "episode: 5699\t average reward: -87.06912991656735\t avg steps: 168.8\t lr: 0.011574650053404249\t epsilon: 0.053181847441645815\n",
      "episode: 5709\t average reward: -89.22133938706015\t avg steps: 177.2\t lr: 0.011516921245425471\t epsilon: 0.05315018753061665\n",
      "episode: 5719\t average reward: -89.92425098925946\t avg steps: 177.9\t lr: 0.011459480361077672\t epsilon: 0.05311884264096572\n",
      "episode: 5729\t average reward: -89.05343945423536\t avg steps: 176.9\t lr: 0.01140232596433575\t epsilon: 0.05308780963817793\n",
      "episode: 5739\t average reward: -85.72968197879858\t avg steps: 170.8\t lr: 0.011345456626336807\t epsilon: 0.05305708541892713\n",
      "episode: 5749\t average reward: -83.98795906080674\t avg steps: 167.1\t lr: 0.011288870925344429\t epsilon: 0.05302666691076581\n",
      "episode: 5759\t average reward: -90.00448681996635\t avg steps: 179.3\t lr: 0.011232567446713151\t epsilon: 0.052996551071817805\n",
      "episode: 5769\t average reward: -86.92146596858639\t avg steps: 172.9\t lr: 0.01117654478285307\t epsilon: 0.052966734890474106\n",
      "episode: 5779\t average reward: -88.01208981001727\t avg steps: 174.7\t lr: 0.011120801533194676\t epsilon: 0.052937215385091746\n",
      "episode: 5789\t average reward: -84.15051173991571\t avg steps: 167.1\t lr: 0.011065336304153817\t epsilon: 0.05290798960369558\n",
      "episode: 5799\t average reward: -87.45704266510812\t avg steps: 172.1\t lr: 0.011010147709096878\t epsilon: 0.05287905462368312\n",
      "episode: 5809\t average reward: -80.57079365079365\t avg steps: 158.5\t lr: 0.010955234368306118\t epsilon: 0.052850407551532246\n",
      "episode: 5819\t average reward: -87.39677047289504\t avg steps: 174.4\t lr: 0.01090059490894515\t epsilon: 0.05282204552251187\n",
      "episode: 5829\t average reward: -86.06106870229007\t avg steps: 171.3\t lr: 0.010846227965024647\t epsilon: 0.05279396570039547\n",
      "episode: 5839\t average reward: -89.58896396396396\t avg steps: 178.6\t lr: 0.010792132177368172\t epsilon: 0.05276616527717741\n",
      "episode: 5849\t average reward: -85.21008902077152\t avg steps: 169.5\t lr: 0.010738306193578226\t epsilon: 0.05273864147279221\n",
      "episode: 5859\t average reward: -85.64319809069212\t avg steps: 168.6\t lr: 0.010684748668002408\t epsilon: 0.05271139153483651\n",
      "episode: 5869\t average reward: -85.62441037735849\t avg steps: 170.6\t lr: 0.010631458261699787\t epsilon: 0.05268441273829379\n",
      "episode: 5879\t average reward: -88.12278697886921\t avg steps: 176.1\t lr: 0.010578433642407426\t epsilon: 0.05265770238526191\n",
      "episode: 5889\t average reward: -86.39917452830188\t avg steps: 170.6\t lr: 0.01052567348450709\t epsilon: 0.05263125780468332\n",
      "episode: 5899\t average reward: -89.42395005675368\t avg steps: 177.2\t lr: 0.01047317646899208\t epsilon: 0.05260507635207792\n",
      "episode: 5909\t average reward: -90.27961819202694\t avg steps: 179.1\t lr: 0.010420941283434274\t epsilon: 0.05257915540927864\n",
      "episode: 5919\t average reward: -89.42727787209961\t avg steps: 177.7\t lr: 0.010368966621951305\t epsilon: 0.052553492384169585\n",
      "episode: 5929\t average reward: -90.86681589255736\t avg steps: 179.7\t lr: 0.010317251185173942\t epsilon: 0.052528084710426866\n",
      "episode: 5939\t average reward: -87.97172533179457\t avg steps: 174.3\t lr: 0.010265793680213565\t epsilon: 0.05250292984726193\n",
      "episode: 5949\t average reward: -93.1444082519001\t avg steps: 185.2\t lr: 0.010214592820629871\t epsilon: 0.052478025279167506\n",
      "episode: 5959\t average reward: -90.75444444444445\t avg steps: 181.0\t lr: 0.010163647326398698\t epsilon: 0.052453368515666024\n",
      "episode: 5969\t average reward: -86.26709526592636\t avg steps: 172.1\t lr: 0.010112955923880047\t epsilon: 0.05242895709106059\n",
      "episode: 5979\t average reward: -86.56483644859813\t avg steps: 172.2\t lr: 0.01006251734578621\t epsilon: 0.0524047885641884\n",
      "episode: 5989\t average reward: -90.45667970933482\t avg steps: 179.9\t lr: 0.010012330331150107\t epsilon: 0.05238086051817663\n",
      "episode: 5999\t average reward: -83.52263126131562\t avg steps: 166.7\t lr: 0.009962393625293754\t epsilon: 0.05235717056020073\n",
      "episode: 6009\t average reward: -88.46026300743281\t avg steps: 175.9\t lr: 0.009912705979796913\t epsilon: 0.052333716321245165\n",
      "episode: 6019\t average reward: -88.59610983981693\t avg steps: 175.8\t lr: 0.009863266152465855\t epsilon: 0.052310495455866496\n",
      "episode: 6029\t average reward: -86.31887456037515\t avg steps: 171.6\t lr: 0.00981407290730232\t epsilon: 0.05228750564195883\n",
      "episode: 6039\t average reward: -87.63379469434832\t avg steps: 174.4\t lr: 0.009765125014472617\t epsilon: 0.052264744580521626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6049\t average reward: -88.236\t avg steps: 176.0\t lr: 0.009716421250276875\t epsilon: 0.052242209995429764\n",
      "episode: 6059\t average reward: -88.02527283170592\t avg steps: 175.1\t lr: 0.009667960397118456\t epsilon: 0.05221989963320596\n",
      "episode: 6069\t average reward: -89.56369785794814\t avg steps: 178.4\t lr: 0.009619741243473506\t epsilon: 0.0521978112627954\n",
      "episode: 6079\t average reward: -89.368986983588\t avg steps: 177.7\t lr: 0.009571762583860671\t epsilon: 0.05217594267534264\n",
      "episode: 6089\t average reward: -93.17128874388254\t avg steps: 184.9\t lr: 0.009524023218810957\t epsilon: 0.0521542916839707\n",
      "episode: 6099\t average reward: -87.66013824884793\t avg steps: 174.6\t lr: 0.00947652195483776\t epsilon: 0.0521328561235624\n",
      "episode: 6109\t average reward: -85.17399049881236\t avg steps: 169.4\t lr: 0.009429257604407007\t epsilon: 0.052111633850543855\n",
      "episode: 6119\t average reward: -86.76864801864802\t avg steps: 172.6\t lr: 0.009382228985907468\t epsilon: 0.052090622742670054\n",
      "episode: 6129\t average reward: -89.20112994350282\t avg steps: 178.0\t lr: 0.009335434923621232\t epsilon: 0.05206982069881272\n",
      "episode: 6139\t average reward: -86.80406976744186\t avg steps: 173.0\t lr: 0.009288874247694312\t epsilon: 0.05204922563875012\n",
      "episode: 6149\t average reward: -84.1063701923077\t avg steps: 167.4\t lr: 0.00924254579410738\t epsilon: 0.05202883550295909\n",
      "episode: 6159\t average reward: -86.74520069808028\t avg steps: 172.9\t lr: 0.009196448404646685\t epsilon: 0.05200864825240906\n",
      "episode: 6169\t average reward: -83.23728813559322\t avg steps: 166.2\t lr: 0.009150580926875082\t epsilon: 0.05198866186835814\n",
      "episode: 6179\t average reward: -86.63118091913904\t avg steps: 172.9\t lr: 0.00910494221410325\t epsilon: 0.051968874352151286\n",
      "episode: 6189\t average reward: -84.98692810457516\t avg steps: 169.3\t lr: 0.009059531125360986\t epsilon: 0.05194928372502038\n",
      "episode: 6199\t average reward: -87.28257093225245\t avg steps: 173.7\t lr: 0.009014346525368706\t epsilon: 0.05192988802788639\n",
      "episode: 6209\t average reward: -87.33775981524249\t avg steps: 174.2\t lr: 0.008969387284509056\t epsilon: 0.05191068532116343\n",
      "episode: 6219\t average reward: -86.90730011587486\t avg steps: 173.6\t lr: 0.008924652278798675\t epsilon: 0.05189167368456483\n",
      "episode: 6229\t average reward: -86.8397212543554\t avg steps: 173.2\t lr: 0.008880140389860094\t epsilon: 0.051872851216911084\n",
      "episode: 6239\t average reward: -85.89535567313345\t avg steps: 171.1\t lr: 0.008835850504893765\t epsilon: 0.051854216035939746\n",
      "episode: 6249\t average reward: -85.80873671782763\t avg steps: 170.4\t lr: 0.008791781516650256\t epsilon: 0.05183576627811719\n",
      "episode: 6259\t average reward: -90.62514156285391\t avg steps: 177.6\t lr: 0.008747932323402574\t epsilon: 0.05181750009845225\n",
      "episode: 6269\t average reward: -87.89861751152074\t avg steps: 174.6\t lr: 0.008704301828918596\t epsilon: 0.05179941567031175\n",
      "episode: 6279\t average reward: -89.69915492957746\t avg steps: 178.5\t lr: 0.008660888942433692\t epsilon: 0.05178151118523779\n",
      "episode: 6289\t average reward: -85.84443134944019\t avg steps: 170.7\t lr: 0.008617692578623437\t epsilon: 0.05176378485276696\n",
      "episode: 6299\t average reward: -81.84662956091528\t avg steps: 162.7\t lr: 0.008574711657576483\t epsilon: 0.05174623490025123\n",
      "episode: 6309\t average reward: -86.61117578579744\t avg steps: 172.8\t lr: 0.008531945104767572\t epsilon: 0.051728859572680724\n",
      "episode: 6319\t average reward: -83.39685420447671\t avg steps: 166.3\t lr: 0.008489391851030653\t epsilon: 0.051711657132508214\n",
      "episode: 6329\t average reward: -86.74520069808028\t avg steps: 172.9\t lr: 0.008447050832532164\t epsilon: 0.05169462585947533\n",
      "episode: 6339\t average reward: -84.81201665675194\t avg steps: 169.1\t lr: 0.008404920990744438\t epsilon: 0.05167776405044059\n",
      "episode: 6349\t average reward: -82.99209726443769\t avg steps: 165.5\t lr: 0.00836300127241924\t epsilon: 0.05166107001920904\n",
      "episode: 6359\t average reward: -96.03412217941663\t avg steps: 182.7\t lr: 0.008321290629561424\t epsilon: 0.05164454209636364\n",
      "episode: 6369\t average reward: -101.95541731467081\t avg steps: 193.9\t lr: 0.008279788019402752\t epsilon: 0.051628178629098326\n",
      "episode: 6379\t average reward: -89.64011299435029\t avg steps: 178.0\t lr: 0.008238492404375797\t epsilon: 0.05161197798105275\n",
      "episode: 6389\t average reward: -99.01738672286618\t avg steps: 190.8\t lr: 0.008197402752088044\t epsilon: 0.05159593853214859\n",
      "episode: 6399\t average reward: -86.70674486803519\t avg steps: 171.5\t lr: 0.008156518035296044\t epsilon: 0.051580058678427604\n",
      "episode: 6409\t average reward: -91.58950276243094\t avg steps: 182.0\t lr: 0.008115837231879744\t epsilon: 0.05156433683189118\n",
      "episode: 6419\t average reward: -89.20387243735763\t avg steps: 176.6\t lr: 0.008075359324816936\t epsilon: 0.05154877142034157\n",
      "episode: 6429\t average reward: -92.7609409190372\t avg steps: 183.8\t lr: 0.008035083302157846\t epsilon: 0.05153336088722463\n",
      "episode: 6439\t average reward: -90.33109243697479\t avg steps: 179.5\t lr: 0.007995008156999803\t epsilon: 0.05151810369147422\n",
      "episode: 6449\t average reward: -87.66414875072633\t avg steps: 173.1\t lr: 0.007955132887462094\t epsilon: 0.05150299830735805\n",
      "episode: 6459\t average reward: -90.00561482313307\t avg steps: 179.1\t lr: 0.007915456496660896\t epsilon: 0.05148804322432512\n",
      "episode: 6469\t average reward: -85.01666666666667\t avg steps: 169.0\t lr: 0.007875977992684384\t epsilon: 0.05147323694685466\n",
      "episode: 6479\t average reward: -89.08314350797266\t avg steps: 176.6\t lr: 0.007836696388567896\t epsilon: 0.05145857799430659\n",
      "episode: 6489\t average reward: -84.87395459976105\t avg steps: 168.4\t lr: 0.007797610702269281\t epsilon: 0.05144406490077343\n",
      "episode: 6499\t average reward: -86.95221445221445\t avg steps: 172.6\t lr: 0.007758719956644348\t epsilon: 0.05142969621493375\n",
      "episode: 6509\t average reward: -84.88961813842482\t avg steps: 168.6\t lr: 0.007720023179422434\t epsilon: 0.05141547049990697\n",
      "episode: 6519\t average reward: -88.34057142857142\t avg steps: 176.0\t lr: 0.00768151940318209\t epsilon: 0.05140138633310975\n",
      "episode: 6529\t average reward: -91.11732152739347\t avg steps: 181.7\t lr: 0.0076432076653269055\t epsilon: 0.05138744230611366\n",
      "episode: 6539\t average reward: -87.49190751445087\t avg steps: 174.0\t lr: 0.007605087008061439\t epsilon: 0.05137363702450439\n",
      "episode: 6549\t average reward: -88.50887235260447\t avg steps: 175.7\t lr: 0.007567156478367268\t epsilon: 0.05135996910774228\n",
      "episode: 6559\t average reward: -94.58916849015317\t avg steps: 183.8\t lr: 0.007529415127979184\t epsilon: 0.05134643718902424\n",
      "episode: 6569\t average reward: -85.77463126843658\t avg steps: 170.5\t lr: 0.007491862013361456\t epsilon: 0.05133303991514715\n",
      "episode: 6579\t average reward: -83.56450635978194\t avg steps: 166.1\t lr: 0.007454496195684263\t epsilon: 0.051319775946372444\n",
      "episode: 6589\t average reward: -89.38335220838051\t avg steps: 177.6\t lr: 0.007417316740800215\t epsilon: 0.05130664395629218\n",
      "episode: 6599\t average reward: -95.32436793975255\t avg steps: 186.9\t lr: 0.007380322719221008\t epsilon: 0.05129364263169643\n",
      "episode: 6609\t average reward: -91.20856507230256\t avg steps: 180.8\t lr: 0.007343513206094176\t epsilon: 0.05128077067244189\n",
      "episode: 6619\t average reward: -95.2572347266881\t avg steps: 187.6\t lr: 0.00730688728117997\t epsilon: 0.051268026791321905\n",
      "episode: 6629\t average reward: -88.5480324074074\t avg steps: 173.8\t lr: 0.007270444028828356\t epsilon: 0.051255409713937744\n",
      "episode: 6639\t average reward: -89.79240943070731\t avg steps: 174.9\t lr: 0.007234182537956137\t epsilon: 0.051242918178571156\n",
      "episode: 6649\t average reward: -96.63127001067235\t avg steps: 188.4\t lr: 0.007198101902024147\t epsilon: 0.05123055093605819\n",
      "episode: 6659\t average reward: -86.82843713278496\t avg steps: 171.2\t lr: 0.007162201219014609\t epsilon: 0.051218306749664294\n",
      "episode: 6669\t average reward: -88.92457142857143\t avg steps: 176.0\t lr: 0.007126479591408576\t epsilon: 0.05120618439496062\n",
      "episode: 6679\t average reward: -90.64029180695847\t avg steps: 179.2\t lr: 0.0070909361261635015\t epsilon: 0.051194182659701604\n",
      "episode: 6689\t average reward: -88.44367015098723\t avg steps: 173.2\t lr: 0.007055569934690902\t epsilon: 0.05118230034370371\n",
      "episode: 6699\t average reward: -77.2911475409836\t avg steps: 153.5\t lr: 0.007020380132834146\t epsilon: 0.051170536258725446\n",
      "episode: 6709\t average reward: -71.99147121535181\t avg steps: 141.7\t lr: 0.006985365840846355\t epsilon: 0.0511588892283485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6719\t average reward: -76.58486842105263\t avg steps: 153.0\t lr: 0.006950526183368407\t epsilon: 0.05114735808786013\n",
      "episode: 6729\t average reward: -73.46782006920415\t avg steps: 145.5\t lr: 0.0069158602894070515\t epsilon: 0.05113594168413669\n",
      "episode: 6739\t average reward: -76.65697290152016\t avg steps: 152.3\t lr: 0.006881367292313133\t epsilon: 0.05112463887552828\n",
      "episode: 6749\t average reward: -68.68195488721804\t avg steps: 134.0\t lr: 0.006847046329759923\t epsilon: 0.051113448531744626\n",
      "episode: 6759\t average reward: -73.05233775296581\t avg steps: 144.3\t lr: 0.006812896543721578\t epsilon: 0.051102369533742024\n",
      "episode: 6769\t average reward: -77.54025974025974\t avg steps: 155.0\t lr: 0.006778917080451665\t epsilon: 0.051091400773611434\n",
      "episode: 6779\t average reward: -77.29511400651465\t avg steps: 154.5\t lr: 0.006745107090461832\t epsilon: 0.05108054115446772\n",
      "episode: 6789\t average reward: -74.2319236016371\t avg steps: 147.6\t lr: 0.006711465728500569\t epsilon: 0.0510697895903399\n",
      "episode: 6799\t average reward: -78.59423076923076\t avg steps: 157.0\t lr: 0.006677992153532069\t epsilon: 0.0510591450060626\n",
      "episode: 6809\t average reward: -75.1105866486851\t avg steps: 149.3\t lr: 0.006644685528715225\t epsilon: 0.051048606337168546\n",
      "episode: 6819\t average reward: -76.12922868741542\t avg steps: 148.8\t lr: 0.006611545021382676\t epsilon: 0.051038172529782044\n",
      "episode: 6829\t average reward: -70.94981818181819\t avg steps: 138.5\t lr: 0.006578569803020013\t epsilon: 0.051027842540513665\n",
      "episode: 6839\t average reward: -73.95021037868163\t avg steps: 143.6\t lr: 0.006545759049245057\t epsilon: 0.051017615336355876\n",
      "episode: 6849\t average reward: -75.8527815468114\t avg steps: 148.4\t lr: 0.006513111939787259\t epsilon: 0.05100748989457974\n",
      "episode: 6859\t average reward: -75.80431848852902\t avg steps: 149.2\t lr: 0.006480627658467181\t epsilon: 0.05099746520263264\n",
      "episode: 6869\t average reward: -72.9150417827298\t avg steps: 144.6\t lr: 0.006448305393176099\t epsilon: 0.05098754025803702\n",
      "episode: 6879\t average reward: -75.53000674308834\t avg steps: 149.3\t lr: 0.006416144335855693\t epsilon: 0.050977714068290166\n",
      "episode: 6889\t average reward: -73.58298171589311\t avg steps: 143.2\t lr: 0.006384143682477858\t epsilon: 0.0509679856507649\n",
      "episode: 6899\t average reward: -66.59414556962025\t avg steps: 127.4\t lr: 0.006352302633024595\t epsilon: 0.05095835403261137\n",
      "episode: 6909\t average reward: -74.40786749482402\t avg steps: 145.9\t lr: 0.006320620391468007\t epsilon: 0.05094881825065973\n",
      "episode: 6919\t average reward: -76.46741277156023\t avg steps: 152.9\t lr: 0.0062890961657504005\t epsilon: 0.05093937735132384\n",
      "episode: 6929\t average reward: -73.25\t avg steps: 143.8\t lr: 0.0062577291677645\t epsilon: 0.050930030390505907\n",
      "episode: 6939\t average reward: -75.02972972972972\t avg steps: 149.0\t lr: 0.006226518613333717\t epsilon: 0.05092077643350205\n",
      "episode: 6949\t average reward: -77.4769330734243\t avg steps: 154.9\t lr: 0.0061954637221925644\t epsilon: 0.05091161455490885\n",
      "episode: 6959\t average reward: -75.28465679676985\t avg steps: 149.6\t lr: 0.0061645637179671454\t epsilon: 0.05090254383853083\n",
      "episode: 6969\t average reward: -74.89850136239782\t avg steps: 147.8\t lr: 0.006133817828155749\t epsilon: 0.050893563377288786\n",
      "episode: 6979\t average reward: -77.02827087442472\t avg steps: 153.1\t lr: 0.006103225284109527\t epsilon: 0.05088467227312911\n",
      "episode: 6989\t average reward: -71.16223977027997\t avg steps: 140.3\t lr: 0.0060727853210132835\t epsilon: 0.05087586963693397\n",
      "episode: 6999\t average reward: -78.17129928894634\t avg steps: 155.7\t lr: 0.006042497177866354\t epsilon: 0.05086715458843242\n",
      "episode: 7009\t average reward: -73.27797081306463\t avg steps: 144.9\t lr: 0.006012360097463588\t epsilon: 0.05085852625611235\n",
      "episode: 7019\t average reward: -69.12274096385542\t avg steps: 133.8\t lr: 0.0059823733263764025\t epsilon: 0.050849983777133324\n",
      "episode: 7029\t average reward: -74.59379310344828\t avg steps: 146.0\t lr: 0.005952536114933959\t epsilon: 0.05084152629724034\n",
      "episode: 7039\t average reward: -74.41804407713498\t avg steps: 146.2\t lr: 0.005922847717204413\t epsilon: 0.05083315297067835\n",
      "episode: 7049\t average reward: -77.70415814587594\t avg steps: 147.7\t lr: 0.005893307390976283\t epsilon: 0.05082486296010773\n",
      "episode: 7059\t average reward: -76.31112591605596\t avg steps: 151.1\t lr: 0.00586391439773987\t epsilon: 0.0508166554365205\n",
      "episode: 7069\t average reward: -74.24691358024691\t avg steps: 146.8\t lr: 0.005834668002668814\t epsilon: 0.05080852957915748\n",
      "episode: 7079\t average reward: -75.3913043478261\t avg steps: 148.2\t lr: 0.005805567474601713\t epsilon: 0.050800484575426144\n",
      "episode: 7089\t average reward: -76.6059405940594\t avg steps: 152.5\t lr: 0.005776612086023848\t epsilon: 0.050792519620819425\n",
      "episode: 7099\t average reward: -75.55466130114017\t avg steps: 150.1\t lr: 0.005747801113049002\t epsilon: 0.050784633918835226\n",
      "episode: 7109\t average reward: -73.47229916897507\t avg steps: 145.4\t lr: 0.0057191338354013466\t epsilon: 0.050776826680896774\n",
      "episode: 7119\t average reward: -76.88408644400786\t avg steps: 153.7\t lr: 0.005690609536397448\t epsilon: 0.05076909712627377\n",
      "episode: 7129\t average reward: -77.04530531845043\t avg steps: 153.3\t lr: 0.005662227502928344\t epsilon: 0.05076144448200431\n",
      "episode: 7139\t average reward: -79.38699291693496\t avg steps: 156.3\t lr: 0.0056339870254417225\t epsilon: 0.050753867982817585\n",
      "episode: 7149\t average reward: -75.58450233800936\t avg steps: 150.7\t lr: 0.005605887397924175\t epsilon: 0.05074636687105737\n",
      "episode: 7159\t average reward: -73.75386779184248\t avg steps: 143.2\t lr: 0.005577927917883549\t epsilon: 0.05073894039660624\n",
      "episode: 7169\t average reward: -76.64166108506363\t avg steps: 150.3\t lr: 0.0055501078863313845\t epsilon: 0.05073158781681055\n",
      "episode: 7179\t average reward: -80.9579409918393\t avg steps: 160.3\t lr: 0.0055224266077654495\t epsilon: 0.0507243083964062\n",
      "episode: 7189\t average reward: -82.75605214152701\t avg steps: 162.1\t lr: 0.005494883390152335\t epsilon: 0.050717101407445085\n",
      "episode: 7199\t average reward: -79.44074311338885\t avg steps: 157.1\t lr: 0.005467477544910167\t epsilon: 0.0507099661292223\n",
      "episode: 7209\t average reward: -74.43186440677967\t avg steps: 148.5\t lr: 0.005440208386891383\t epsilon: 0.050702901848204085\n",
      "episode: 7219\t average reward: -80.80166880616174\t avg steps: 156.8\t lr: 0.005413075234365619\t epsilon: 0.05069590785795643\n",
      "episode: 7229\t average reward: -83.41758917589176\t avg steps: 163.6\t lr: 0.005386077409002645\t epsilon: 0.05068898345907451\n",
      "episode: 7239\t average reward: -81.3552220137586\t avg steps: 160.9\t lr: 0.00535921423585542\t epsilon: 0.050682127959112644\n",
      "episode: 7249\t average reward: -77.17584605175846\t avg steps: 151.7\t lr: 0.005332485043343217\t epsilon: 0.05067534067251513\n",
      "episode: 7259\t average reward: -73.05547752808988\t avg steps: 143.4\t lr: 0.005305889163234833\t epsilon: 0.050668620920547656\n",
      "episode: 7269\t average reward: -73.31254429482637\t avg steps: 142.1\t lr: 0.005279425930631878\t epsilon: 0.050661968031229423\n",
      "episode: 7279\t average reward: -72.6777856635912\t avg steps: 141.9\t lr: 0.0052530946839521595\t epsilon: 0.050655381339265955\n",
      "episode: 7289\t average reward: -69.97584187408492\t avg steps: 137.6\t lr: 0.0052268947649131365\t epsilon: 0.05064886018598257\n",
      "episode: 7299\t average reward: -74.91554054054055\t avg steps: 149.0\t lr: 0.005200825518515473\t epsilon: 0.05064240391925849\n",
      "episode: 7309\t average reward: -77.37154150197628\t avg steps: 152.8\t lr: 0.005174886293026648\t epsilon: 0.05063601189346169\n",
      "episode: 7319\t average reward: -81.86438529784537\t avg steps: 158.8\t lr: 0.005149076439964676\t epsilon: 0.050629683469384235\n",
      "episode: 7329\t average reward: -72.88981868898188\t avg steps: 144.4\t lr: 0.005123395314081883\t epsilon: 0.05062341801417846\n",
      "episode: 7339\t average reward: -74.47799593771158\t avg steps: 148.7\t lr: 0.005097842273348785\t epsilon: 0.050617214901293624\n",
      "episode: 7349\t average reward: -71.07956989247312\t avg steps: 140.5\t lr: 0.005072416678938034\t epsilon: 0.05061107351041326\n",
      "episode: 7359\t average reward: -75.34408602150538\t avg steps: 149.8\t lr: 0.005047117895208446\t epsilon: 0.05060499322739317\n",
      "episode: 7369\t average reward: -71.9864768683274\t avg steps: 141.5\t lr: 0.005021945289689109\t epsilon: 0.05059897344419998\n",
      "episode: 7379\t average reward: -75.6912257200268\t avg steps: 150.3\t lr: 0.0049968982330635715\t epsilon: 0.050593013558850354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7389\t average reward: -78.51119894598155\t avg steps: 152.8\t lr: 0.004971976099154118\t epsilon: 0.0505871129753508\n",
      "episode: 7399\t average reward: -81.54615881213687\t avg steps: 155.9\t lr: 0.004947178264906101\t epsilon: 0.05058127110363804\n",
      "episode: 7409\t average reward: -78.12639161755075\t avg steps: 153.7\t lr: 0.004922504110372373\t epsilon: 0.050575487359520034\n",
      "episode: 7419\t average reward: -83.82125307125307\t avg steps: 163.8\t lr: 0.004897953018697783\t epsilon: 0.05056976116461756\n",
      "episode: 7429\t average reward: -71.8421433743664\t avg steps: 139.1\t lr: 0.004873524376103763\t epsilon: 0.050564091946306344\n",
      "episode: 7439\t average reward: -78.57758620689656\t avg steps: 151.8\t lr: 0.004849217571872976\t epsilon: 0.050558479137659845\n",
      "episode: 7449\t average reward: -76.58090185676393\t avg steps: 151.8\t lr: 0.0048250319983340504\t epsilon: 0.050552922177392504\n",
      "episode: 7459\t average reward: -75.76117411607738\t avg steps: 150.9\t lr: 0.004800967050846383\t epsilon: 0.050547420509803674\n",
      "episode: 7469\t average reward: -84.35501519756839\t avg steps: 165.5\t lr: 0.004777022127785042\t epsilon: 0.05054197358472202\n",
      "episode: 7479\t average reward: -83.84272445820433\t avg steps: 162.5\t lr: 0.004753196630525697\t epsilon: 0.05053658085745047\n",
      "episode: 7489\t average reward: -83.98482932996207\t avg steps: 159.2\t lr: 0.004729489963429678\t epsilon: 0.05053124178871183\n",
      "episode: 7499\t average reward: -82.78165938864629\t avg steps: 161.3\t lr: 0.0047059015338290705\t epsilon: 0.05052595584459475\n",
      "episode: 7509\t average reward: -78.29407979407979\t avg steps: 156.4\t lr: 0.004682430752011911\t epsilon: 0.05052072249650044\n",
      "episode: 7519\t average reward: -82.63782447466008\t avg steps: 162.8\t lr: 0.0046590770312074275\t epsilon: 0.05051554122108971\n",
      "episode: 7529\t average reward: -85.8891537544696\t avg steps: 168.8\t lr: 0.004635839787571385\t epsilon: 0.050510411500230716\n",
      "episode: 7539\t average reward: -86.51738865161684\t avg steps: 164.9\t lr: 0.00461271844017148\t epsilon: 0.05050533282094708\n",
      "episode: 7549\t average reward: -86.25296208530806\t avg steps: 169.8\t lr: 0.004589712410972827\t epsilon: 0.050500304675366654\n",
      "episode: 7559\t average reward: -79.36721728081322\t avg steps: 158.4\t lr: 0.004566821124823497\t epsilon: 0.05049532656067069\n",
      "episode: 7569\t average reward: -83.2735618115055\t avg steps: 164.4\t lr: 0.004544044009440142\t epsilon: 0.05049039797904356\n",
      "episode: 7579\t average reward: -78.95415848068107\t avg steps: 153.7\t lr: 0.004521380495393692\t epsilon: 0.05048551843762301\n",
      "episode: 7589\t average reward: -76.37752355316286\t avg steps: 149.6\t lr: 0.0044988300160951145\t epsilon: 0.050480687448450814\n",
      "episode: 7599\t average reward: -76.23030707610147\t avg steps: 150.8\t lr: 0.004476392007781255\t epsilon: 0.05047590452842404\n",
      "episode: 7609\t average reward: -81.08796007485964\t avg steps: 161.3\t lr: 0.004454065909500736\t epsilon: 0.0504711691992467\n",
      "episode: 7619\t average reward: -77.50260078023408\t avg steps: 154.8\t lr: 0.004431851163099937\t epsilon: 0.05046648098738192\n",
      "episode: 7629\t average reward: -80.61280101394169\t avg steps: 158.8\t lr: 0.004409747213209039\t epsilon: 0.05046183942400462\n",
      "episode: 7639\t average reward: -76.95625841184388\t avg steps: 149.6\t lr: 0.004387753507228149\t epsilon: 0.05045724404495459\n",
      "episode: 7649\t average reward: -83.31002475247524\t avg steps: 162.6\t lr: 0.004365869495313468\t epsilon: 0.050452694390690084\n",
      "episode: 7659\t average reward: -80.67567567567568\t avg steps: 160.1\t lr: 0.004344094630363559\t epsilon: 0.0504481900062419\n",
      "episode: 7669\t average reward: -78.07806451612903\t avg steps: 156.0\t lr: 0.004322428368005662\t epsilon: 0.05044373044116783\n",
      "episode: 7679\t average reward: -75.71916890080429\t avg steps: 150.2\t lr: 0.004300870166582094\t epsilon: 0.050439315249507656\n",
      "episode: 7689\t average reward: -81.78206724782068\t avg steps: 161.6\t lr: 0.004279419487136694\t epsilon: 0.05043494398973853\n",
      "episode: 7699\t average reward: -82.50246913580247\t avg steps: 163.0\t lr: 0.004258075793401359\t epsilon: 0.05043061622473083\n",
      "episode: 7709\t average reward: -76.12640635340834\t avg steps: 152.1\t lr: 0.004236838551782633\t epsilon: 0.050426331521704455\n",
      "episode: 7719\t average reward: -78.57520981278245\t avg steps: 155.9\t lr: 0.004215707231348373\t epsilon: 0.05042208945218552\n",
      "episode: 7729\t average reward: -82.85221674876847\t avg steps: 163.4\t lr: 0.004194681303814463\t epsilon: 0.050417889591963555\n",
      "episode: 7739\t average reward: -78.44919093851132\t avg steps: 155.5\t lr: 0.004173760243531622\t epsilon: 0.05041373152104903\n",
      "episode: 7749\t average reward: -75.65556295802799\t avg steps: 151.1\t lr: 0.004152943527472252\t epsilon: 0.05040961482363138\n",
      "episode: 7759\t average reward: -80.08946700507614\t avg steps: 158.6\t lr: 0.004132230635217369\t epsilon: 0.05040553908803744\n",
      "episode: 7769\t average reward: -83.52454940957116\t avg steps: 161.9\t lr: 0.004111621048943587\t epsilon: 0.05040150390669026\n",
      "episode: 7779\t average reward: -71.79347826086956\t avg steps: 139.0\t lr: 0.004091114253410176\t epsilon: 0.05039750887606833\n",
      "episode: 7789\t average reward: -77.55136540962289\t avg steps: 154.8\t lr: 0.004070709735946177\t epsilon: 0.050393553596665266\n",
      "episode: 7799\t average reward: -79.83111111111111\t avg steps: 158.5\t lr: 0.004050406986437596\t epsilon: 0.050389637672949836\n",
      "episode: 7809\t average reward: -81.8790523690773\t avg steps: 161.4\t lr: 0.004030205497314633\t epsilon: 0.0503857607133264\n",
      "episode: 7819\t average reward: -77.44046844502277\t avg steps: 154.7\t lr: 0.004010104763539011\t epsilon: 0.05038192233009576\n",
      "episode: 7829\t average reward: -81.55204460966543\t avg steps: 162.4\t lr: 0.003990104282591337\t epsilon: 0.050378122139416406\n",
      "episode: 7839\t average reward: -81.70792079207921\t avg steps: 162.6\t lr: 0.003970203554458544\t epsilon: 0.05037435976126609\n",
      "episode: 7849\t average reward: -81.45340838023765\t avg steps: 160.9\t lr: 0.003950402081621396\t epsilon: 0.05037063481940387\n",
      "episode: 7859\t average reward: -86.45081472540737\t avg steps: 166.7\t lr: 0.003930699369042038\t epsilon: 0.05036694694133245\n",
      "episode: 7869\t average reward: -85.46002386634845\t avg steps: 168.6\t lr: 0.003911094924151631\t epsilon: 0.05036329575826096\n",
      "episode: 7879\t average reward: -85.20898203592814\t avg steps: 168.0\t lr: 0.003891588256838029\t epsilon: 0.050359680905068045\n",
      "episode: 7889\t average reward: -81.93316831683168\t avg steps: 162.6\t lr: 0.0038721788794335364\t epsilon: 0.050356102020265366\n",
      "episode: 7899\t average reward: -82.86372007366482\t avg steps: 163.9\t lr: 0.0038528663067027057\t epsilon: 0.05035255874596147\n",
      "episode: 7909\t average reward: -79.16284987277353\t avg steps: 158.2\t lr: 0.003833650055830213\t epsilon: 0.050349050727825966\n",
      "episode: 7919\t average reward: -83.25258673158855\t avg steps: 165.3\t lr: 0.0038145296464087842\t epsilon: 0.05034557761505413\n",
      "episode: 7929\t average reward: -81.95182211241507\t avg steps: 162.9\t lr: 0.003795504600427191\t epsilon: 0.050342139060331775\n",
      "episode: 7939\t average reward: -84.23272727272727\t avg steps: 166.0\t lr: 0.0037765744422582903\t epsilon: 0.05033873471980057\n",
      "episode: 7949\t average reward: -76.77230971128608\t avg steps: 153.4\t lr: 0.0037577386986471437\t epsilon: 0.05033536425302362\n",
      "episode: 7959\t average reward: -84.05939393939394\t avg steps: 166.0\t lr: 0.003738996898699177\t epsilon: 0.05033202732295145\n",
      "episode: 7969\t average reward: -82.422934648582\t avg steps: 163.2\t lr: 0.0037203485738684186\t epsilon: 0.05032872359588827\n",
      "episode: 7979\t average reward: -83.15441176470588\t avg steps: 164.2\t lr: 0.003701793257945776\t epsilon: 0.05032545274145861\n",
      "episode: 7989\t average reward: -85.8352375225496\t avg steps: 167.3\t lr: 0.003683330487047383\t epsilon: 0.05032221443257431\n",
      "episode: 7999\t average reward: -84.8447242206235\t avg steps: 167.8\t lr: 0.003664959799603006\t epsilon: 0.050319008345401775\n",
      "episode: 8009\t average reward: -80.32828282828282\t avg steps: 159.4\t lr: 0.003646680736344503\t epsilon: 0.05031583415932962\n",
      "episode: 8019\t average reward: -81.02311055590256\t avg steps: 161.1\t lr: 0.0036284928402943403\t epsilon: 0.0503126915569366\n",
      "episode: 8029\t average reward: -81.04364089775561\t avg steps: 161.4\t lr: 0.0036103956567541695\t epsilon: 0.05030958022395985\n",
      "episode: 8039\t average reward: -81.66666666666667\t avg steps: 161.8\t lr: 0.003592388733293459\t epsilon: 0.050306499849263484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 8049\t average reward: -78.3363344051447\t avg steps: 156.5\t lr: 0.0035744716197381853\t epsilon: 0.050303450124807456\n",
      "episode: 8059\t average reward: -78.50096215522771\t avg steps: 156.9\t lr: 0.003556643868159572\t epsilon: 0.050300430745616784\n",
      "episode: 8069\t average reward: -84.38164251207729\t avg steps: 166.6\t lr: 0.003538905032862907\t epsilon: 0.05029744140975104\n",
      "episode: 8079\t average reward: -80.51635220125786\t avg steps: 160.0\t lr: 0.0035212546703763826\t epsilon: 0.05029448181827413\n",
      "episode: 8089\t average reward: -84.89268585131894\t avg steps: 167.8\t lr: 0.0035036923394400157\t epsilon: 0.050291551675224457\n",
      "episode: 8099\t average reward: -83.91883706844337\t avg steps: 166.1\t lr: 0.00348621760099462\t epsilon: 0.050288650687585264\n",
      "episode: 8109\t average reward: -79.80342422320862\t avg steps: 158.7\t lr: 0.0034688300181708225\t epsilon: 0.050285778565255373\n",
      "episode: 8119\t average reward: -79.34735500318675\t avg steps: 157.9\t lr: 0.003451529156278147\t epsilon: 0.05028293502102016\n",
      "episode: 8129\t average reward: -77.0\t avg steps: 153.9\t lr: 0.003434314582794147\t epsilon: 0.050280119770522824\n",
      "episode: 8139\t average reward: -80.30245746691871\t avg steps: 159.7\t lr: 0.0034171858673535866\t epsilon: 0.05027733253223598\n",
      "episode: 8149\t average reward: -80.08654453569173\t avg steps: 159.3\t lr: 0.0034001425817376863\t epsilon: 0.05027457302743347\n",
      "episode: 8159\t average reward: -77.98708010335918\t avg steps: 155.8\t lr: 0.003383184299863423\t epsilon: 0.05027184098016251\n",
      "episode: 8169\t average reward: -78.1418439716312\t avg steps: 156.1\t lr: 0.003366310597772864\t epsilon: 0.050269136117216104\n",
      "episode: 8179\t average reward: -79.88403041825094\t avg steps: 158.8\t lr: 0.0033495210536225784\t epsilon: 0.050266458168105696\n",
      "episode: 8189\t average reward: -78.92889173606662\t avg steps: 157.1\t lr: 0.003332815247673087\t epsilon: 0.05026380686503416\n",
      "episode: 8199\t average reward: -82.28685996298582\t avg steps: 163.1\t lr: 0.0033161927622783723\t epsilon: 0.05026118194286895\n",
      "episode: 8209\t average reward: -76.9527868852459\t avg steps: 153.5\t lr: 0.003299653181875433\t epsilon: 0.050258583139115694\n",
      "episode: 8219\t average reward: -78.61107533805537\t avg steps: 156.3\t lr: 0.0032831960929738976\t epsilon: 0.05025601019389183\n",
      "episode: 8229\t average reward: -83.78915295551494\t avg steps: 165.1\t lr: 0.003266821084145684\t epsilon: 0.0502534628499007\n",
      "episode: 8239\t average reward: -80.61973601508485\t avg steps: 160.1\t lr: 0.0032505277460147235\t epsilon: 0.05025094085240578\n",
      "episode: 8249\t average reward: -86.98357771260997\t avg steps: 171.5\t lr: 0.003234315671246712\t epsilon: 0.05024844394920521\n",
      "episode: 8259\t average reward: -80.15719696969697\t avg steps: 159.4\t lr: 0.0032181844545389354\t epsilon: 0.05024597189060661\n",
      "episode: 8269\t average reward: -79.60076287349014\t avg steps: 158.3\t lr: 0.003202133692610137\t epsilon: 0.05024352442940204\n",
      "episode: 8279\t average reward: -80.60943396226415\t avg steps: 160.0\t lr: 0.0031861629841904307\t epsilon: 0.050241101320843355\n",
      "episode: 8289\t average reward: -80.58875552747946\t avg steps: 159.3\t lr: 0.003170271930011276\t epsilon: 0.050238702322617665\n",
      "episode: 8299\t average reward: -80.57558507273878\t avg steps: 159.1\t lr: 0.00315446013279549\t epsilon: 0.05023632719482316\n",
      "episode: 8309\t average reward: -79.50541746335246\t avg steps: 157.9\t lr: 0.003138727197247316\t epsilon: 0.050233975699945074\n",
      "episode: 8319\t average reward: -81.39850560398506\t avg steps: 161.6\t lr: 0.0031230727300425513\t epsilon: 0.05023164760283197\n",
      "episode: 8329\t average reward: -79.01343570057581\t avg steps: 157.3\t lr: 0.003107496339818698\t epsilon: 0.05022934267067219\n",
      "episode: 8339\t average reward: -81.94990723562152\t avg steps: 162.7\t lr: 0.003091997637165189\t epsilon: 0.050227060672970586\n",
      "episode: 8349\t average reward: -82.06571605703658\t avg steps: 162.3\t lr: 0.0030765762346136507\t epsilon: 0.050224801381525505\n",
      "episode: 8359\t average reward: -83.62659380692168\t avg steps: 165.7\t lr: 0.0030612317466282165\t epsilon: 0.05022256457040591\n",
      "episode: 8369\t average reward: -80.10342639593908\t avg steps: 158.6\t lr: 0.0030459637895958874\t epsilon: 0.050220350015928825\n",
      "episode: 8379\t average reward: -74.73045822102426\t avg steps: 149.4\t lr: 0.003030771981816942\t epsilon: 0.05021815749663696\n",
      "episode: 8389\t average reward: -78.51979234263466\t avg steps: 155.1\t lr: 0.0030156559434953946\t epsilon: 0.05021598679327656\n",
      "episode: 8399\t average reward: -77.73450750163079\t avg steps: 154.3\t lr: 0.0030006152967294976\t epsilon: 0.05021383768877547\n",
      "episode: 8409\t average reward: -78.14276443867618\t avg steps: 155.1\t lr: 0.0029856496655023042\t epsilon: 0.05021170996822146\n",
      "episode: 8419\t average reward: -81.18193224592221\t avg steps: 160.4\t lr: 0.0029707586756722503\t epsilon: 0.0502096034188407\n",
      "episode: 8429\t average reward: -83.53553921568627\t avg steps: 164.2\t lr: 0.002955941954963816\t epsilon: 0.05020751782997649\n",
      "episode: 8439\t average reward: -81.44077306733168\t avg steps: 161.4\t lr: 0.0029411991329582107\t epsilon: 0.050205452993068216\n",
      "episode: 8449\t average reward: -80.08433734939759\t avg steps: 158.7\t lr: 0.0029265298410841175\t epsilon: 0.05020340870163045\n",
      "episode: 8459\t average reward: -83.3280487804878\t avg steps: 165.0\t lr: 0.002911933712608474\t epsilon: 0.05020138475123236\n",
      "episode: 8469\t average reward: -74.98388179986569\t avg steps: 149.9\t lr: 0.00289741038262731\t epsilon: 0.05019938093947722\n",
      "episode: 8479\t average reward: -80.53123028391167\t avg steps: 159.5\t lr: 0.002882959488056616\t epsilon: 0.050197397065982176\n",
      "episode: 8489\t average reward: -80.30176767676768\t avg steps: 159.4\t lr: 0.00286858066762328\t epsilon: 0.050195432932358224\n",
      "episode: 8499\t average reward: -82.18029739776952\t avg steps: 162.4\t lr: 0.00285427356185604\t epsilon: 0.050193488342190375\n",
      "episode: 8509\t average reward: -79.07618437900128\t avg steps: 157.2\t lr: 0.0028400378130765064\t epsilon: 0.05019156310101798\n",
      "episode: 8519\t average reward: -79.61553273427471\t avg steps: 156.8\t lr: 0.002825873065390219\t epsilon: 0.05018965701631533\n",
      "episode: 8529\t average reward: -76.8410290237467\t avg steps: 152.6\t lr: 0.0028117789646777466\t epsilon: 0.050187769897472354\n",
      "episode: 8539\t average reward: -87.0831381733021\t avg steps: 171.8\t lr: 0.0027977551585858383\t epsilon: 0.050185901555775604\n",
      "episode: 8549\t average reward: -77.86141834743006\t avg steps: 154.7\t lr: 0.0027838012965186116\t epsilon: 0.05018405180438935\n",
      "episode: 8559\t average reward: -77.32765399737877\t avg steps: 153.6\t lr: 0.002769917029628785\t epsilon: 0.05018222045833691\n",
      "episode: 8569\t average reward: -86.18509468540012\t avg steps: 164.7\t lr: 0.002756102010808968\t epsilon: 0.050180407334482154\n",
      "episode: 8579\t average reward: -78.40025906735751\t avg steps: 155.4\t lr: 0.0027423558946829685\t epsilon: 0.050178612251511184\n",
      "episode: 8589\t average reward: -77.72258485639686\t avg steps: 154.2\t lr: 0.0027286783375971672\t epsilon: 0.05017683502991421\n",
      "episode: 8599\t average reward: -77.83453237410072\t avg steps: 153.9\t lr: 0.0027150689976119247\t epsilon: 0.0501750754919676\n",
      "episode: 8609\t average reward: -86.79213817748659\t avg steps: 168.9\t lr: 0.002701527534493032\t epsilon: 0.050173333461716076\n",
      "episode: 8619\t average reward: -79.40705128205128\t avg steps: 157.0\t lr: 0.002688053609703207\t epsilon: 0.05017160876495517\n",
      "episode: 8629\t average reward: -75.75518394648829\t avg steps: 150.5\t lr: 0.0026746468863936266\t epsilon: 0.05016990122921376\n",
      "episode: 8639\t average reward: -90.07118254879448\t avg steps: 175.2\t lr: 0.0026613070293955115\t epsilon: 0.050168210683736864\n",
      "episode: 8649\t average reward: -81.90094043887147\t avg steps: 160.5\t lr: 0.0026480337052117386\t epsilon: 0.050166536959468516\n",
      "episode: 8659\t average reward: -87.79893238434164\t avg steps: 169.6\t lr: 0.0026348265820085167\t epsilon: 0.0501648798890349\n",
      "episode: 8669\t average reward: -78.70736434108527\t avg steps: 155.8\t lr: 0.0026216853296070755\t epsilon: 0.05016323930672758\n",
      "episode: 8679\t average reward: -79.8284625158831\t avg steps: 158.4\t lr: 0.002608609619475421\t epsilon: 0.05016161504848697\n",
      "episode: 8689\t average reward: -80.08924050632912\t avg steps: 159.0\t lr: 0.0025955991247201184\t epsilon: 0.05016000695188589\n",
      "episode: 8699\t average reward: -93.5715877437326\t avg steps: 180.5\t lr: 0.002582653520078122\t epsilon: 0.05015841485611334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 8709\t average reward: -81.56546134663341\t avg steps: 161.4\t lr: 0.0025697724819086403\t epsilon: 0.05015683860195841\n",
      "episode: 8719\t average reward: -86.024231678487\t avg steps: 170.2\t lr: 0.0025569556881850485\t epsilon: 0.05015527803179437\n",
      "episode: 8729\t average reward: -77.5812133072407\t avg steps: 154.3\t lr: 0.0025442028184868345\t epsilon: 0.05015373298956292\n",
      "episode: 8739\t average reward: -76.36206896551724\t avg steps: 151.8\t lr: 0.002531513553991595\t epsilon: 0.05015220332075853\n",
      "episode: 8749\t average reward: -76.9795918367347\t avg steps: 152.9\t lr: 0.002518887577467056\t epsilon: 0.05015068887241305\n",
      "episode: 8759\t average reward: -80.45110410094637\t avg steps: 159.5\t lr: 0.002506324573263145\t epsilon: 0.05014918949308039\n",
      "episode: 8769\t average reward: -80.61061946902655\t avg steps: 159.2\t lr: 0.002493824227304104\t epsilon: 0.050147705032821364\n",
      "episode: 8779\t average reward: -74.67611336032388\t avg steps: 149.2\t lr: 0.002481386227080632\t epsilon: 0.050146235343188704\n",
      "episode: 8789\t average reward: -81.16656111462952\t avg steps: 158.9\t lr: 0.002469010261642076\t epsilon: 0.05014478027721223\n",
      "episode: 8799\t average reward: -77.5386631716907\t avg steps: 153.6\t lr: 0.0024566960215886557\t epsilon: 0.05014333968938413\n",
      "episode: 8809\t average reward: -77.94918566775245\t avg steps: 154.5\t lr: 0.0024444431990637253\t epsilon: 0.05014191343564441\n",
      "episode: 8819\t average reward: -73.87184730743013\t avg steps: 147.7\t lr: 0.0024322514877460895\t epsilon: 0.05014050137336652\n",
      "episode: 8829\t average reward: -77.06776315789473\t avg steps: 153.0\t lr: 0.0024201205828423265\t epsilon: 0.05013910336134306\n",
      "episode: 8839\t average reward: -79.95982142857143\t avg steps: 157.8\t lr: 0.002408050181079183\t epsilon: 0.050137719259771646\n",
      "episode: 8849\t average reward: -77.6218872870249\t avg steps: 153.6\t lr: 0.0023960399806959853\t epsilon: 0.05013634893024098\n",
      "episode: 8859\t average reward: -90.98686464877213\t avg steps: 176.1\t lr: 0.0023840896814370997\t epsilon: 0.050134992235716956\n",
      "episode: 8869\t average reward: -83.88093769278224\t avg steps: 163.1\t lr: 0.0023721989845444207\t epsilon: 0.050133649040529\n",
      "episode: 8879\t average reward: -87.75816993464052\t avg steps: 169.3\t lr: 0.002360367592749908\t epsilon: 0.05013231921035647\n",
      "episode: 8889\t average reward: -88.77537922987165\t avg steps: 172.4\t lr: 0.00234859521026815\t epsilon: 0.050131002612215245\n",
      "episode: 8899\t average reward: -82.03935040599625\t avg steps: 161.1\t lr: 0.0023368815427889686\t epsilon: 0.05012969911444441\n",
      "episode: 8909\t average reward: -76.8235681369322\t avg steps: 152.9\t lr: 0.002325226297470072\t epsilon: 0.0501284085866931\n",
      "episode: 8919\t average reward: -73.61369863013698\t avg steps: 147.0\t lr: 0.0023136291829297185\t epsilon: 0.050127130899907474\n",
      "episode: 8929\t average reward: -77.9556135770235\t avg steps: 154.2\t lr: 0.002302089909239439\t epsilon: 0.05012586592631778\n",
      "episode: 8939\t average reward: -78.86843810758263\t avg steps: 155.3\t lr: 0.0022906081879167915\t epsilon: 0.0501246135394256\n",
      "episode: 8949\t average reward: -83.95980511571254\t avg steps: 165.2\t lr: 0.0022791837319181443\t epsilon: 0.05012337361399121\n",
      "episode: 8959\t average reward: -76.5576923076923\t avg steps: 151.8\t lr: 0.002267816255631503\t epsilon: 0.05012214602602103\n",
      "episode: 8969\t average reward: -78.03202614379084\t avg steps: 154.0\t lr: 0.002256505474869368\t epsilon: 0.05012093065275525\n",
      "episode: 8979\t average reward: -84.09424724602204\t avg steps: 164.4\t lr: 0.0022452511068616287\t epsilon: 0.050119727372655506\n",
      "episode: 8989\t average reward: -76.08582834331337\t avg steps: 151.3\t lr: 0.0022340528702485037\t epsilon: 0.05011853606539281\n",
      "episode: 8999\t average reward: -71.686925795053\t avg steps: 142.5\t lr: 0.0022229104850734916\t epsilon: 0.05011735661183543\n",
      "episode: 9009\t average reward: -92.34042553191489\t avg steps: 179.6\t lr: 0.002211823672776383\t epsilon: 0.05011618889403704\n",
      "episode: 9019\t average reward: -75.25301204819277\t avg steps: 150.4\t lr: 0.0022007921561862935\t epsilon: 0.05011503279522487\n",
      "episode: 9029\t average reward: -71.60028248587571\t avg steps: 142.6\t lr: 0.002189815659514733\t epsilon: 0.050113888199788084\n",
      "episode: 9039\t average reward: -80.81166772352569\t avg steps: 158.7\t lr: 0.0021788939083487134\t epsilon: 0.05011275499326618\n",
      "episode: 9049\t average reward: -72.3152709359606\t avg steps: 143.1\t lr: 0.002168026629643887\t epsilon: 0.050111633062337575\n",
      "episode: 9059\t average reward: -76.98080741230973\t avg steps: 152.1\t lr: 0.0021572135517177174\t epsilon: 0.050110522294808224\n",
      "episode: 9069\t average reward: -75.73253493013972\t avg steps: 151.3\t lr: 0.002146454404242698\t epsilon: 0.05010942257960046\n",
      "episode: 9079\t average reward: -80.125\t avg steps: 157.8\t lr: 0.002135748918239579\t epsilon: 0.05010833380674184\n",
      "episode: 9089\t average reward: -76.41633199464525\t avg steps: 150.4\t lr: 0.002125096826070653\t epsilon: 0.05010725586735417\n",
      "episode: 9099\t average reward: -73.42768595041322\t avg steps: 146.2\t lr: 0.002114497861433061\t epsilon: 0.05010618865364262\n",
      "episode: 9109\t average reward: -75.32684563758389\t avg steps: 150.0\t lr: 0.002103951759352135\t epsilon: 0.05010513205888493\n",
      "episode: 9119\t average reward: -77.18630678077683\t avg steps: 152.9\t lr: 0.002093458256174774\t epsilon: 0.05010408597742073\n",
      "episode: 9129\t average reward: -76.20902455209024\t avg steps: 151.7\t lr: 0.0020830170895628514\t epsilon: 0.05010305030464101\n",
      "episode: 9139\t average reward: -77.2800788954635\t avg steps: 153.1\t lr: 0.0020726279984866584\t epsilon: 0.050102024936977636\n",
      "episode: 9149\t average reward: -71.86873676781934\t avg steps: 142.7\t lr: 0.0020622907232183754\t epsilon: 0.050101009771892975\n",
      "episode: 9159\t average reward: -77.6483300589391\t avg steps: 153.7\t lr: 0.002052005005325586\t epsilon: 0.05010000470786968\n",
      "episode: 9169\t average reward: -78.34630872483221\t avg steps: 150.0\t lr: 0.002041770587664805\t epsilon: 0.05009900964440051\n",
      "episode: 9179\t average reward: -70.89842632331903\t avg steps: 140.8\t lr: 0.0020315872143750573\t epsilon: 0.050098024481978295\n",
      "episode: 9189\t average reward: -73.51304945054945\t avg steps: 146.6\t lr: 0.0020214546308714816\t epsilon: 0.05009704912208596\n",
      "episode: 9199\t average reward: -79.98647778493239\t avg steps: 156.3\t lr: 0.0020113725838389615\t epsilon: 0.050096083467186706\n",
      "episode: 9209\t average reward: -79.84566326530613\t avg steps: 157.8\t lr: 0.0020013408212257965\t epsilon: 0.05009512742071424\n",
      "episode: 9219\t average reward: -82.96941323345818\t avg steps: 161.2\t lr: 0.001991359092237399\t epsilon: 0.05009418088706312\n",
      "episode: 9229\t average reward: -78.2358306188925\t avg steps: 154.5\t lr: 0.001981427147330022\t epsilon: 0.05009324377157919\n",
      "episode: 9239\t average reward: -75.29765886287625\t avg steps: 150.5\t lr: 0.0019715447382045296\t epsilon: 0.050092315980550126\n",
      "episode: 9249\t average reward: -78.20936280884266\t avg steps: 154.8\t lr: 0.001961711617800177\t epsilon: 0.05009139742119604\n",
      "episode: 9259\t average reward: -73.84993178717599\t avg steps: 147.6\t lr: 0.001951927540288442\t epsilon: 0.050090488001660244\n",
      "episode: 9269\t average reward: -82.155\t avg steps: 161.0\t lr: 0.001942192261066877\t epsilon: 0.05008958763100002\n",
      "episode: 9279\t average reward: -74.16301369863014\t avg steps: 147.0\t lr: 0.0019325055367529949\t epsilon: 0.05008869621917755\n",
      "episode: 9289\t average reward: -77.31200527704486\t avg steps: 152.6\t lr: 0.001922867125178183\t epsilon: 0.05008781367705092\n",
      "episode: 9299\t average reward: -74.89883800410117\t avg steps: 147.3\t lr: 0.0019132767853816497\t epsilon: 0.05008693991636516\n",
      "episode: 9309\t average reward: -75.31346282652378\t avg steps: 150.3\t lr: 0.0019037342776043993\t epsilon: 0.05008607484974349\n",
      "episode: 9319\t average reward: -73.08310249307479\t avg steps: 145.4\t lr: 0.0018942393632832438\t epsilon: 0.05008521839067853\n",
      "episode: 9329\t average reward: -77.26026490066225\t avg steps: 152.0\t lr: 0.0018847918050448288\t epsilon: 0.05008437045352365\n",
      "episode: 9339\t average reward: -81.58354430379747\t avg steps: 159.0\t lr: 0.0018753913666997059\t epsilon: 0.05008353095348443\n",
      "episode: 9349\t average reward: -80.6584126984127\t avg steps: 158.5\t lr: 0.001866037813236427\t epsilon: 0.05008269980661017\n",
      "episode: 9359\t average reward: -75.88992661774516\t avg steps: 150.9\t lr: 0.0018567309108156694\t epsilon: 0.05008187692978549\n",
      "episode: 9369\t average reward: -74.28474576271186\t avg steps: 148.5\t lr: 0.0018474704267643863\t epsilon: 0.050081062240722014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9379\t average reward: -78.43811394891945\t avg steps: 153.7\t lr: 0.001838256129569995\t epsilon: 0.050080255657950164\n",
      "episode: 9389\t average reward: -77.12425644415069\t avg steps: 152.3\t lr: 0.0018290877888745855\t epsilon: 0.05007945710081099\n",
      "episode: 9399\t average reward: -74.91509433962264\t avg steps: 149.4\t lr: 0.0018199651754691615\t epsilon: 0.050078666489448115\n",
      "episode: 9409\t average reward: -76.57057256990679\t avg steps: 151.2\t lr: 0.0018108880612879156\t epsilon: 0.05007788374479974\n",
      "episode: 9419\t average reward: -77.49078947368422\t avg steps: 153.0\t lr: 0.001801856219402519\t epsilon: 0.05007710878859074\n",
      "episode: 9429\t average reward: -80.64071474154436\t avg steps: 157.7\t lr: 0.0017928694240164546\t epsilon: 0.05007634154332486\n",
      "episode: 9439\t average reward: -74.88745762711865\t avg steps: 148.5\t lr: 0.0017839274504593688\t epsilon: 0.05007558193227694\n",
      "episode: 9449\t average reward: -74.82905405405405\t avg steps: 149.0\t lr: 0.001775030075181458\t epsilon: 0.05007482987948522\n",
      "episode: 9459\t average reward: -76.66377005347593\t avg steps: 150.6\t lr: 0.0017661770757478757\t epsilon: 0.05007408530974381\n",
      "episode: 9469\t average reward: -81.47394852479599\t avg steps: 160.3\t lr: 0.001757368230833176\t epsilon: 0.05007334814859512\n",
      "episode: 9479\t average reward: -83.9760147601476\t avg steps: 163.6\t lr: 0.0017486033202157752\t epsilon: 0.050072618322322404\n",
      "episode: 9489\t average reward: -75.98010610079575\t avg steps: 151.8\t lr: 0.0017398821247724544\t epsilon: 0.05007189575794244\n",
      "episode: 9499\t average reward: -82.61007462686567\t avg steps: 161.8\t lr: 0.0017312044264728719\t epsilon: 0.05007118038319819\n",
      "episode: 9509\t average reward: -83.28597899938234\t avg steps: 162.9\t lr: 0.0017225700083741181\t epsilon: 0.050070472126551566\n",
      "episode: 9519\t average reward: -85.9010989010989\t avg steps: 164.8\t lr: 0.001713978654615291\t epsilon: 0.05006977091717633\n",
      "episode: 9529\t average reward: -90.9526285384171\t avg steps: 174.1\t lr: 0.001705430150412099\t epsilon: 0.05006907668495095\n",
      "episode: 9539\t average reward: -79.76805111821086\t avg steps: 157.5\t lr: 0.001696924282051492\t epsilon: 0.05006838936045163\n",
      "episode: 9549\t average reward: -74.87188132164532\t avg steps: 149.3\t lr: 0.0016884608368863175\t epsilon: 0.05006770887494535\n",
      "episode: 9559\t average reward: -90.00345224395858\t avg steps: 174.8\t lr: 0.0016800396033300046\t epsilon: 0.05006703516038299\n",
      "episode: 9569\t average reward: -97.92643923240938\t avg steps: 188.6\t lr: 0.0016716603708512787\t epsilon: 0.050066368149392526\n",
      "episode: 9579\t average reward: -82.55813953488372\t avg steps: 160.1\t lr: 0.00166332292996889\t epsilon: 0.05006570777527231\n",
      "episode: 9589\t average reward: -79.3855035279025\t avg steps: 156.9\t lr: 0.0016550270722463815\t epsilon: 0.05006505397198438\n",
      "episode: 9599\t average reward: -71.22782114975159\t avg steps: 141.9\t lr: 0.0016467725902868787\t epsilon: 0.050064406674147854\n",
      "episode: 9609\t average reward: -75.38528428093646\t avg steps: 150.5\t lr: 0.0016385592777279027\t epsilon: 0.050063765817032424\n",
      "episode: 9619\t average reward: -85.6044957472661\t avg steps: 165.6\t lr: 0.0016303869292362116\t epsilon: 0.05006313133655183\n",
      "episode: 9629\t average reward: -73.34212352532963\t avg steps: 145.1\t lr: 0.0016222553405026673\t epsilon: 0.0500625031692575\n",
      "episode: 9639\t average reward: -77.47143795141169\t avg steps: 153.3\t lr: 0.001614164308237128\t epsilon: 0.050061881252332185\n",
      "episode: 9649\t average reward: -80.91282375236892\t avg steps: 159.3\t lr: 0.0016061136301633646\t epsilon: 0.05006126552358367\n",
      "episode: 9659\t average reward: -79.64358974358974\t avg steps: 157.0\t lr: 0.0015981031050140088\t epsilon: 0.05006065592143857\n",
      "episode: 9669\t average reward: -77.24901445466492\t avg steps: 153.2\t lr: 0.0015901325325255124\t epsilon: 0.05006005238493616\n",
      "episode: 9679\t average reward: -76.19385026737967\t avg steps: 150.6\t lr: 0.0015822017134331488\t epsilon: 0.050059454853722284\n",
      "episode: 9689\t average reward: -88.48372093023256\t avg steps: 173.0\t lr: 0.0015743104494660273\t epsilon: 0.050058863268043326\n",
      "episode: 9699\t average reward: -85.27045177045177\t avg steps: 164.8\t lr: 0.0015664585433421382\t epsilon: 0.05005827756874023\n",
      "episode: 9709\t average reward: -75.77844712182062\t avg steps: 150.4\t lr: 0.001558645798763419\t epsilon: 0.05005769769724257\n",
      "episode: 9719\t average reward: -80.46777281429483\t avg steps: 157.7\t lr: 0.0015508720204108482\t epsilon: 0.05005712359556272\n",
      "episode: 9729\t average reward: -75.07940780619111\t avg steps: 149.6\t lr: 0.001543137013939561\t epsilon: 0.05005655520629002\n",
      "episode: 9739\t average reward: -77.29072847682119\t avg steps: 152.0\t lr: 0.0015354405859739956\t epsilon: 0.05005599247258509\n",
      "episode: 9749\t average reward: -76.304\t avg steps: 151.0\t lr: 0.0015277825441030503\t epsilon: 0.05005543533817407\n",
      "episode: 9759\t average reward: -72.43566433566434\t avg steps: 144.0\t lr: 0.0015201626968752797\t epsilon: 0.050054883747343064\n",
      "episode: 9769\t average reward: -76.68974700399467\t avg steps: 151.2\t lr: 0.0015125808537941063\t epsilon: 0.050054337644932535\n",
      "episode: 9779\t average reward: -71.60197600564572\t avg steps: 142.7\t lr: 0.0015050368253130579\t epsilon: 0.05005379697633178\n",
      "episode: 9789\t average reward: -75.17303822937626\t avg steps: 150.1\t lr: 0.00149753042283103\t epsilon: 0.05005326168747348\n",
      "episode: 9799\t average reward: -78.28023793787177\t avg steps: 152.3\t lr: 0.001490061458687569\t epsilon: 0.050052731724828325\n",
      "episode: 9809\t average reward: -76.07933333333334\t avg steps: 151.0\t lr: 0.0014826297461581815\t epsilon: 0.05005220703539959\n",
      "episode: 9819\t average reward: -75.633423180593\t avg steps: 149.4\t lr: 0.0014752350994496697\t epsilon: 0.0500516875667179\n",
      "episode: 9829\t average reward: -72.34401114206128\t avg steps: 144.6\t lr: 0.0014678773336954793\t epsilon: 0.050051173266835954\n",
      "episode: 9839\t average reward: -76.57792642140468\t avg steps: 150.5\t lr: 0.001460556264951083\t epsilon: 0.05005066408432334\n",
      "episode: 9849\t average reward: -79.78940568475453\t avg steps: 155.8\t lr: 0.0014532717101893816\t epsilon: 0.05005015996826138\n",
      "episode: 9859\t average reward: -68.70345842531273\t avg steps: 136.9\t lr: 0.001446023487296126\t epsilon: 0.05004966086823804\n",
      "episode: 9869\t average reward: -83.46679197994987\t avg steps: 160.6\t lr: 0.0014388114150653665\t epsilon: 0.05004916673434291\n",
      "episode: 9879\t average reward: -73.1644782308224\t avg steps: 145.7\t lr: 0.001431635313194922\t epsilon: 0.05004867751716219\n",
      "episode: 9889\t average reward: -72.75797503467406\t avg steps: 145.2\t lr: 0.0014244950022818718\t epsilon: 0.050048193167773744\n",
      "episode: 9899\t average reward: -71.96848739495799\t avg steps: 143.8\t lr: 0.0014173903038180698\t epsilon: 0.05004771363774224\n",
      "episode: 9909\t average reward: -74.79661016949153\t avg steps: 148.5\t lr: 0.001410321040185687\t epsilon: 0.050047238879114275\n",
      "episode: 9919\t average reward: -73.17561983471074\t avg steps: 146.2\t lr: 0.001403287034652763\t epsilon: 0.050046768844413586\n",
      "episode: 9929\t average reward: -80.84366925064599\t avg steps: 155.8\t lr: 0.0013962881113687934\t epsilon: 0.05004630348663631\n",
      "episode: 9939\t average reward: -73.80273037542662\t avg steps: 147.5\t lr: 0.0013893240953603316\t epsilon: 0.050045842759246284\n",
      "episode: 9949\t average reward: -76.83731739707835\t avg steps: 151.6\t lr: 0.001382394812526614\t epsilon: 0.05004538661617039\n",
      "episode: 9959\t average reward: -75.42318059299191\t avg steps: 149.4\t lr: 0.0013755000896352098\t epsilon: 0.05004493501179393\n",
      "episode: 9969\t average reward: -78.53780407626562\t avg steps: 153.1\t lr: 0.001368639754317687\t epsilon: 0.0500444879009561\n",
      "episode: 9979\t average reward: -85.66161309884778\t avg steps: 165.9\t lr: 0.001361813635065304\t epsilon: 0.050044045238945435\n",
      "episode: 9989\t average reward: -72.13687150837988\t avg steps: 144.2\t lr: 0.0013550215612247272\t epsilon: 0.05004360698149537\n",
      "episode: 9999\t average reward: -73.07734806629834\t avg steps: 145.8\t lr: 0.001348263362993755\t epsilon: 0.0500431730847798\n",
      "episode: 10009\t average reward: -78.65844155844155\t avg steps: 155.0\t lr: 0.0013415388714170797\t epsilon: 0.050042743505408674\n",
      "episode: 10019\t average reward: -89.61734997029114\t avg steps: 169.3\t lr: 0.0013348479183820615\t epsilon: 0.050042318200423715\n",
      "episode: 10029\t average reward: -77.31965585704832\t avg steps: 152.1\t lr: 0.0013281903366145265\t epsilon: 0.050041897127294066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10039\t average reward: -85.08348457350272\t avg steps: 166.3\t lr: 0.0013215659596745833\t epsilon: 0.050041480243912057\n",
      "episode: 10049\t average reward: -80.75445292620866\t avg steps: 158.2\t lr: 0.0013149746219524637\t epsilon: 0.050041067508589006\n",
      "episode: 10059\t average reward: -79.24805194805195\t avg steps: 155.0\t lr: 0.00130841615866438\t epsilon: 0.050040658880051034\n",
      "episode: 10069\t average reward: -78.46797385620916\t avg steps: 154.0\t lr: 0.001301890405848411\t epsilon: 0.05004025431743496\n",
      "episode: 10079\t average reward: -80.4093529788597\t avg steps: 157.1\t lr: 0.001295397200360395\t epsilon: 0.050039853780284166\n",
      "episode: 10089\t average reward: -82.86068111455108\t avg steps: 162.5\t lr: 0.0012889363798698566\t epsilon: 0.050039457228544616\n",
      "episode: 10099\t average reward: -83.50215384615385\t avg steps: 163.5\t lr: 0.0012825077828559472\t epsilon: 0.050039064622560796\n",
      "episode: 10109\t average reward: -78.04805194805195\t avg steps: 155.0\t lr: 0.0012761112486034062\t epsilon: 0.05003867592307179\n",
      "episode: 10119\t average reward: -85.48139109212934\t avg steps: 164.9\t lr: 0.0012697466171985446\t epsilon: 0.050038291091207325\n",
      "episode: 10129\t average reward: -68.1510574018127\t avg steps: 133.4\t lr: 0.0012634137295252459\t epsilon: 0.050037910088483885\n",
      "episode: 10139\t average reward: -69.72140762463343\t avg steps: 137.4\t lr: 0.001257112427260988\t epsilon: 0.050037532876800885\n",
      "episode: 10149\t average reward: -85.83676012461059\t avg steps: 161.5\t lr: 0.0012508425528728851\t epsilon: 0.050037159418436845\n",
      "episode: 10159\t average reward: -77.01321877065433\t avg steps: 152.3\t lr: 0.0012446039496137535\t epsilon: 0.050036789676045614\n",
      "episode: 10169\t average reward: -77.36280288146693\t avg steps: 153.7\t lr: 0.0012383964615181851\t epsilon: 0.05003642361265265\n",
      "episode: 10179\t average reward: -79.61685823754789\t avg steps: 157.6\t lr: 0.001232219933398655\t epsilon: 0.0500360611916513\n",
      "episode: 10189\t average reward: -81.37382592360676\t avg steps: 160.7\t lr: 0.0012260742108416375\t epsilon: 0.05003570237679916\n",
      "episode: 10199\t average reward: -84.68799034399517\t avg steps: 166.7\t lr: 0.0012199591402037493\t epsilon: 0.05003534713221446\n",
      "episode: 10209\t average reward: -73.04\t avg steps: 146.0\t lr: 0.0012138745686079058\t epsilon: 0.050034995422372434\n",
      "episode: 10219\t average reward: -82.09227871939737\t avg steps: 160.3\t lr: 0.0012078203439395002\t epsilon: 0.05003464721210182\n",
      "episode: 10229\t average reward: -75.389338731444\t avg steps: 149.2\t lr: 0.0012017963148425997\t epsilon: 0.05003430246658127\n",
      "episode: 10239\t average reward: -79.22114764667955\t avg steps: 156.1\t lr: 0.0011958023307161645\t epsilon: 0.05003396115133597\n",
      "episode: 10249\t average reward: -79.77016645326505\t avg steps: 157.2\t lr: 0.0011898382417102789\t epsilon: 0.05003362323223411\n",
      "episode: 10259\t average reward: -76.67981591058515\t avg steps: 153.1\t lr: 0.0011839038987224064\t epsilon: 0.05003328867548349\n",
      "episode: 10269\t average reward: -74.96430976430976\t avg steps: 149.5\t lr: 0.0011779991533936642\t epsilon: 0.05003295744762816\n",
      "episode: 10279\t average reward: -77.74409448818898\t avg steps: 153.4\t lr: 0.0011721238581051108\t epsilon: 0.05003262951554506\n",
      "episode: 10289\t average reward: -75.9601593625498\t avg steps: 151.6\t lr: 0.0011662778659740582\t epsilon: 0.0500323048464407\n",
      "episode: 10299\t average reward: -73.96657571623466\t avg steps: 147.6\t lr: 0.0011604610308503986\t epsilon: 0.05003198340784791\n",
      "episode: 10309\t average reward: -91.22386296515062\t avg steps: 170.3\t lr: 0.00115467320731295\t epsilon: 0.05003166516762255\n",
      "episode: 10319\t average reward: -73.67874231032125\t avg steps: 147.3\t lr: 0.0011489142506658245\t epsilon: 0.05003135009394035\n",
      "episode: 10329\t average reward: -78.14294996751137\t avg steps: 154.9\t lr: 0.0011431840169348051\t epsilon: 0.05003103815529367\n",
      "episode: 10339\t average reward: -75.1751677852349\t avg steps: 150.0\t lr: 0.0011374823628637497\t epsilon: 0.050030729320488375\n",
      "episode: 10349\t average reward: -87.95260663507109\t avg steps: 169.8\t lr: 0.00113180914591101\t epsilon: 0.050030423558640735\n",
      "episode: 10359\t average reward: -73.63474692202462\t avg steps: 147.2\t lr: 0.0011261642242458665\t epsilon: 0.05003012083917432\n",
      "episode: 10369\t average reward: -78.62088974854932\t avg steps: 156.1\t lr: 0.0011205474567449836\t epsilon: 0.05002982113181692\n",
      "episode: 10379\t average reward: -79.35237483953787\t avg steps: 156.8\t lr: 0.0011149587029888814\t epsilon: 0.05002952440659755\n",
      "episode: 10389\t average reward: -77.07368421052631\t avg steps: 153.0\t lr: 0.0011093978232584244\t epsilon: 0.05002923063384345\n",
      "episode: 10399\t average reward: -78.63707064160725\t avg steps: 155.3\t lr: 0.0011038646785313292\t epsilon: 0.05002893978417709\n",
      "episode: 10409\t average reward: -77.13609467455622\t avg steps: 153.1\t lr: 0.0010983591304786911\t epsilon: 0.050028651828513265\n",
      "episode: 10419\t average reward: -77.46035976015989\t avg steps: 151.1\t lr: 0.0010928810414615215\t epsilon: 0.05002836673805617\n",
      "episode: 10429\t average reward: -72.39315642458101\t avg steps: 144.2\t lr: 0.0010874302745273092\t epsilon: 0.05002808448429652\n",
      "episode: 10439\t average reward: -73.32778932778933\t avg steps: 145.3\t lr: 0.0010820066934065973\t epsilon: 0.0500278050390087\n",
      "episode: 10449\t average reward: -77.46108179419525\t avg steps: 152.6\t lr: 0.001076610162509575\t epsilon: 0.050027528374247954\n",
      "episode: 10459\t average reward: -77.6063829787234\t avg steps: 151.4\t lr: 0.0010712405469226888\t epsilon: 0.05002725446234757\n",
      "episode: 10469\t average reward: -79.90597204574333\t avg steps: 158.4\t lr: 0.0010658977124052697\t epsilon: 0.050026983275916134\n",
      "episode: 10479\t average reward: -78.50355067785668\t avg steps: 155.9\t lr: 0.0010605815253861752\t epsilon: 0.050026714787834776\n",
      "episode: 10489\t average reward: -79.90031948881789\t avg steps: 157.5\t lr: 0.0010552918529604552\t epsilon: 0.05002644897125447\n",
      "episode: 10499\t average reward: -73.98978201634877\t avg steps: 147.8\t lr: 0.001050028562886022\t epsilon: 0.050026185799593316\n",
      "episode: 10509\t average reward: -83.50338045482484\t avg steps: 163.7\t lr: 0.0010447915235803503\t epsilon: 0.05002592524653395\n",
      "episode: 10519\t average reward: -84.38231707317073\t avg steps: 165.0\t lr: 0.0010395806041171842\t epsilon: 0.05002566728602085\n",
      "episode: 10529\t average reward: -83.27165841584159\t avg steps: 162.6\t lr: 0.001034395674223266\t epsilon: 0.05002541189225773\n",
      "episode: 10539\t average reward: -82.96257668711657\t avg steps: 164.0\t lr: 0.001029236604275078\t epsilon: 0.050025159039705024\n",
      "episode: 10549\t average reward: -81.5475\t avg steps: 161.0\t lr: 0.0010241032652956034\t epsilon: 0.05002490870307724\n",
      "episode: 10559\t average reward: -81.85758706467662\t avg steps: 161.8\t lr: 0.0010189955289510988\t epsilon: 0.05002466085734053\n",
      "episode: 10569\t average reward: -74.67229729729729\t avg steps: 149.0\t lr: 0.0010139132675478916\t epsilon: 0.05002441547771011\n",
      "episode: 10579\t average reward: -79.05138086062942\t avg steps: 156.7\t lr: 0.0010088563540291812\t epsilon: 0.0500241725396478\n",
      "episode: 10589\t average reward: -82.03051058530511\t avg steps: 161.6\t lr: 0.001003824661971866\t epsilon: 0.050023932018859595\n",
      "episode: 10599\t average reward: -80.23611111111111\t avg steps: 159.4\t lr: 0.0009988180655833827\t epsilon: 0.05002369389129323\n",
      "episode: 10609\t average reward: -79.3690932311622\t avg steps: 157.6\t lr: 0.0009938364396985609\t epsilon: 0.05002345813313573\n",
      "episode: 10619\t average reward: -78.74629748873149\t avg steps: 156.3\t lr: 0.000988879659776494\t epsilon: 0.050023224720811096\n",
      "episode: 10629\t average reward: -80.89238514789176\t avg steps: 159.9\t lr: 0.0009839476018974256\t epsilon: 0.0500229936309779\n",
      "episode: 10639\t average reward: -77.65852047556143\t avg steps: 152.4\t lr: 0.000979040142759652\t epsilon: 0.05002276484052696\n",
      "episode: 10649\t average reward: -77.15696533682146\t avg steps: 153.9\t lr: 0.0009741571596764381\t epsilon: 0.05002253832657904\n",
      "episode: 10659\t average reward: -81.26969124133585\t avg steps: 159.7\t lr: 0.0009692985305729546\t epsilon: 0.05002231406648256\n",
      "episode: 10669\t average reward: -86.29055258467024\t avg steps: 169.3\t lr: 0.0009644641339832194\t epsilon: 0.05002209203781133\n",
      "episode: 10679\t average reward: -78.98711340206185\t avg steps: 156.2\t lr: 0.0009596538490470666\t epsilon: 0.05002187221836229\n",
      "episode: 10689\t average reward: -78.58242463117384\t avg steps: 156.9\t lr: 0.0009548675555071219\t epsilon: 0.050021654586153305\n",
      "episode: 10699\t average reward: -78.76531270148291\t avg steps: 156.1\t lr: 0.0009501051337057978\t epsilon: 0.05002143911942099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10709\t average reward: -76.20397350993377\t avg steps: 152.0\t lr: 0.0009453664645823009\t epsilon: 0.050021225796618475\n",
      "episode: 10719\t average reward: -80.00830140485313\t avg steps: 157.6\t lr: 0.0009406514296696564\t epsilon: 0.05002101459641332\n",
      "episode: 10729\t average reward: -75.40482573726541\t avg steps: 150.2\t lr: 0.0009359599110917451\t epsilon: 0.05002080549768531\n",
      "episode: 10739\t average reward: -80.63440860215054\t avg steps: 159.1\t lr: 0.0009312917915603599\t epsilon: 0.05002059847952441\n",
      "episode: 10749\t average reward: -80.5966709346991\t avg steps: 157.2\t lr: 0.0009266469543722687\t epsilon: 0.050020393521228626\n",
      "episode: 10759\t average reward: -79.47422024188415\t avg steps: 158.1\t lr: 0.0009220252834062994\t epsilon: 0.050020190602301964\n",
      "episode: 10769\t average reward: -79.93821656050956\t avg steps: 158.0\t lr: 0.0009174266631204376\t epsilon: 0.050019989702452354\n",
      "episode: 10779\t average reward: -74.26766304347827\t avg steps: 148.2\t lr: 0.0009128509785489365\t epsilon: 0.05001979080158965\n",
      "episode: 10789\t average reward: -92.65488215488216\t avg steps: 179.2\t lr: 0.0009082981152994434\t epsilon: 0.0500195938798236\n",
      "episode: 10799\t average reward: -83.80790273556231\t avg steps: 165.5\t lr: 0.0009037679595501402\t epsilon: 0.05001939891746185\n",
      "episode: 10809\t average reward: -79.08\t avg steps: 156.0\t lr: 0.000899260398046896\t epsilon: 0.05001920589500802\n",
      "episode: 10819\t average reward: -81.5765595463138\t avg steps: 159.7\t lr: 0.0008947753181004405\t epsilon: 0.05001901479315969\n",
      "episode: 10829\t average reward: -79.27401676337847\t avg steps: 156.1\t lr: 0.0008903126075835403\t epsilon: 0.05001882559280653\n",
      "episode: 10839\t average reward: -80.63964534515516\t avg steps: 158.9\t lr: 0.0008858721549282003\t epsilon: 0.05001863827502834\n",
      "episode: 10849\t average reward: -77.02980132450331\t avg steps: 152.0\t lr: 0.0008814538491228725\t epsilon: 0.05001845282109317\n",
      "episode: 10859\t average reward: -75.29040912139504\t avg steps: 150.1\t lr: 0.000877057579709682\t epsilon: 0.0500182692124555\n",
      "episode: 10869\t average reward: -82.3543599257885\t avg steps: 162.7\t lr: 0.0008726832367816644\t epsilon: 0.050018087430754296\n",
      "episode: 10879\t average reward: -82.60037059913527\t avg steps: 162.9\t lr: 0.0008683307109800186\t epsilon: 0.05001790745781124\n",
      "episode: 10889\t average reward: -80.03111111111112\t avg steps: 158.5\t lr: 0.000863999893491373\t epsilon: 0.05001772927562889\n",
      "episode: 10899\t average reward: -84.54194327097163\t avg steps: 166.7\t lr: 0.0008596906760450639\t epsilon: 0.05001755286638888\n",
      "episode: 10909\t average reward: -82.35414091470952\t avg steps: 162.8\t lr: 0.0008554029509104321\t epsilon: 0.05001737821245013\n",
      "episode: 10919\t average reward: -86.98197115384616\t avg steps: 167.4\t lr: 0.0008511366108941255\t epsilon: 0.05001720529634711\n",
      "episode: 10929\t average reward: -78.44329228775113\t avg steps: 155.3\t lr: 0.0008468915493374213\t epsilon: 0.05001703410078806\n",
      "episode: 10939\t average reward: -75.45891783567134\t avg steps: 150.7\t lr: 0.0008426676601135594\t epsilon: 0.05001686460865328\n",
      "episode: 10949\t average reward: -75.32508361204013\t avg steps: 150.5\t lr: 0.0008384648376250895\t epsilon: 0.05001669680299343\n",
      "episode: 10959\t average reward: -76.04837640821736\t avg steps: 151.9\t lr: 0.0008342829768012302\t epsilon: 0.050016530667027784\n",
      "episode: 10969\t average reward: -80.30686149936467\t avg steps: 158.4\t lr: 0.0008301219730952431\t epsilon: 0.050016366184142624\n",
      "episode: 10979\t average reward: -75.5720961281709\t avg steps: 150.8\t lr: 0.0008259817224818184\t epsilon: 0.05001620333788951\n",
      "episode: 10989\t average reward: -84.11077481840194\t avg steps: 166.2\t lr: 0.0008218621214544763\t epsilon: 0.05001604211198369\n",
      "episode: 10999\t average reward: -79.54939451880179\t avg steps: 157.9\t lr: 0.0008177630670229759\t epsilon: 0.05001588249030244\n",
      "episode: 11009\t average reward: -79.53521126760563\t avg steps: 157.2\t lr: 0.000813684456710743\t epsilon: 0.05001572445688345\n",
      "episode: 11019\t average reward: -78.17180327868853\t avg steps: 153.5\t lr: 0.0008096261885523073\t epsilon: 0.05001556799592326\n",
      "episode: 11029\t average reward: -83.78363636363636\t avg steps: 166.0\t lr: 0.0008055881610907535\t epsilon: 0.05001541309177563\n",
      "episode: 11039\t average reward: -77.69675324675325\t avg steps: 155.0\t lr: 0.0008015702733751846\t epsilon: 0.050015259728950025\n",
      "episode: 11049\t average reward: -77.57395287958116\t avg steps: 153.8\t lr: 0.0007975724249581986\t epsilon: 0.05001510789211003\n",
      "episode: 11059\t average reward: -78.85705086928526\t avg steps: 156.3\t lr: 0.0007935945158933761\t epsilon: 0.050014957566071834\n",
      "episode: 11069\t average reward: -76.79330708661418\t avg steps: 153.4\t lr: 0.0007896364467327848\t epsilon: 0.05001480873580271\n",
      "episode: 11079\t average reward: -79.35572616762636\t avg steps: 157.3\t lr: 0.0007856981185244887\t epsilon: 0.05001466138641951\n",
      "episode: 11089\t average reward: -78.50930083386787\t avg steps: 156.9\t lr: 0.0007817794328100775\t epsilon: 0.05001451550318717\n",
      "episode: 11099\t average reward: -84.64397590361446\t avg steps: 167.0\t lr: 0.0007778802916222044\t epsilon: 0.05001437107151724\n",
      "episode: 11109\t average reward: -82.35758323057954\t avg steps: 163.2\t lr: 0.0007740005974821363\t epsilon: 0.05001422807696644\n",
      "episode: 11119\t average reward: -82.2027194066749\t avg steps: 162.8\t lr: 0.0007701402533973179\t epsilon: 0.05001408650523519\n",
      "episode: 11129\t average reward: -84.42349397590361\t avg steps: 167.0\t lr: 0.000766299162858946\t epsilon: 0.050013946342166216\n",
      "episode: 11139\t average reward: -82.73758430410791\t avg steps: 164.1\t lr: 0.0007624772298395569\t epsilon: 0.05001380757374307\n",
      "episode: 11149\t average reward: -88.94270833333333\t avg steps: 173.8\t lr: 0.0007586743587906257\t epsilon: 0.05001367018608881\n",
      "episode: 11159\t average reward: -91.10842696629213\t avg steps: 179.0\t lr: 0.000754890454640179\t epsilon: 0.05001353416546454\n",
      "episode: 11169\t average reward: -84.88955582232893\t avg steps: 167.6\t lr: 0.0007511254227904157\t epsilon: 0.0500133994982681\n",
      "episode: 11179\t average reward: -78.19265463917526\t avg steps: 156.2\t lr: 0.0007473791691153433\t epsilon: 0.050013266171032654\n",
      "episode: 11189\t average reward: -82.26224426534408\t avg steps: 162.3\t lr: 0.0007436515999584249\t epsilon: 0.05001313417042537\n",
      "episode: 11199\t average reward: -89.35485714285714\t avg steps: 176.0\t lr: 0.0007399426221302371\t epsilon: 0.05001300348324607\n",
      "episode: 11209\t average reward: -90.75027995520716\t avg steps: 179.6\t lr: 0.0007362521429061415\t epsilon: 0.050012874096425936\n",
      "episode: 11219\t average reward: -86.1955109273479\t avg steps: 170.3\t lr: 0.000732580070023965\t epsilon: 0.05001274599702617\n",
      "episode: 11229\t average reward: -86.33668044890726\t avg steps: 170.3\t lr: 0.0007289263116816936\t epsilon: 0.05001261917223672\n",
      "episode: 11239\t average reward: -83.75500303214069\t avg steps: 165.9\t lr: 0.0007252907765351799\t epsilon: 0.05001249360937502\n",
      "episode: 11249\t average reward: -81.19625\t avg steps: 161.0\t lr: 0.0007216733736958551\t epsilon: 0.050012369295884665\n",
      "episode: 11259\t average reward: -78.94797687861272\t avg steps: 156.7\t lr: 0.00071807401272846\t epsilon: 0.05001224621933421\n",
      "episode: 11269\t average reward: -83.84920634920636\t avg steps: 164.8\t lr: 0.0007144926036487828\t epsilon: 0.05001212436741589\n",
      "episode: 11279\t average reward: -87.28253223915593\t avg steps: 171.6\t lr: 0.00071092905692141\t epsilon: 0.05001200372794441\n",
      "episode: 11289\t average reward: -81.08067542213884\t avg steps: 160.9\t lr: 0.0007073832834574877\t epsilon: 0.05001188428885574\n",
      "episode: 11299\t average reward: -80.31549118387909\t avg steps: 159.8\t lr: 0.0007038551946124949\t epsilon: 0.05001176603820585\n",
      "episode: 11309\t average reward: -81.77585139318886\t avg steps: 162.5\t lr: 0.0007003447021840259\t epsilon: 0.05001164896416959\n",
      "episode: 11319\t average reward: -85.80785246876859\t avg steps: 169.1\t lr: 0.0006968517184095884\t epsilon: 0.05001153305503945\n",
      "episode: 11329\t average reward: -82.61590628853267\t avg steps: 163.2\t lr: 0.0006933761559644057\t epsilon: 0.050011418299224425\n",
      "episode: 11339\t average reward: -84.49364021804966\t avg steps: 166.1\t lr: 0.0006899179279592352\t epsilon: 0.05001130468524884\n",
      "episode: 11349\t average reward: -81.59737006887914\t avg steps: 160.7\t lr: 0.0006864769479381972\t epsilon: 0.0500111922017512\n",
      "episode: 11359\t average reward: -85.41391721655668\t avg steps: 167.7\t lr: 0.0006830531298766115\t epsilon: 0.05001108083748307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 11369\t average reward: -81.908125\t avg steps: 161.0\t lr: 0.0006796463881788486\t epsilon: 0.05001097058130791\n",
      "episode: 11379\t average reward: -83.62186927306048\t avg steps: 164.7\t lr: 0.0006762566376761883\t epsilon: 0.05001086142220003\n",
      "episode: 11389\t average reward: -81.58640049906425\t avg steps: 161.3\t lr: 0.0006728837936246911\t epsilon: 0.05001075334924342\n",
      "episode: 11399\t average reward: -82.14800995024876\t avg steps: 161.8\t lr: 0.0006695277717030812\t epsilon: 0.050010646351630696\n",
      "episode: 11409\t average reward: -83.1988950276243\t avg steps: 163.9\t lr: 0.000666188488010635\t epsilon: 0.050010540418662\n",
      "episode: 11419\t average reward: -81.2396486825596\t avg steps: 160.4\t lr: 0.0006628658590650865\t epsilon: 0.050010435539743964\n",
      "episode: 11429\t average reward: -89.53776263486655\t avg steps: 177.1\t lr: 0.0006595598018005389\t epsilon: 0.050010331704388594\n",
      "episode: 11439\t average reward: -80.11820480404552\t avg steps: 159.2\t lr: 0.0006562702335653885\t epsilon: 0.050010228902212274\n",
      "episode: 11449\t average reward: -81.46959247648903\t avg steps: 160.5\t lr: 0.000652997072120258\t epsilon: 0.0500101271229347\n",
      "episode: 11459\t average reward: -88.11498257839722\t avg steps: 173.2\t lr: 0.0006497402356359408\t epsilon: 0.05001002635637786\n",
      "episode: 11469\t average reward: -76.41160949868073\t avg steps: 152.6\t lr: 0.000646499642691355\t epsilon: 0.050009926592465004\n",
      "episode: 11479\t average reward: -90.28676470588235\t avg steps: 177.8\t lr: 0.000643275212271508\t epsilon: 0.050009827821219675\n",
      "episode: 11489\t average reward: -80.70263488080302\t avg steps: 160.4\t lr: 0.0006400668637654722\t epsilon: 0.050009730032764654\n",
      "episode: 11499\t average reward: -85.63598326359832\t avg steps: 168.3\t lr: 0.0006368745169643674\t epsilon: 0.05000963321732102\n",
      "episode: 11509\t average reward: -79.3388746803069\t avg steps: 157.4\t lr: 0.0006336980920593573\t epsilon: 0.05000953736520714\n",
      "episode: 11519\t average reward: -79.32033248081841\t avg steps: 157.4\t lr: 0.0006305375096396539\t epsilon: 0.050009442466837736\n",
      "episode: 11529\t average reward: -83.57212416311626\t avg steps: 165.3\t lr: 0.0006273926906905317\t epsilon: 0.05000934851272289\n",
      "episode: 11539\t average reward: -87.99826489300173\t avg steps: 173.9\t lr: 0.0006242635565913539\t epsilon: 0.050009255493467096\n",
      "episode: 11549\t average reward: -80.87704918032787\t avg steps: 159.6\t lr: 0.0006211500291136043\t epsilon: 0.05000916339976837\n",
      "episode: 11559\t average reward: -79.55095541401273\t avg steps: 158.0\t lr: 0.0006180520304189339\t epsilon: 0.050009072222417246\n",
      "episode: 11569\t average reward: -78.76\t avg steps: 156.0\t lr: 0.0006149694830572145\t epsilon: 0.05000898195229593\n",
      "episode: 11579\t average reward: -81.57793017456359\t avg steps: 161.4\t lr: 0.0006119023099646013\t epsilon: 0.05000889258037733\n",
      "episode: 11589\t average reward: -81.40387016229712\t avg steps: 161.2\t lr: 0.0006088504344616071\t epsilon: 0.05000880409772417\n",
      "episode: 11599\t average reward: -79.31774503523383\t avg steps: 157.1\t lr: 0.0006058137802511855\t epsilon: 0.05000871649548813\n",
      "episode: 11609\t average reward: -87.65726043503821\t avg steps: 171.1\t lr: 0.000602792271416823\t epsilon: 0.0500086297649089\n",
      "episode: 11619\t average reward: -81.33083176985616\t avg steps: 160.9\t lr: 0.0005997858324206413\t epsilon: 0.05000854389731335\n",
      "episode: 11629\t average reward: -78.06459948320413\t avg steps: 155.8\t lr: 0.0005967943881015091\t epsilon: 0.050008458884114655\n",
      "episode: 11639\t average reward: -77.61923326835607\t avg steps: 154.9\t lr: 0.000593817863673162\t epsilon: 0.05000837471681142\n",
      "episode: 11649\t average reward: -78.61658031088083\t avg steps: 155.4\t lr: 0.0005908561847223353\t epsilon: 0.050008291386986835\n",
      "episode: 11659\t average reward: -78.48900388098318\t avg steps: 155.6\t lr: 0.0005879092772069003\t epsilon: 0.050008208886307866\n",
      "episode: 11669\t average reward: -75.63733333333333\t avg steps: 151.0\t lr: 0.0005849770674540158\t epsilon: 0.05000812720652437\n",
      "episode: 11679\t average reward: -78.16342412451363\t avg steps: 155.2\t lr: 0.0005820594821582853\t epsilon: 0.0500080463394683\n",
      "episode: 11689\t average reward: -78.58664955070603\t avg steps: 156.8\t lr: 0.0005791564483799244\t epsilon: 0.05000796627705288\n",
      "episode: 11699\t average reward: -75.46492985971943\t avg steps: 150.7\t lr: 0.0005762678935429373\t epsilon: 0.050007887011271804\n",
      "episode: 11709\t average reward: -82.20820385332505\t avg steps: 161.9\t lr: 0.0005733937454333028\t epsilon: 0.05000780853419843\n",
      "episode: 11719\t average reward: -84.5\t avg steps: 165.0\t lr: 0.0005705339321971685\t epsilon: 0.05000773083798497\n",
      "episode: 11729\t average reward: -85.93586698337292\t avg steps: 169.4\t lr: 0.0005676883823390539\t epsilon: 0.05000765391486177\n",
      "episode: 11739\t average reward: -86.62833432128038\t avg steps: 169.7\t lr: 0.0005648570247200654\t epsilon: 0.05000757775713642\n",
      "episode: 11749\t average reward: -79.423273657289\t avg steps: 157.4\t lr: 0.0005620397885561146\t epsilon: 0.05000750235719311\n",
      "episode: 11759\t average reward: -76.21975806451613\t avg steps: 149.8\t lr: 0.0005592366034161506\t epsilon: 0.05000742770749176\n",
      "episode: 11769\t average reward: -87.83109292811221\t avg steps: 172.1\t lr: 0.0005564473992203989\t epsilon: 0.05000735380056736\n",
      "episode: 11779\t average reward: -86.31067382230172\t avg steps: 168.7\t lr: 0.0005536721062386094\t epsilon: 0.050007280629029136\n",
      "episode: 11789\t average reward: -80.0941475826972\t avg steps: 158.2\t lr: 0.000550910655088313\t epsilon: 0.050007208185559884\n",
      "episode: 11799\t average reward: -78.40090968161144\t avg steps: 154.9\t lr: 0.0005481629767330871\t epsilon: 0.0500071364629152\n",
      "episode: 11809\t average reward: -78.54335260115607\t avg steps: 156.7\t lr: 0.0005454290024808292\t epsilon: 0.05000706545392275\n",
      "episode: 11819\t average reward: -80.28101265822785\t avg steps: 159.0\t lr: 0.0005427086639820416\t epsilon: 0.05000699515148158\n",
      "episode: 11829\t average reward: -83.38220858895706\t avg steps: 164.0\t lr: 0.0005400018932281196\t epsilon: 0.05000692554856139\n",
      "episode: 11839\t average reward: -78.4990328820116\t avg steps: 156.1\t lr: 0.0005373086225496534\t epsilon: 0.05000685663820183\n",
      "episode: 11849\t average reward: -78.61057382333978\t avg steps: 156.1\t lr: 0.000534628784614736\t epsilon: 0.0500067884135118\n",
      "episode: 11859\t average reward: -75.20495646349632\t avg steps: 150.3\t lr: 0.000531962312427279\t epsilon: 0.050006720867668775\n",
      "episode: 11869\t average reward: -82.38257107540173\t avg steps: 162.8\t lr: 0.0005293091393253393\t epsilon: 0.05000665399391812\n",
      "episode: 11879\t average reward: -84.65703971119133\t avg steps: 167.2\t lr: 0.0005266691989794508\t epsilon: 0.050006587785572404\n",
      "episode: 11889\t average reward: -81.83178150217256\t avg steps: 162.1\t lr: 0.000524042425390967\t epsilon: 0.05000652223601073\n",
      "episode: 11899\t average reward: -85.69345238095238\t avg steps: 169.0\t lr: 0.0005214287528904123\t epsilon: 0.0500064573386781\n",
      "episode: 11909\t average reward: -75.15080428954424\t avg steps: 150.2\t lr: 0.0005188281161358377\t epsilon: 0.05000639308708471\n",
      "episode: 11919\t average reward: -77.84142394822007\t avg steps: 155.5\t lr: 0.0005162404501111889\t epsilon: 0.050006329474805364\n",
      "episode: 11929\t average reward: -77.86093143596378\t avg steps: 155.6\t lr: 0.0005136656901246803\t epsilon: 0.05000626649547877\n",
      "episode: 11939\t average reward: -80.0551330798479\t avg steps: 158.8\t lr: 0.0005111037718071783\t epsilon: 0.050006204142806945\n",
      "episode: 11949\t average reward: -79.66624203821657\t avg steps: 158.0\t lr: 0.0005085546311105916\t epsilon: 0.05000614241055457\n",
      "episode: 11959\t average reward: -83.33598045204643\t avg steps: 164.7\t lr: 0.0005060182043062697\t epsilon: 0.050006081292548375\n",
      "episode: 11969\t average reward: -82.96990171990171\t avg steps: 163.8\t lr: 0.0005034944279834108\t epsilon: 0.0500060207826765\n",
      "episode: 11979\t average reward: -83.41819291819291\t avg steps: 164.8\t lr: 0.0005009832390474746\t epsilon: 0.05000596087488791\n",
      "episode: 11989\t average reward: -80.75689223057644\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000590156319177\n",
      "episode: 11999\t average reward: -81.65732087227414\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.05000584284165687\n",
      "episode: 12009\t average reward: -81.473454091193\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.05000578470441101\n",
      "episode: 12019\t average reward: -85.02999400119975\t avg steps: 167.7\t lr: 0.0005\t epsilon: 0.05000572714564041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 12029\t average reward: -78.43948220064725\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000567015958914\n",
      "episode: 12039\t average reward: -82.8840490797546\t avg steps: 164.0\t lr: 0.0005\t epsilon: 0.05000561374055856\n",
      "episode: 12049\t average reward: -83.0147329650092\t avg steps: 163.9\t lr: 0.0005\t epsilon: 0.05000555788290672\n",
      "episode: 12059\t average reward: -84.04239854633555\t avg steps: 166.1\t lr: 0.0005\t epsilon: 0.050005502581047793\n",
      "episode: 12069\t average reward: -81.2735790131168\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.05000544782945156\n",
      "episode: 12079\t average reward: -84.64333132166566\t avg steps: 166.7\t lr: 0.0005\t epsilon: 0.05000539362264281\n",
      "episode: 12089\t average reward: -81.66313162819714\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000533995520082\n",
      "episode: 12099\t average reward: -79.84939374601149\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.050005286821758796\n",
      "episode: 12109\t average reward: -79.55176848874598\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000523421700336\n",
      "episode: 12119\t average reward: -80.92336922102596\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000518213567398\n",
      "episode: 12129\t average reward: -79.84605597964376\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000513057256249\n",
      "episode: 12139\t average reward: -78.96463022508038\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.050005079522512534\n",
      "episode: 12149\t average reward: -84.13807785888078\t avg steps: 165.4\t lr: 0.0005\t epsilon: 0.05000502898041906\n",
      "episode: 12159\t average reward: -84.1683765841883\t avg steps: 166.7\t lr: 0.0005\t epsilon: 0.050004978941227816\n",
      "episode: 12169\t average reward: -83.8718730933496\t avg steps: 164.9\t lr: 0.0005\t epsilon: 0.050004929399934846\n",
      "episode: 12179\t average reward: -75.84441489361703\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000488035158598\n",
      "episode: 12189\t average reward: -85.24119402985075\t avg steps: 168.5\t lr: 0.0005\t epsilon: 0.050004831791276336\n",
      "episode: 12199\t average reward: -84.0938824954573\t avg steps: 166.1\t lr: 0.0005\t epsilon: 0.05000478371414985\n",
      "episode: 12209\t average reward: -78.48157724628312\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000473611539876\n",
      "episode: 12219\t average reward: -78.66125892277742\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05000468899026316\n",
      "episode: 12229\t average reward: -81.69937888198758\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05000464233403049\n",
      "episode: 12239\t average reward: -84.20169082125604\t avg steps: 166.6\t lr: 0.0005\t epsilon: 0.0500045961420351\n",
      "episode: 12249\t average reward: -80.08739708676377\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000455040965773\n",
      "episode: 12259\t average reward: -87.10961313012896\t avg steps: 171.6\t lr: 0.0005\t epsilon: 0.050004505132325135\n",
      "episode: 12269\t average reward: -86.54127358490567\t avg steps: 170.6\t lr: 0.0005\t epsilon: 0.050004460305509514\n",
      "episode: 12279\t average reward: -84.92247596153847\t avg steps: 167.4\t lr: 0.0005\t epsilon: 0.050004415924728166\n",
      "episode: 12289\t average reward: -78.36825192802057\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000437198554297\n",
      "episode: 12299\t average reward: -86.35832349468713\t avg steps: 170.4\t lr: 0.0005\t epsilon: 0.05000432848355997\n",
      "episode: 12309\t average reward: -78.23116548615583\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000428541442894\n",
      "episode: 12319\t average reward: -77.46358907672301\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000424277384291\n",
      "episode: 12329\t average reward: -80.87019533711405\t avg steps: 159.7\t lr: 0.0005\t epsilon: 0.05000420055753781\n",
      "episode: 12339\t average reward: -83.5677811550152\t avg steps: 165.5\t lr: 0.0005\t epsilon: 0.05000415876129197\n",
      "episode: 12349\t average reward: -85.0509592326139\t avg steps: 167.8\t lr: 0.0005\t epsilon: 0.050004117380925715\n",
      "episode: 12359\t average reward: -82.53065015479876\t avg steps: 162.5\t lr: 0.0005\t epsilon: 0.050004076412300986\n",
      "episode: 12369\t average reward: -79.55321861057999\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.050004035851320884\n",
      "episode: 12379\t average reward: -84.6734693877551\t avg steps: 167.6\t lr: 0.0005\t epsilon: 0.05000399569392928\n",
      "episode: 12389\t average reward: -75.41015364061457\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000395593611039\n",
      "episode: 12399\t average reward: -83.94203782794386\t avg steps: 164.9\t lr: 0.0005\t epsilon: 0.05000391657388842\n",
      "episode: 12409\t average reward: -76.79593175853019\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000387760332709\n",
      "episode: 12419\t average reward: -80.94051346274264\t avg steps: 160.7\t lr: 0.0005\t epsilon: 0.050003839020529336\n",
      "episode: 12429\t average reward: -81.26708463949844\t avg steps: 160.5\t lr: 0.0005\t epsilon: 0.05000380082163683\n",
      "episode: 12439\t average reward: -84.2890103217972\t avg steps: 165.7\t lr: 0.0005\t epsilon: 0.05000376300282965\n",
      "episode: 12449\t average reward: -80.27020202020202\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.050003725560325896\n",
      "episode: 12459\t average reward: -81.49595519601742\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.050003688490381275\n",
      "episode: 12469\t average reward: -87.90548424737456\t avg steps: 172.4\t lr: 0.0005\t epsilon: 0.05000365178928876\n",
      "episode: 12479\t average reward: -81.93997524752476\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.050003615453378225\n",
      "episode: 12489\t average reward: -84.0018192844148\t avg steps: 165.9\t lr: 0.0005\t epsilon: 0.05000357947901604\n",
      "episode: 12499\t average reward: -77.73898963730569\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000354386260474\n",
      "episode: 12509\t average reward: -85.7030411449016\t avg steps: 168.7\t lr: 0.0005\t epsilon: 0.050003508600582655\n",
      "episode: 12519\t average reward: -79.40421455938697\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.050003473689423546\n",
      "episode: 12529\t average reward: -84.9027027027027\t avg steps: 167.5\t lr: 0.0005\t epsilon: 0.05000343912563628\n",
      "episode: 12539\t average reward: -75.77245508982035\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.050003404905764444\n",
      "episode: 12549\t average reward: -82.57495373226404\t avg steps: 163.1\t lr: 0.0005\t epsilon: 0.050003371026386016\n",
      "episode: 12559\t average reward: -78.087890625\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000333748411304\n",
      "episode: 12569\t average reward: -75.33177257525084\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000330427559126\n",
      "episode: 12579\t average reward: -78.70463320463321\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.050003271397499785\n",
      "episode: 12589\t average reward: -79.41491395793498\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000323884655079\n",
      "episode: 12599\t average reward: -76.75984251968504\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000320661948915\n",
      "episode: 12609\t average reward: -79.87579214195183\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05000317471309213\n",
      "episode: 12619\t average reward: -80.74480151228734\t avg steps: 159.7\t lr: 0.0005\t epsilon: 0.050003143124169064\n",
      "episode: 12629\t average reward: -75.25987943737441\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.050003111849561035\n",
      "episode: 12639\t average reward: -81.40488110137672\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.050003080886140555\n",
      "episode: 12649\t average reward: -81.14473684210526\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000305023081126\n",
      "episode: 12659\t average reward: -78.04598445595855\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000301988050758\n",
      "episode: 12669\t average reward: -79.26453674121406\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000298983219447\n",
      "episode: 12679\t average reward: -82.11873840445269\t avg steps: 162.7\t lr: 0.0005\t epsilon: 0.05000296008286707\n",
      "episode: 12689\t average reward: -82.56683168316832\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.050002930629550434\n",
      "episode: 12699\t average reward: -76.93254747871644\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.050002901469299185\n",
      "episode: 12709\t average reward: -78.94034637588197\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.050002872599197286\n",
      "episode: 12719\t average reward: -76.94338380513496\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.050002844016357705\n",
      "episode: 12729\t average reward: -87.94428322692977\t avg steps: 173.3\t lr: 0.0005\t epsilon: 0.050002815717922124\n",
      "episode: 12739\t average reward: -81.6863354037267\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05000278770106068\n",
      "episode: 12749\t average reward: -83.15257352941177\t avg steps: 164.2\t lr: 0.0005\t epsilon: 0.05000275996297167\n",
      "episode: 12759\t average reward: -81.96032238065716\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.050002732500881254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 12769\t average reward: -82.27142857142857\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.050002705312043205\n",
      "episode: 12779\t average reward: -85.06080674292595\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.05000267839373862\n",
      "episode: 12789\t average reward: -75.45460614152204\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.05000265174327563\n",
      "episode: 12799\t average reward: -83.1298224127373\t avg steps: 164.3\t lr: 0.0005\t epsilon: 0.05000262535798919\n",
      "episode: 12809\t average reward: -81.75529265255292\t avg steps: 161.6\t lr: 0.0005\t epsilon: 0.050002599235240724\n",
      "episode: 12819\t average reward: -79.77168367346938\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000257337241795\n",
      "episode: 12829\t average reward: -81.46355140186915\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.05000254776693457\n",
      "episode: 12839\t average reward: -81.89267990074441\t avg steps: 162.2\t lr: 0.0005\t epsilon: 0.05000252241623\n",
      "episode: 12849\t average reward: -80.26485461441213\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.050002497317769165\n",
      "episode: 12859\t average reward: -83.8681652490887\t avg steps: 165.6\t lr: 0.0005\t epsilon: 0.05000247246904218\n",
      "episode: 12869\t average reward: -84.06193078324226\t avg steps: 165.7\t lr: 0.0005\t epsilon: 0.05000244786756416\n",
      "episode: 12879\t average reward: -79.79820051413881\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000242351087494\n",
      "episode: 12889\t average reward: -75.95159151193634\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.05000239939653882\n",
      "episode: 12899\t average reward: -80.19506016466117\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000237552214436\n",
      "episode: 12909\t average reward: -81.04448621553885\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000235188530409\n",
      "episode: 12919\t average reward: -77.82303188028627\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000232848365431\n",
      "episode: 12929\t average reward: -85.20621637776449\t avg steps: 168.3\t lr: 0.0005\t epsilon: 0.050002305314854834\n",
      "episode: 12939\t average reward: -76.11721854304636\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000228237658877\n",
      "episode: 12949\t average reward: -77.51463890696161\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.050002259666562264\n",
      "episode: 12959\t average reward: -79.85587301587302\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.0500022371825043\n",
      "episode: 12969\t average reward: -82.09073958980733\t avg steps: 161.9\t lr: 0.0005\t epsilon: 0.050002214922166444\n",
      "episode: 12979\t average reward: -81.1737207833228\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.05000219288332266\n",
      "episode: 12989\t average reward: -82.00868486352357\t avg steps: 162.2\t lr: 0.0005\t epsilon: 0.05000217106376903\n",
      "episode: 12999\t average reward: -75.87118193891102\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.050002149461323586\n",
      "episode: 13009\t average reward: -74.72574123989219\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000212807382606\n",
      "episode: 13019\t average reward: -78.40129032258065\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050002106899137706\n",
      "episode: 13029\t average reward: -83.73751522533496\t avg steps: 165.2\t lr: 0.0005\t epsilon: 0.05000208593514101\n",
      "episode: 13039\t average reward: -85.70714285714286\t avg steps: 169.0\t lr: 0.0005\t epsilon: 0.05000206517973957\n",
      "episode: 13049\t average reward: -84.66264333132166\t avg steps: 166.7\t lr: 0.0005\t epsilon: 0.05000204463085782\n",
      "episode: 13059\t average reward: -81.29046424090339\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000202428644086\n",
      "episode: 13069\t average reward: -81.07365792759052\t avg steps: 161.2\t lr: 0.0005\t epsilon: 0.050002004144454236\n",
      "episode: 13079\t average reward: -79.77211966900063\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05000198420288373\n",
      "episode: 13089\t average reward: -75.9526982011992\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05000196445973516\n",
      "episode: 13099\t average reward: -81.4627426424546\t avg steps: 160.7\t lr: 0.0005\t epsilon: 0.0500019449130342\n",
      "episode: 13109\t average reward: -74.97108271687962\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.050001925560826166\n",
      "episode: 13119\t average reward: -84.24592145015106\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.05000190640117582\n",
      "episode: 13129\t average reward: -78.17887232663642\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000188743216718\n",
      "episode: 13139\t average reward: -79.62324393358877\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000186865190333\n",
      "episode: 13149\t average reward: -84.42839879154079\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.05000185005850623\n",
      "episode: 13159\t average reward: -80.4153455928979\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05000183165011652\n",
      "episode: 13169\t average reward: -78.47066408768536\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05000181342489334\n",
      "episode: 13179\t average reward: -80.33206831119544\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000179538101417\n",
      "episode: 13189\t average reward: -84.00121359223301\t avg steps: 165.8\t lr: 0.0005\t epsilon: 0.050001777516674596\n",
      "episode: 13199\t average reward: -78.3038138332256\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000175983008817\n",
      "episode: 13209\t average reward: -76.69484808454425\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.050001742319486224\n",
      "episode: 13219\t average reward: -74.11820652173913\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.050001724983117675\n",
      "episode: 13229\t average reward: -75.19839142091153\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000170781924887\n",
      "episode: 13239\t average reward: -80.83155248271527\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05000169082616342\n",
      "episode: 13249\t average reward: -79.55902999361838\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000167400216199\n",
      "episode: 13259\t average reward: -81.84754200373366\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.050001657345562174\n",
      "episode: 13269\t average reward: -76.92894736842105\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.0500016408546983\n",
      "episode: 13279\t average reward: -74.5608108108108\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000162452792126\n",
      "episode: 13289\t average reward: -77.81315104166667\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050001608363598356\n",
      "episode: 13299\t average reward: -77.26277850589777\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.050001592360113166\n",
      "episode: 13309\t average reward: -77.23853211009174\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05000157651586531\n",
      "episode: 13319\t average reward: -82.29429987608427\t avg steps: 162.4\t lr: 0.0005\t epsilon: 0.05000156082927035\n",
      "episode: 13329\t average reward: -81.71633416458853\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.05000154529875962\n",
      "episode: 13339\t average reward: -82.34596273291926\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05000152992278006\n",
      "episode: 13349\t average reward: -87.58610624635143\t avg steps: 172.3\t lr: 0.0005\t epsilon: 0.050001514699794046\n",
      "episode: 13359\t average reward: -81.52743142144638\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.050001499628279274\n",
      "episode: 13369\t average reward: -78.87548387096774\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000148470672858\n",
      "episode: 13379\t average reward: -80.16666666666667\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.050001469933649796\n",
      "episode: 13389\t average reward: -79.48084291187739\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.050001455307565605\n",
      "episode: 13399\t average reward: -84.30773881499395\t avg steps: 166.4\t lr: 0.0005\t epsilon: 0.050001440827013376\n",
      "episode: 13409\t average reward: -82.23918417799753\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.05000142649054506\n",
      "episode: 13419\t average reward: -77.65454545454546\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000141229672698\n",
      "episode: 13429\t average reward: -76.3891820580475\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000139824413975\n",
      "episode: 13439\t average reward: -76.66688654353563\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.0500013843313781\n",
      "episode: 13449\t average reward: -82.37965260545906\t avg steps: 162.2\t lr: 0.0005\t epsilon: 0.05000137055705074\n",
      "episode: 13459\t average reward: -79.82877148313176\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05000135691978023\n",
      "episode: 13469\t average reward: -82.9360786724032\t avg steps: 163.7\t lr: 0.0005\t epsilon: 0.05000134341820283\n",
      "episode: 13479\t average reward: -79.51309904153355\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.050001330050968365\n",
      "episode: 13489\t average reward: -85.45508982035928\t avg steps: 168.0\t lr: 0.0005\t epsilon: 0.05000131681674011\n",
      "episode: 13499\t average reward: -77.1895081967213\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.050001303714194624\n",
      "episode: 13509\t average reward: -80.40808591282375\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.05000129074202164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 13519\t average reward: -76.75857519788919\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000127789892394\n",
      "episode: 13529\t average reward: -85.54138972809668\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.050001265183617194\n",
      "episode: 13539\t average reward: -80.16898734177215\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000125259482987\n",
      "episode: 13549\t average reward: -85.20958083832335\t avg steps: 168.0\t lr: 0.0005\t epsilon: 0.05000124013130306\n",
      "episode: 13559\t average reward: -86.83303938859494\t avg steps: 171.1\t lr: 0.0005\t epsilon: 0.05000122779179043\n",
      "episode: 13569\t average reward: -80.5110829639012\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000121557505799\n",
      "episode: 13579\t average reward: -80.55583437892095\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000120347988407\n",
      "episode: 13589\t average reward: -78.76591639871383\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000119150505915\n",
      "episode: 13599\t average reward: -78.40903225806451\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000117964938572\n",
      "episode: 13609\t average reward: -81.92981366459627\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05000116791167821\n",
      "episode: 13619\t average reward: -82.63866584311303\t avg steps: 162.9\t lr: 0.0005\t epsilon: 0.05000115629076285\n",
      "episode: 13629\t average reward: -80.10235219326128\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000114478547753\n",
      "episode: 13639\t average reward: -84.18055555555556\t avg steps: 166.6\t lr: 0.0005\t epsilon: 0.0500011333946717\n",
      "episode: 13649\t average reward: -81.73200992555832\t avg steps: 162.2\t lr: 0.0005\t epsilon: 0.05000112211720629\n",
      "episode: 13659\t average reward: -82.84378843788438\t avg steps: 163.6\t lr: 0.0005\t epsilon: 0.05000111095195354\n",
      "episode: 13669\t average reward: -75.06375838926175\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.0500010998977969\n",
      "episode: 13679\t average reward: -78.76349614395887\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.050001088953630965\n",
      "episode: 13689\t average reward: -83.10878918254456\t avg steps: 163.7\t lr: 0.0005\t epsilon: 0.0500010781183613\n",
      "episode: 13699\t average reward: -88.4976717112922\t avg steps: 172.8\t lr: 0.0005\t epsilon: 0.05000106739090436\n",
      "episode: 13709\t average reward: -83.33272171253823\t avg steps: 164.5\t lr: 0.0005\t epsilon: 0.05000105677018741\n",
      "episode: 13719\t average reward: -79.71337579617834\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.050001046255148354\n",
      "episode: 13729\t average reward: -78.95886889460154\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000103584473569\n",
      "episode: 13739\t average reward: -76.17592592592592\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000102553790836\n",
      "episode: 13749\t average reward: -77.10943643512451\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05000101533363567\n",
      "episode: 13759\t average reward: -77.62075718015666\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.0500010052308972\n",
      "episode: 13769\t average reward: -75.18419290020094\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000099522868265\n",
      "episode: 13779\t average reward: -74.24898236092265\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.0500009853259918\n",
      "episode: 13789\t average reward: -79.36835361947469\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000097552183437\n",
      "episode: 13799\t average reward: -81.57409713574097\t avg steps: 161.6\t lr: 0.0005\t epsilon: 0.05000096581522994\n",
      "episode: 13809\t average reward: -84.72161835748793\t avg steps: 166.6\t lr: 0.0005\t epsilon: 0.050000956205207836\n",
      "episode: 13819\t average reward: -75.92629482071713\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05000094669080705\n",
      "episode: 13829\t average reward: -81.58265751715534\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000093727107613\n",
      "episode: 13839\t average reward: -79.99809038828772\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.0500009279450731\n",
      "episode: 13849\t average reward: -79.96268184693233\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000091871186535\n",
      "episode: 13859\t average reward: -75.06040268456375\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.05000090957052955\n",
      "episode: 13869\t average reward: -81.63239875389408\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.05000090052015157\n",
      "episode: 13879\t average reward: -77.74609375\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050000891559826344\n",
      "episode: 13889\t average reward: -78.94996792815908\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000088268865785\n",
      "episode: 13899\t average reward: -76.75841584158415\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000873905758955\n",
      "episode: 13909\t average reward: -76.3843605036448\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000086521025137\n",
      "episode: 13919\t average reward: -83.14935464044254\t avg steps: 163.7\t lr: 0.0005\t epsilon: 0.05000085660126553\n",
      "episode: 13929\t average reward: -75.1307847082495\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05000084807794052\n",
      "episode: 13939\t average reward: -74.71813890761969\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000083963942402\n",
      "episode: 13949\t average reward: -81.32456140350877\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000083128487216\n",
      "episode: 13959\t average reward: -79.17466410748561\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.050000823013449484\n",
      "episode: 13969\t average reward: -76.93324607329843\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000081482432883\n",
      "episode: 13979\t average reward: -80.90138190954774\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.0500008067166913\n",
      "episode: 13989\t average reward: -78.0448343079922\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.0500007986897261\n",
      "episode: 13999\t average reward: -83.83985102420857\t avg steps: 162.1\t lr: 0.0005\t epsilon: 0.050000790742630544\n",
      "episode: 14009\t average reward: -77.86931079323797\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.050000782874609906\n",
      "episode: 14019\t average reward: -74.44316644113667\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000077508487739\n",
      "episode: 14029\t average reward: -74.45565335138795\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.050000767372654\n",
      "episode: 14039\t average reward: -74.47734956051386\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05000075973716851\n",
      "episode: 14049\t average reward: -78.18134715025907\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000075217765738\n",
      "episode: 14059\t average reward: -83.42185592185592\t avg steps: 164.8\t lr: 0.0005\t epsilon: 0.050000744693364636\n",
      "episode: 14069\t average reward: -74.86617350369872\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000073728354185\n",
      "episode: 14079\t average reward: -73.06891798759476\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05000072994744804\n",
      "episode: 14089\t average reward: -82.70098643649816\t avg steps: 163.2\t lr: 0.0005\t epsilon: 0.050000722684349574\n",
      "episode: 14099\t average reward: -80.88294524858402\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000071549352015\n",
      "episode: 14109\t average reward: -76.13558201058201\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000070837424067\n",
      "episode: 14119\t average reward: -79.9656050955414\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000070132579921\n",
      "episode: 14129\t average reward: -74.43166441136671\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.050000694347490916\n",
      "episode: 14139\t average reward: -77.05820797907128\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000068743861794\n",
      "episode: 14149\t average reward: -74.61309925725861\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000068059848941\n",
      "episode: 14159\t average reward: -77.58485639686684\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000067382642129\n",
      "episode: 14169\t average reward: -77.09335963182117\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000066712173637\n",
      "episode: 14179\t average reward: -77.52365308804205\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.050000660483764184\n",
      "episode: 14189\t average reward: -79.10238248551191\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000065391184093\n",
      "episode: 14199\t average reward: -76.60289283366207\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000064740530939\n",
      "episode: 14209\t average reward: -79.94102726696259\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05000064096351894\n",
      "episode: 14219\t average reward: -79.53358925143954\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000063458582536\n",
      "episode: 14229\t average reward: -79.3058748403576\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.0500006282715909\n",
      "episode: 14239\t average reward: -80.29575680810639\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000062202018412\n",
      "episode: 14249\t average reward: -79.32842509603073\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000061583097987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 14259\t average reward: -79.6734693877551\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000060970335924\n",
      "episode: 14269\t average reward: -76.46891534391534\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000603636709454\n",
      "episode: 14279\t average reward: -74.20977596741344\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000059763042384\n",
      "episode: 14289\t average reward: -77.59568909209666\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.050000591683901766\n",
      "episode: 14299\t average reward: -78.22186076772934\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000058579654858\n",
      "episode: 14309\t average reward: -75.57161981258366\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000057996777553\n",
      "episode: 14319\t average reward: -77.63529411764706\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000057419699974\n",
      "episode: 14329\t average reward: -76.66139657444005\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.050000568483644134\n",
      "episode: 14339\t average reward: -84.11732522796352\t avg steps: 165.5\t lr: 0.0005\t epsilon: 0.050000562827137364\n",
      "episode: 14349\t average reward: -79.49069916613213\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.050000557226913774\n",
      "episode: 14359\t average reward: -83.06311274509804\t avg steps: 164.2\t lr: 0.0005\t epsilon: 0.050000551682413345\n",
      "episode: 14369\t average reward: -77.52837573385519\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000054619308161\n",
      "episode: 14379\t average reward: -78.54886731391586\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000054075836965\n",
      "episode: 14389\t average reward: -79.65730695596682\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000053537773397\n",
      "episode: 14399\t average reward: -77.53063885267275\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000053005063651\n",
      "episode: 14409\t average reward: -74.89778076664425\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.050000524776544555\n",
      "episode: 14419\t average reward: -83.27550397067807\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.05000051955493069\n",
      "episode: 14429\t average reward: -79.38067818298144\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.050000514385272754\n",
      "episode: 14439\t average reward: -80.36375078665827\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000050926705377\n",
      "episode: 14449\t average reward: -79.02685421994885\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05000050419976192\n",
      "episode: 14459\t average reward: -79.24521072796935\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000049918289047\n",
      "episode: 14469\t average reward: -78.20605280103027\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000049421593772\n",
      "episode: 14479\t average reward: -87.62819025522042\t avg steps: 173.4\t lr: 0.0005\t epsilon: 0.050000489298406975\n",
      "episode: 14489\t average reward: -83.0700365408039\t avg steps: 165.2\t lr: 0.0005\t epsilon: 0.05000048442980648\n",
      "episode: 14499\t average reward: -81.03680598877105\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.050000479609649366\n",
      "episode: 14509\t average reward: -79.56643356643356\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000047483745362\n",
      "episode: 14519\t average reward: -80.80979284369114\t avg steps: 160.3\t lr: 0.0005\t epsilon: 0.050000470112742015\n",
      "episode: 14529\t average reward: -80.32410320956576\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000046543504207\n",
      "episode: 14539\t average reward: -78.05631067961166\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.050000460803886024\n",
      "episode: 14549\t average reward: -84.7996400719856\t avg steps: 167.7\t lr: 0.0005\t epsilon: 0.05000045621881075\n",
      "episode: 14559\t average reward: -83.75885225885226\t avg steps: 164.8\t lr: 0.0005\t epsilon: 0.05000045167935774\n",
      "episode: 14569\t average reward: -79.62022900763358\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000044718507304\n",
      "episode: 14579\t average reward: -81.94489164086687\t avg steps: 162.5\t lr: 0.0005\t epsilon: 0.05000044273550722\n",
      "episode: 14589\t average reward: -76.27260726072608\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000438330215315\n",
      "episode: 14599\t average reward: -79.18785942492013\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.0500004339687568\n",
      "episode: 14609\t average reward: -78.81531531531532\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000042965069552\n",
      "episode: 14619\t average reward: -80.11533586818759\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05000042537559967\n",
      "episode: 14629\t average reward: -76.38892551087673\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.050000421143041734\n",
      "episode: 14639\t average reward: -79.47371794871795\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05000041695259846\n",
      "episode: 14649\t average reward: -77.03599476439791\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000041280385078\n",
      "episode: 14659\t average reward: -81.9085252022402\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.050000408696383836\n",
      "episode: 14669\t average reward: -80.97867001254706\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.050000404629786874\n",
      "episode: 14679\t average reward: -80.4102402022756\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.050000400603653225\n",
      "episode: 14689\t average reward: -75.77209302325582\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.050000396617580274\n",
      "episode: 14699\t average reward: -78.90699166132136\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000039267116941\n",
      "episode: 14709\t average reward: -82.61828289067326\t avg steps: 162.9\t lr: 0.0005\t epsilon: 0.050000388764025995\n",
      "episode: 14719\t average reward: -81.81619937694704\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.0500003848957593\n",
      "episode: 14729\t average reward: -79.59426751592356\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000038106598251\n",
      "episode: 14739\t average reward: -76.85638998682477\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000037727431263\n",
      "episode: 14749\t average reward: -75.65223184543638\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.0500003735203705\n",
      "episode: 14759\t average reward: -76.558648111332\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000036980378071\n",
      "episode: 14769\t average reward: -78.19310793237972\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.050000366124171615\n",
      "episode: 14779\t average reward: -80.36409608091024\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.05000036248117524\n",
      "episode: 14789\t average reward: -76.46719681908549\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000035887442728\n",
      "episode: 14799\t average reward: -78.8879587894398\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.050000355303567064\n",
      "episode: 14809\t average reward: -80.97542533081285\t avg steps: 159.7\t lr: 0.0005\t epsilon: 0.05000035176823751\n",
      "episode: 14819\t average reward: -80.05608667941364\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000034826808506\n",
      "episode: 14829\t average reward: -77.62287581699347\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.050000344802759715\n",
      "episode: 14839\t average reward: -79.0618556701031\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000034137191493\n",
      "episode: 14849\t average reward: -78.59184993531694\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000033797520762\n",
      "episode: 14859\t average reward: -74.73180592991913\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000033461229812\n",
      "episode: 14869\t average reward: -82.04844720496894\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05000033128285012\n",
      "episode: 14879\t average reward: -79.86378103119033\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05000032798653069\n",
      "episode: 14889\t average reward: -80.72847265870521\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05000032472301018\n",
      "episode: 14899\t average reward: -84.98079231692677\t avg steps: 167.6\t lr: 0.0005\t epsilon: 0.05000032149196224\n",
      "episode: 14909\t average reward: -79.0618556701031\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000031829306377\n",
      "episode: 14919\t average reward: -79.64322250639387\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05000031512599487\n",
      "episode: 14929\t average reward: -75.87649402390439\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.050000311990438834\n",
      "episode: 14939\t average reward: -83.01104972375691\t avg steps: 163.9\t lr: 0.0005\t epsilon: 0.0500003088860821\n",
      "episode: 14949\t average reward: -77.04213298222516\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05000030581261423\n",
      "episode: 14959\t average reward: -77.67840834964123\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000302769727875\n",
      "episode: 14969\t average reward: -79.46739130434783\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05000029975711875\n",
      "episode: 14979\t average reward: -79.18573264781492\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000029677448558\n",
      "episode: 14989\t average reward: -75.19290020093771\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000029382153011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 14999\t average reward: -77.29646596858639\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000029089795704\n",
      "episode: 15009\t average reward: -78.57928802588997\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.050000288003474\n",
      "episode: 15019\t average reward: -77.849609375\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050000285137791554\n",
      "episode: 15029\t average reward: -75.27175368139224\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.050000282300623124\n",
      "episode: 15039\t average reward: -79.80830670926518\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000027949168499\n",
      "episode: 15049\t average reward: -79.47603833865814\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000027671069626\n",
      "episode: 15059\t average reward: -77.4397116644823\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05000027395737883\n",
      "episode: 15069\t average reward: -80.01651842439644\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.050000271231457366\n",
      "episode: 15079\t average reward: -79.50223642172524\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000026853265927\n",
      "episode: 15089\t average reward: -79.01997422680412\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000026586071467\n",
      "episode: 15099\t average reward: -75.26773761713521\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.050000263215356354\n",
      "episode: 15109\t average reward: -76.97957839262187\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.050000260596319804\n",
      "episode: 15119\t average reward: -81.09868007542426\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.050000258003343095\n",
      "episode: 15129\t average reward: -80.10573248407643\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.050000255436166936\n",
      "episode: 15139\t average reward: -78.35328562134028\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000025289453461\n",
      "episode: 15149\t average reward: -81.43098063710181\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.050000250378191946\n",
      "episode: 15159\t average reward: -79.8125\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000024788688731\n",
      "episode: 15169\t average reward: -78.590174531351\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000024542037157\n",
      "episode: 15179\t average reward: -79.17139175257732\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000024297839807\n",
      "episode: 15189\t average reward: -81.96756082345603\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.050000240560722616\n",
      "episode: 15199\t average reward: -81.6925\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.05000023816710343\n",
      "episode: 15209\t average reward: -74.40284360189574\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.05000023579730116\n",
      "episode: 15219\t average reward: -79.37243589743589\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05000023345107881\n",
      "episode: 15229\t average reward: -76.7752808988764\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000023112820177\n",
      "episode: 15239\t average reward: -79.21994884910485\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.050000228828437736\n",
      "episode: 15249\t average reward: -82.5571253071253\t avg steps: 163.8\t lr: 0.0005\t epsilon: 0.05000022655155673\n",
      "episode: 15259\t average reward: -85.99704316972206\t avg steps: 170.1\t lr: 0.0005\t epsilon: 0.05000022429733108\n",
      "episode: 15269\t average reward: -86.41725768321513\t avg steps: 170.2\t lr: 0.0005\t epsilon: 0.050000222065535345\n",
      "episode: 15279\t average reward: -80.68738229755179\t avg steps: 160.3\t lr: 0.0005\t epsilon: 0.050000219855946354\n",
      "episode: 15289\t average reward: -85.30238095238096\t avg steps: 169.0\t lr: 0.0005\t epsilon: 0.05000021766834313\n",
      "episode: 15299\t average reward: -88.87800687285224\t avg steps: 175.6\t lr: 0.0005\t epsilon: 0.05000021550250693\n",
      "episode: 15309\t average reward: -80.31829573934837\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000021335822116\n",
      "episode: 15319\t average reward: -83.3021978021978\t avg steps: 164.8\t lr: 0.0005\t epsilon: 0.05000021123527139\n",
      "episode: 15329\t average reward: -82.50864197530865\t avg steps: 163.0\t lr: 0.0005\t epsilon: 0.05000020913344532\n",
      "episode: 15339\t average reward: -82.88664215686275\t avg steps: 164.2\t lr: 0.0005\t epsilon: 0.050000207052532775\n",
      "episode: 15349\t average reward: -79.92219387755102\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.050000204992325645\n",
      "episode: 15359\t average reward: -81.00062932662051\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000020295261793\n",
      "episode: 15369\t average reward: -76.25181758096497\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000020093320564\n",
      "episode: 15379\t average reward: -81.06953223767383\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.05000019893388684\n",
      "episode: 15389\t average reward: -80.40696202531646\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000019695446159\n",
      "episode: 15399\t average reward: -75.64933333333333\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.050000194994731954\n",
      "episode: 15409\t average reward: -82.89483394833948\t avg steps: 163.6\t lr: 0.0005\t epsilon: 0.05000019305450195\n",
      "episode: 15419\t average reward: -80.54942965779468\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.050000191133577565\n",
      "episode: 15429\t average reward: -81.1323713927227\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000018923176669\n",
      "episode: 15439\t average reward: -73.50137174211248\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000018734887915\n",
      "episode: 15449\t average reward: -72.97860593512767\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05000018548472666\n",
      "episode: 15459\t average reward: -76.76089828269485\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.050000183639122786\n",
      "episode: 15469\t average reward: -84.7653429602888\t avg steps: 167.2\t lr: 0.0005\t epsilon: 0.05000018181188299\n",
      "episode: 15479\t average reward: -78.99483870967742\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000180002824524\n",
      "episode: 15489\t average reward: -80.88190954773869\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.05000017821176649\n",
      "episode: 15499\t average reward: -79.15424164524421\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000017643852979\n",
      "episode: 15509\t average reward: -80.35632911392405\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000017468293709\n",
      "episode: 15519\t average reward: -79.67992302758178\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000017294481282\n",
      "episode: 15529\t average reward: -78.0104643557881\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000017122398318\n",
      "episode: 15539\t average reward: -83.21928746928747\t avg steps: 163.8\t lr: 0.0005\t epsilon: 0.05000016952027608\n",
      "episode: 15549\t average reward: -73.3543956043956\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05000016783352115\n",
      "episode: 15559\t average reward: -79.79411764705883\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.050000166163549714\n",
      "episode: 15569\t average reward: -78.03898635477583\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000016451019477\n",
      "episode: 15579\t average reward: -78.80064724919094\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000016287329098\n",
      "episode: 15589\t average reward: -78.81366860090264\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05000016125267466\n",
      "episode: 15599\t average reward: -82.5326354679803\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.05000015964818374\n",
      "episode: 15609\t average reward: -80.40441640378549\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000015805965777\n",
      "episode: 15619\t average reward: -79.97025316455696\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.0500001564869379\n",
      "episode: 15629\t average reward: -77.36214800261952\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000015492986685\n",
      "episode: 15639\t average reward: -80.47634069400631\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.050000153388288913\n",
      "episode: 15649\t average reward: -80.737106918239\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.05000015186204994\n",
      "episode: 15659\t average reward: -78.93709884467266\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.050000150350997294\n",
      "episode: 15669\t average reward: -76.09463931171409\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000014885497988\n",
      "episode: 15679\t average reward: -83.30012224938875\t avg steps: 164.6\t lr: 0.0005\t epsilon: 0.05000014737384808\n",
      "episode: 15689\t average reward: -81.45290081097941\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000014590745379\n",
      "episode: 15699\t average reward: -81.43391521197007\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.05000014445565037\n",
      "episode: 15709\t average reward: -80.3850031505986\t avg steps: 159.7\t lr: 0.0005\t epsilon: 0.05000014301829263\n",
      "episode: 15719\t average reward: -77.44211903204709\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.050000141595236844\n",
      "episode: 15729\t average reward: -78.75353016688062\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.0500001401863407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 15739\t average reward: -80.18939393939394\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.0500001387914633\n",
      "episode: 15749\t average reward: -80.70025188916877\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000013741046517\n",
      "episode: 15759\t average reward: -76.0877659574468\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.050000136043208195\n",
      "episode: 15769\t average reward: -76.86939313984169\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000013468955566\n",
      "episode: 15779\t average reward: -82.03233830845771\t avg steps: 161.8\t lr: 0.0005\t epsilon: 0.050000133349372186\n",
      "episode: 15789\t average reward: -76.47546419098143\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.05000013202252376\n",
      "episode: 15799\t average reward: -80.62192816635161\t avg steps: 159.7\t lr: 0.0005\t epsilon: 0.0500001307088777\n",
      "episode: 15809\t average reward: -78.86791237113403\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000012940830264\n",
      "episode: 15819\t average reward: -78.2444733420026\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.050000128120668515\n",
      "episode: 15829\t average reward: -76.29122340425532\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000012684584656\n",
      "episode: 15839\t average reward: -78.09811565951917\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.050000125583709296\n",
      "episode: 15849\t average reward: -76.24734042553192\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.050000124334130515\n",
      "episode: 15859\t average reward: -76.13439787092481\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000012309698524\n",
      "episode: 15869\t average reward: -78.71935483870968\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000012187214978\n",
      "episode: 15879\t average reward: -78.16493506493507\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000012065950162\n",
      "episode: 15889\t average reward: -78.13494132985659\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000011945891952\n",
      "episode: 15899\t average reward: -80.49270767279644\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05000011827028341\n",
      "episode: 15909\t average reward: -79.74314850223072\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000011709347443\n",
      "episode: 15919\t average reward: -84.5496368038741\t avg steps: 166.2\t lr: 0.0005\t epsilon: 0.050000115928374896\n",
      "episode: 15929\t average reward: -79.41270860077022\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000011477486829\n",
      "episode: 15939\t average reward: -82.32737361282368\t avg steps: 163.2\t lr: 0.0005\t epsilon: 0.050000113632839266\n",
      "episode: 15949\t average reward: -78.8891736066624\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000011250217363\n",
      "episode: 15959\t average reward: -80.48010107391029\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.0500001113827583\n",
      "episode: 15969\t average reward: -77.6814911706998\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.050000110274481334\n",
      "episode: 15979\t average reward: -79.91507024265645\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000010917723191\n",
      "episode: 15989\t average reward: -83.37046153846154\t avg steps: 163.5\t lr: 0.0005\t epsilon: 0.0500001080909003\n",
      "episode: 15999\t average reward: -75.07449664429531\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.050000107015377875\n",
      "episode: 16009\t average reward: -80.816120906801\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.050000105950557074\n",
      "episode: 16019\t average reward: -80.10012674271229\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.050000104896331415\n",
      "episode: 16029\t average reward: -76.02518223989397\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000010385259548\n",
      "episode: 16039\t average reward: -82.14250309789344\t avg steps: 162.4\t lr: 0.0005\t epsilon: 0.05000010281924489\n",
      "episode: 16049\t average reward: -76.50362080315998\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05000010179617631\n",
      "episode: 16059\t average reward: -77.15851272015655\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000010078328743\n",
      "episode: 16069\t average reward: -82.43580246913581\t avg steps: 163.0\t lr: 0.0005\t epsilon: 0.05000009978047697\n",
      "episode: 16079\t average reward: -80.88468809073724\t avg steps: 159.7\t lr: 0.0005\t epsilon: 0.05000009878764463\n",
      "episode: 16089\t average reward: -78.64732430689878\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05000009780469114\n",
      "episode: 16099\t average reward: -82.53374613003096\t avg steps: 162.5\t lr: 0.0005\t epsilon: 0.05000009683151821\n",
      "episode: 16109\t average reward: -76.73416886543535\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.050000095868028505\n",
      "episode: 16119\t average reward: -77.22207621550591\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000009491412568\n",
      "episode: 16129\t average reward: -79.52112676056338\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000009396971435\n",
      "episode: 16139\t average reward: -78.7275661717237\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000009303470007\n",
      "episode: 16149\t average reward: -80.60352422907489\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.050000092108989334\n",
      "episode: 16159\t average reward: -77.29888816219751\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.050000091192489576\n",
      "episode: 16169\t average reward: -82.04027261462205\t avg steps: 162.4\t lr: 0.0005\t epsilon: 0.05000009028510915\n",
      "episode: 16179\t average reward: -79.64308476736775\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.050000089386757304\n",
      "episode: 16189\t average reward: -80.53000631711939\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.050000088497344206\n",
      "episode: 16199\t average reward: -79.57908163265306\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000008761678092\n",
      "episode: 16209\t average reward: -75.7304347826087\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000008674497938\n",
      "episode: 16219\t average reward: -80.45471698113208\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.05000008588185242\n",
      "episode: 16229\t average reward: -77.15540983606557\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.050000085027313707\n",
      "episode: 16239\t average reward: -79.75541401273885\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.0500000841812778\n",
      "episode: 16249\t average reward: -81.03764115432874\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000008334366009\n",
      "episode: 16259\t average reward: -86.12322274881517\t avg steps: 169.8\t lr: 0.0005\t epsilon: 0.05000008251437681\n",
      "episode: 16269\t average reward: -78.95646606914212\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000008169334505\n",
      "episode: 16279\t average reward: -83.91080097087378\t avg steps: 165.8\t lr: 0.0005\t epsilon: 0.05000008088048268\n",
      "episode: 16289\t average reward: -77.9523498694517\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000080075708435\n",
      "episode: 16299\t average reward: -78.24059662775616\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.050000079278941824\n",
      "episode: 16309\t average reward: -74.19484046164291\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000007849010317\n",
      "episode: 16319\t average reward: -83.78448275862068\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.0500000777091136\n",
      "episode: 16329\t average reward: -80.63291139240506\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.050000076935895\n",
      "episode: 16339\t average reward: -80.0349872773537\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000007617037005\n",
      "episode: 16349\t average reward: -81.4208880550344\t avg steps: 160.9\t lr: 0.0005\t epsilon: 0.05000007541246221\n",
      "episode: 16359\t average reward: -73.33104395604396\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05000007466209567\n",
      "episode: 16369\t average reward: -75.14777327935222\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.050000073919195406\n",
      "episode: 16379\t average reward: -78.44401294498383\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000007318368712\n",
      "episode: 16389\t average reward: -77.20131147540984\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.050000072455497264\n",
      "episode: 16399\t average reward: -76.86635944700461\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05000007173455302\n",
      "episode: 16409\t average reward: -75.93724966622163\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.05000007102078229\n",
      "episode: 16419\t average reward: -76.55761589403974\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000007031411371\n",
      "episode: 16429\t average reward: -83.5171568627451\t avg steps: 164.2\t lr: 0.0005\t epsilon: 0.05000006961447658\n",
      "episode: 16439\t average reward: -76.88010540184453\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000006892180097\n",
      "episode: 16449\t average reward: -77.54177545691905\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000006823601759\n",
      "episode: 16459\t average reward: -82.24248120300751\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000006755705787\n",
      "episode: 16469\t average reward: -79.28626444159178\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.050000066884853915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 16479\t average reward: -75.27443105756359\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.050000066219338495\n",
      "episode: 16489\t average reward: -74.58175675675676\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000006556044507\n",
      "episode: 16499\t average reward: -80.16836086404066\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.050000064908107746\n",
      "episode: 16509\t average reward: -79.49808673469387\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000006426226128\n",
      "episode: 16519\t average reward: -74.33559322033898\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.050000063622841096\n",
      "episode: 16529\t average reward: -84.11218335343787\t avg steps: 166.8\t lr: 0.0005\t epsilon: 0.05000006298978325\n",
      "episode: 16539\t average reward: -79.03729903536977\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.050000062363024435\n",
      "episode: 16549\t average reward: -75.72066666666667\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.050000061742501975\n",
      "episode: 16559\t average reward: -81.04072681704261\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000006112815381\n",
      "episode: 16569\t average reward: -79.63450479233227\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.050000060519918524\n",
      "episode: 16579\t average reward: -84.38489425981874\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.05000005991773527\n",
      "episode: 16589\t average reward: -84.17583081570997\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.05000005932154384\n",
      "episode: 16599\t average reward: -77.42613263296126\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000058731284616\n",
      "episode: 16609\t average reward: -85.44071856287425\t avg steps: 168.0\t lr: 0.0005\t epsilon: 0.05000005814689858\n",
      "episode: 16619\t average reward: -78.00584415584416\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000005756832727\n",
      "episode: 16629\t average reward: -85.44710101613867\t avg steps: 168.3\t lr: 0.0005\t epsilon: 0.05000005699551284\n",
      "episode: 16639\t average reward: -88.87630662020906\t avg steps: 173.2\t lr: 0.0005\t epsilon: 0.05000005642839801\n",
      "episode: 16649\t average reward: -73.48732008224812\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.05000005586692607\n",
      "episode: 16659\t average reward: -80.7698161065314\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05000005531104087\n",
      "episode: 16669\t average reward: -79.06761107533805\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.050000054760686814\n",
      "episode: 16679\t average reward: -78.01106050748211\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000005421580888\n",
      "episode: 16689\t average reward: -82.9944099378882\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05000005367635257\n",
      "episode: 16699\t average reward: -80.53438485804416\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000005314226393\n",
      "episode: 16709\t average reward: -81.76125\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.050000052613489575\n",
      "episode: 16719\t average reward: -81.36540880503145\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.050000052089976606\n",
      "episode: 16729\t average reward: -80.1787072243346\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05000005157167268\n",
      "episode: 16739\t average reward: -76.12052980132451\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000005105852596\n",
      "episode: 16749\t average reward: -80.29069031032299\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000005055048514\n",
      "episode: 16759\t average reward: -74.11768707482993\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.050000050047499404\n",
      "episode: 16769\t average reward: -82.5655129789864\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.05000004954951847\n",
      "episode: 16779\t average reward: -81.02765556253928\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.050000049056492524\n",
      "episode: 16789\t average reward: -82.34925558312655\t avg steps: 162.2\t lr: 0.0005\t epsilon: 0.050000048568372264\n",
      "episode: 16799\t average reward: -73.26460481099656\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.050000048085108884\n",
      "episode: 16809\t average reward: -79.0795892169448\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000004760665406\n",
      "episode: 16819\t average reward: -77.61463096015676\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.050000047132959934\n",
      "episode: 16829\t average reward: -80.18718274111676\t avg steps: 158.6\t lr: 0.0005\t epsilon: 0.05000004666397915\n",
      "episode: 16839\t average reward: -77.40026160889471\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.0500000461996648\n",
      "episode: 16849\t average reward: -84.7080024434942\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.05000004573997045\n",
      "episode: 16859\t average reward: -80.20177103099304\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000004528485014\n",
      "episode: 16869\t average reward: -80.93891687657431\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000004483425836\n",
      "episode: 16879\t average reward: -79.03024453024453\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000004438815003\n",
      "episode: 16889\t average reward: -80.63664987405542\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000004394648056\n",
      "episode: 16899\t average reward: -78.84674822923374\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000004350920577\n",
      "episode: 16909\t average reward: -76.96835860250495\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000004307628194\n",
      "episode: 16919\t average reward: -82.37391841779976\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.05000004264766578\n",
      "episode: 16929\t average reward: -81.30875\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.05000004222331441\n",
      "episode: 16939\t average reward: -77.80481457384515\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000004180318541\n",
      "episode: 16949\t average reward: -77.39947780678851\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000041387236765\n",
      "episode: 16959\t average reward: -81.35870243293824\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000004097542688\n",
      "episode: 16969\t average reward: -77.36780104712042\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000004056771457\n",
      "episode: 16979\t average reward: -81.72370877411325\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.05000004016405907\n",
      "episode: 16989\t average reward: -81.11369346733669\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.05000003976442\n",
      "episode: 16999\t average reward: -77.79635653871178\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000003936875741\n",
      "episode: 17009\t average reward: -78.65703275529866\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000003897703173\n",
      "episode: 17019\t average reward: -79.29948914431674\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000003858920379\n",
      "episode: 17029\t average reward: -83.11308068459658\t avg steps: 164.6\t lr: 0.0005\t epsilon: 0.05000003820523479\n",
      "episode: 17039\t average reward: -83.05558949297496\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.05000003782508635\n",
      "episode: 17049\t average reward: -85.07228195937873\t avg steps: 168.4\t lr: 0.0005\t epsilon: 0.050000037448720454\n",
      "episode: 17059\t average reward: -77.19569471624266\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000037076099464\n",
      "episode: 17069\t average reward: -81.50654205607476\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.050000036707186106\n",
      "episode: 17079\t average reward: -80.82023884349466\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.050000036341943506\n",
      "episode: 17089\t average reward: -77.73952879581152\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000035980335124\n",
      "episode: 17099\t average reward: -78.10887880751783\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000003562232481\n",
      "episode: 17109\t average reward: -79.87786259541984\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.050000035267876754\n",
      "episode: 17119\t average reward: -80.13197969543147\t avg steps: 158.6\t lr: 0.0005\t epsilon: 0.05000003491695552\n",
      "episode: 17129\t average reward: -78.87596401028277\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.050000034569526\n",
      "episode: 17139\t average reward: -82.12252475247524\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.05000003422555347\n",
      "episode: 17149\t average reward: -81.21477770820287\t avg steps: 160.7\t lr: 0.0005\t epsilon: 0.05000003388500353\n",
      "episode: 17159\t average reward: -77.01311475409837\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.050000033547842104\n",
      "episode: 17169\t average reward: -82.8980343980344\t avg steps: 163.8\t lr: 0.0005\t epsilon: 0.050000033214035504\n",
      "episode: 17179\t average reward: -77.61513372472277\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000003288355032\n",
      "episode: 17189\t average reward: -82.84334365325077\t avg steps: 162.5\t lr: 0.0005\t epsilon: 0.05000003255635353\n",
      "episode: 17199\t average reward: -77.68888888888888\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.0500000322324124\n",
      "episode: 17209\t average reward: -83.87181044957472\t avg steps: 165.6\t lr: 0.0005\t epsilon: 0.05000003191169454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 17219\t average reward: -77.41781270464963\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.050000031594167875\n",
      "episode: 17229\t average reward: -74.44993234100136\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.050000031279800655\n",
      "episode: 17239\t average reward: -79.18473380372033\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000003096856143\n",
      "episode: 17249\t average reward: -77.94729993493819\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.0500000306604191\n",
      "episode: 17259\t average reward: -74.0374149659864\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000003035534283\n",
      "episode: 17269\t average reward: -78.93496458467482\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000003005330213\n",
      "episode: 17279\t average reward: -80.52937460518004\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.050000029754266775\n",
      "episode: 17289\t average reward: -78.0078277886497\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000002945820687\n",
      "episode: 17299\t average reward: -78.88766946417043\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.050000029165092816\n",
      "episode: 17309\t average reward: -73.3127147766323\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.0500000288748953\n",
      "episode: 17319\t average reward: -83.68957055214725\t avg steps: 164.0\t lr: 0.0005\t epsilon: 0.05000002858758529\n",
      "episode: 17329\t average reward: -80.51423149905123\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000002830313406\n",
      "episode: 17339\t average reward: -78.01624431448992\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000002802151317\n",
      "episode: 17349\t average reward: -86.54680977936792\t avg steps: 168.7\t lr: 0.0005\t epsilon: 0.05000002774269446\n",
      "episode: 17359\t average reward: -77.32764281024293\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000027466650034\n",
      "episode: 17369\t average reward: -82.9316923076923\t avg steps: 163.5\t lr: 0.0005\t epsilon: 0.0500000271933523\n",
      "episode: 17379\t average reward: -74.53783783783784\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000002692277392\n",
      "episode: 17389\t average reward: -80.0795165394402\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000002665488785\n",
      "episode: 17399\t average reward: -81.48122653316646\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.05000002638966728\n",
      "episode: 17409\t average reward: -79.89961880559085\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.050000026127085706\n",
      "episode: 17419\t average reward: -82.88314883148831\t avg steps: 163.6\t lr: 0.0005\t epsilon: 0.05000002586711686\n",
      "episode: 17429\t average reward: -81.89234598630989\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.050000025609734745\n",
      "episode: 17439\t average reward: -83.49358582773365\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.05000002535491363\n",
      "episode: 17449\t average reward: -74.68690958164642\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05000002510262802\n",
      "episode: 17459\t average reward: -84.02366504854369\t avg steps: 165.8\t lr: 0.0005\t epsilon: 0.050000024852852695\n",
      "episode: 17469\t average reward: -78.58785529715762\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000002460556268\n",
      "episode: 17479\t average reward: -73.07580978635424\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.050000024360733246\n",
      "episode: 17489\t average reward: -80.47148288973384\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.0500000241183399\n",
      "episode: 17499\t average reward: -78.89619600257898\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.050000023878358404\n",
      "episode: 17509\t average reward: -85.19744835965979\t avg steps: 165.6\t lr: 0.0005\t epsilon: 0.05000002364076477\n",
      "episode: 17519\t average reward: -75.896\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000002340553523\n",
      "episode: 17529\t average reward: -73.91689373297002\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000002317264626\n",
      "episode: 17539\t average reward: -77.77163305139882\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000002294207458\n",
      "episode: 17549\t average reward: -76.94276315789473\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.050000022713797124\n",
      "episode: 17559\t average reward: -84.45317220543807\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.05000002248779107\n",
      "episode: 17569\t average reward: -77.44459016393442\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000002226403381\n",
      "episode: 17579\t average reward: -77.21484888304862\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000002204250297\n",
      "episode: 17589\t average reward: -81.41077019411397\t avg steps: 160.7\t lr: 0.0005\t epsilon: 0.0500000218231764\n",
      "episode: 17599\t average reward: -81.579375\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.05000002160603217\n",
      "episode: 17609\t average reward: -84.8037326911499\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.05000002139104855\n",
      "episode: 17619\t average reward: -77.708984375\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000002117820407\n",
      "episode: 17629\t average reward: -76.11383189940437\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000002096747742\n",
      "episode: 17639\t average reward: -79.23047375160051\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.050000020758847526\n",
      "episode: 17649\t average reward: -81.64602876797998\t avg steps: 160.9\t lr: 0.0005\t epsilon: 0.05000002055229354\n",
      "episode: 17659\t average reward: -77.24491135915956\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000020347794806\n",
      "episode: 17669\t average reward: -77.30235602094241\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000020145330865\n",
      "episode: 17679\t average reward: -74.17990495587237\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000001994488147\n",
      "episode: 17689\t average reward: -76.61548643282595\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000001974642659\n",
      "episode: 17699\t average reward: -76.74403183023873\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.05000001954994636\n",
      "episode: 17709\t average reward: -77.33224115334207\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.050000019355421144\n",
      "episode: 17719\t average reward: -74.19416157501698\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.050000019162831484\n",
      "episode: 17729\t average reward: -77.85510071474984\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.050000018972158125\n",
      "episode: 17739\t average reward: -81.2218045112782\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.050000018783382\n",
      "episode: 17749\t average reward: -75.96797865243495\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05000001859648422\n",
      "episode: 17759\t average reward: -79.61033163265306\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.050000018411446114\n",
      "episode: 17769\t average reward: -76.90579710144928\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000001822824916\n",
      "episode: 17779\t average reward: -76.51094890510949\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000001804687506\n",
      "episode: 17789\t average reward: -78.43078913324709\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000001786730565\n",
      "episode: 17799\t average reward: -82.10106051154087\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000001768952299\n",
      "episode: 17809\t average reward: -78.51911860012962\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000001751350929\n",
      "episode: 17819\t average reward: -73.46364883401921\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.050000017339246965\n",
      "episode: 17829\t average reward: -73.15506547208821\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05000001716671858\n",
      "episode: 17839\t average reward: -81.56222639149469\t avg steps: 160.9\t lr: 0.0005\t epsilon: 0.05000001699590687\n",
      "episode: 17849\t average reward: -77.85134250163719\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000001682679477\n",
      "episode: 17859\t average reward: -76.39243027888446\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05000001665936537\n",
      "episode: 17869\t average reward: -76.4830789648308\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000001649360191\n",
      "episode: 17879\t average reward: -82.94766009852216\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.05000001632948783\n",
      "episode: 17889\t average reward: -78.13046314416178\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000001616700671\n",
      "episode: 17899\t average reward: -79.1805912596401\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.0500000160061423\n",
      "episode: 17909\t average reward: -76.76765676567656\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000001584687853\n",
      "episode: 17919\t average reward: -75.7314629258517\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.050000015689199456\n",
      "episode: 17929\t average reward: -74.11556764106051\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05000001553308931\n",
      "episode: 17939\t average reward: -77.38713910761155\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000001537853249\n",
      "episode: 17949\t average reward: -78.64322580645161\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000001522551353\n",
      "episode: 17959\t average reward: -75.8411214953271\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.05000001507401714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 17969\t average reward: -75.62868632707774\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000001492402817\n",
      "episode: 17979\t average reward: -77.1218872870249\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05000001477553161\n",
      "episode: 17989\t average reward: -77.50850785340315\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000001462851261\n",
      "episode: 17999\t average reward: -78.29785853341986\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.050000014482956476\n",
      "episode: 18009\t average reward: -77.77254901960784\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000001433884865\n",
      "episode: 18019\t average reward: -78.74645161290323\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000014196174725\n",
      "episode: 18029\t average reward: -80.71994884910485\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.050000014054920425\n",
      "episode: 18039\t average reward: -78.76162790697674\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000001391507163\n",
      "episode: 18049\t average reward: -76.5933774834437\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000001377661435\n",
      "episode: 18059\t average reward: -81.97258566978194\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.050000013639534754\n",
      "episode: 18069\t average reward: -76.73087071240106\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.050000013503819114\n",
      "episode: 18079\t average reward: -74.0183923705722\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.050000013369453866\n",
      "episode: 18089\t average reward: -75.992\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000001323642558\n",
      "episode: 18099\t average reward: -75.09979770734996\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000001310472094\n",
      "episode: 18109\t average reward: -75.66042780748663\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.050000012974326796\n",
      "episode: 18119\t average reward: -78.06046814044213\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.050000012845230084\n",
      "episode: 18129\t average reward: -76.97222222222223\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000012717417906\n",
      "episode: 18139\t average reward: -79.72396166134185\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000001259087749\n",
      "episode: 18149\t average reward: -76.93737640079104\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000001246559616\n",
      "episode: 18159\t average reward: -78.71872974724563\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000001234156141\n",
      "episode: 18169\t average reward: -77.23413996075867\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000001221876082\n",
      "episode: 18179\t average reward: -78.59896507115135\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000001209718212\n",
      "episode: 18189\t average reward: -75.7927807486631\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000001197681315\n",
      "episode: 18199\t average reward: -81.94900497512438\t avg steps: 161.8\t lr: 0.0005\t epsilon: 0.050000011857641864\n",
      "episode: 18209\t average reward: -84.18727272727273\t avg steps: 166.0\t lr: 0.0005\t epsilon: 0.050000011739656354\n",
      "episode: 18219\t average reward: -77.72786458333333\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000001162284482\n",
      "episode: 18229\t average reward: -82.65144972239358\t avg steps: 163.1\t lr: 0.0005\t epsilon: 0.05000001150719559\n",
      "episode: 18239\t average reward: -76.00466666666667\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000001139269707\n",
      "episode: 18249\t average reward: -76.12724850099933\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05000001127933785\n",
      "episode: 18259\t average reward: -75.25554808338937\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000001116710656\n",
      "episode: 18269\t average reward: -77.60707269155206\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000001105599199\n",
      "episode: 18279\t average reward: -80.20101781170483\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000001094598303\n",
      "episode: 18289\t average reward: -78.23086900129702\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000001083706868\n",
      "episode: 18299\t average reward: -74.90376850605652\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.05000001072923805\n",
      "episode: 18309\t average reward: -78.21373056994818\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000001062248035\n",
      "episode: 18319\t average reward: -82.38809671419715\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.050000010516784904\n",
      "episode: 18329\t average reward: -75.68808567603749\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.050000010412141145\n",
      "episode: 18339\t average reward: -73.67395762132604\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000001030853861\n",
      "episode: 18349\t average reward: -76.48972829688536\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.050000010205966935\n",
      "episode: 18359\t average reward: -84.3217972070431\t avg steps: 165.7\t lr: 0.0005\t epsilon: 0.05000001010441587\n",
      "episode: 18369\t average reward: -81.32706766917293\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000001000387525\n",
      "episode: 18379\t average reward: -80.29601518026566\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000000990433503\n",
      "episode: 18389\t average reward: -78.83989670755327\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000980578525\n",
      "episode: 18399\t average reward: -74.38753387533875\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000970821605\n",
      "episode: 18409\t average reward: -81.45984943538268\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000000961161769\n",
      "episode: 18419\t average reward: -81.31469849246231\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.0500000095159805\n",
      "episode: 18429\t average reward: -78.35737491877843\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000942129491\n",
      "episode: 18439\t average reward: -80.78584965255844\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.050000009327551456\n",
      "episode: 18449\t average reward: -84.89703210175651\t avg steps: 166.1\t lr: 0.0005\t epsilon: 0.050000009234740767\n",
      "episode: 18459\t average reward: -76.39894319682959\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05000000914285357\n",
      "episode: 18469\t average reward: -76.94389438943894\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000905188065\n",
      "episode: 18479\t average reward: -76.99802371541502\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000896181293\n",
      "episode: 18489\t average reward: -76.37118193891102\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.0500000088726414\n",
      "episode: 18499\t average reward: -81.24401008827239\t avg steps: 159.6\t lr: 0.0005\t epsilon: 0.05000000878435715\n",
      "episode: 18509\t average reward: -77.36811023622047\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.050000008696951335\n",
      "episode: 18519\t average reward: -73.5968514715948\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.050000008610415224\n",
      "episode: 18529\t average reward: -81.29197994987469\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000000852474016\n",
      "episode: 18539\t average reward: -79.94787031150668\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000000843991758\n",
      "episode: 18549\t average reward: -76.35827814569537\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000000835593899\n",
      "episode: 18559\t average reward: -76.26808228268082\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.050000008272796014\n",
      "episode: 18569\t average reward: -75.28244788164089\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000000819048032\n",
      "episode: 18579\t average reward: -76.58702845797485\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.050000008108983675\n",
      "episode: 18589\t average reward: -84.77237237237237\t avg steps: 167.5\t lr: 0.0005\t epsilon: 0.05000000802829794\n",
      "episode: 18599\t average reward: -81.49781386633354\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.05000000794841504\n",
      "episode: 18609\t average reward: -78.10273081924578\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000786932699\n",
      "episode: 18619\t average reward: -76.61920529801324\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.050000007791025876\n",
      "episode: 18629\t average reward: -77.59385219097449\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000771350387\n",
      "episode: 18639\t average reward: -77.3967320261438\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000763675323\n",
      "episode: 18649\t average reward: -79.6941251596424\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.050000007560766266\n",
      "episode: 18659\t average reward: -77.68672334859386\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000748553538\n",
      "episode: 18669\t average reward: -76.9452506596306\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.050000007411053066\n",
      "episode: 18679\t average reward: -79.50031989763276\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000733731185\n",
      "episode: 18689\t average reward: -80.70643939393939\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.05000000726430438\n",
      "episode: 18699\t average reward: -73.01517241379311\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000719202334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 18709\t average reward: -76.76897689768977\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000007120461515\n",
      "episode: 18719\t average reward: -81.47371714643305\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.05000000704961174\n",
      "episode: 18729\t average reward: -77.09671052631579\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000697946693\n",
      "episode: 18739\t average reward: -80.32637571157495\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000000691002007\n",
      "episode: 18749\t average reward: -79.19730077120822\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.050000006841264225\n",
      "episode: 18759\t average reward: -79.31153846153846\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05000000677319251\n",
      "episode: 18769\t average reward: -76.91578947368421\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000670579812\n",
      "episode: 18779\t average reward: -77.83071895424837\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.050000006639074314\n",
      "episode: 18789\t average reward: -82.13490099009901\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.05000000657301442\n",
      "episode: 18799\t average reward: -76.7504924491136\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000006507611834\n",
      "episode: 18809\t average reward: -82.07347447073475\t avg steps: 161.6\t lr: 0.0005\t epsilon: 0.05000000644286001\n",
      "episode: 18819\t average reward: -79.486867392697\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000000637875249\n",
      "episode: 18829\t average reward: -74.125\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.050000006315282834\n",
      "episode: 18839\t average reward: -80.36945500633713\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.050000006252444724\n",
      "episode: 18849\t average reward: -78.66300129366105\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000619023186\n",
      "episode: 18859\t average reward: -75.04429530201342\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.05000000612863802\n",
      "episode: 18869\t average reward: -85.63474122546104\t avg steps: 169.1\t lr: 0.0005\t epsilon: 0.05000000606765705\n",
      "episode: 18879\t average reward: -82.59579728059333\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.05000000600728286\n",
      "episode: 18889\t average reward: -79.07027724049\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.0500000059475094\n",
      "episode: 18899\t average reward: -77.56033920417482\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000588833069\n",
      "episode: 18909\t average reward: -81.55659787367104\t avg steps: 160.9\t lr: 0.0005\t epsilon: 0.05000000582974082\n",
      "episode: 18919\t average reward: -79.77869897959184\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000000577173393\n",
      "episode: 18929\t average reward: -78.20388349514563\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000571430422\n",
      "episode: 18939\t average reward: -78.04486345903771\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000565744594\n",
      "episode: 18949\t average reward: -76.6996699669967\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000560115341\n",
      "episode: 18959\t average reward: -80.47465145754119\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05000000554542101\n",
      "episode: 18969\t average reward: -77.91780821917808\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000005490243145\n",
      "episode: 18979\t average reward: -85.84491978609626\t avg steps: 169.3\t lr: 0.0005\t epsilon: 0.05000000543561431\n",
      "episode: 18989\t average reward: -83.3138101109741\t avg steps: 163.2\t lr: 0.0005\t epsilon: 0.050000005381529045\n",
      "episode: 18999\t average reward: -75.93324432576769\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.05000000532798194\n",
      "episode: 19009\t average reward: -79.02253702511268\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000000527496763\n",
      "episode: 19019\t average reward: -76.32119205298014\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.050000005222480826\n",
      "episode: 19029\t average reward: -77.7106466361855\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.050000005170516275\n",
      "episode: 19039\t average reward: -77.1833660772757\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.050000005119068776\n",
      "episode: 19049\t average reward: -75.15013404825737\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.050000005068133194\n",
      "episode: 19059\t average reward: -76.37707090788602\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000000501770442\n",
      "episode: 19069\t average reward: -73.91008174386921\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000000496777743\n",
      "episode: 19079\t average reward: -80.0012706480305\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05000000491834722\n",
      "episode: 19089\t average reward: -74.18070652173913\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.050000004869408844\n",
      "episode: 19099\t average reward: -82.48198757763976\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05000000482095742\n",
      "episode: 19109\t average reward: -82.33188854489164\t avg steps: 162.5\t lr: 0.0005\t epsilon: 0.05000000477298809\n",
      "episode: 19119\t average reward: -82.4597629444791\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000000472549607\n",
      "episode: 19129\t average reward: -85.56186491332934\t avg steps: 168.3\t lr: 0.0005\t epsilon: 0.050000004678476595\n",
      "episode: 19139\t average reward: -81.2588161209068\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000000463192498\n",
      "episode: 19149\t average reward: -79.50893997445722\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.050000004585836554\n",
      "episode: 19159\t average reward: -88.49409681227863\t avg steps: 170.4\t lr: 0.0005\t epsilon: 0.05000000454020671\n",
      "episode: 19169\t average reward: -79.26568501920615\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.050000004495030906\n",
      "episode: 19179\t average reward: -75.66577896138482\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.0500000044503046\n",
      "episode: 19189\t average reward: -77.28797886393659\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05000000440602333\n",
      "episode: 19199\t average reward: -77.48815789473684\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.050000004362182666\n",
      "episode: 19209\t average reward: -77.3782894736842\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000431877822\n",
      "episode: 19219\t average reward: -74.97983870967742\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.050000004275805664\n",
      "episode: 19229\t average reward: -81.85544430538172\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.05000000423326068\n",
      "episode: 19239\t average reward: -77.7578125\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050000004191139036\n",
      "episode: 19249\t average reward: -78.87870967741935\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000004149436506\n",
      "episode: 19259\t average reward: -77.2111475409836\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000410814892\n",
      "episode: 19269\t average reward: -80.471853257432\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000000406727216\n",
      "episode: 19279\t average reward: -80.18106734434562\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.050000004026802124\n",
      "episode: 19289\t average reward: -78.04036458333333\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000000398673477\n",
      "episode: 19299\t average reward: -77.96610169491525\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.0500000039470661\n",
      "episode: 19309\t average reward: -78.29209844559585\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.050000003907792134\n",
      "episode: 19319\t average reward: -77.86123778501629\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05000000386890895\n",
      "episode: 19329\t average reward: -79.8329081632653\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000000383041266\n",
      "episode: 19339\t average reward: -76.74736147757255\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000000379229942\n",
      "episode: 19349\t average reward: -76.18683510638297\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000000375456541\n",
      "episode: 19359\t average reward: -80.75833857772184\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.050000003717206865\n",
      "episode: 19369\t average reward: -78.51839896707553\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000368022004\n",
      "episode: 19379\t average reward: -76.54960317460318\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000003643601236\n",
      "episode: 19389\t average reward: -75.998\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.0500000036073468\n",
      "episode: 19399\t average reward: -78.19413680781759\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.0500000035714531\n",
      "episode: 19409\t average reward: -77.90395846852694\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05000000353591655\n",
      "episode: 19419\t average reward: -75.87733333333334\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000000350073359\n",
      "episode: 19429\t average reward: -77.08672798948751\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000000346590071\n",
      "episode: 19439\t average reward: -79.07559256886611\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000000343141442\n",
      "episode: 19449\t average reward: -78.64732430689878\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05000000339727127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 19459\t average reward: -81.15809284818067\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000000336346786\n",
      "episode: 19469\t average reward: -81.38784461152882\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.0500000033300008\n",
      "episode: 19479\t average reward: -80.80754716981131\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.050000003296866734\n",
      "episode: 19489\t average reward: -79.32415118513774\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000000326406236\n",
      "episode: 19499\t average reward: -77.83799609629148\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.0500000032315844\n",
      "episode: 19509\t average reward: -77.44546048334422\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.0500000031994296\n",
      "episode: 19519\t average reward: -79.7123724489796\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.050000003167594745\n",
      "episode: 19529\t average reward: -77.37508196721312\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000313607665\n",
      "episode: 19539\t average reward: -79.40089514066496\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05000000310487216\n",
      "episode: 19549\t average reward: -78.96915167095116\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000000307397817\n",
      "episode: 19559\t average reward: -85.18432076600838\t avg steps: 168.1\t lr: 0.0005\t epsilon: 0.050000003043391576\n",
      "episode: 19569\t average reward: -82.57573891625616\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.05000000301310932\n",
      "episode: 19579\t average reward: -80.14946168461051\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.050000002983128386\n",
      "episode: 19589\t average reward: -78.32186891628812\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05000000295344576\n",
      "episode: 19599\t average reward: -75.91194129419613\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.050000002924058484\n",
      "episode: 19609\t average reward: -80.25095057034221\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05000000289496362\n",
      "episode: 19619\t average reward: -74.02314499659633\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000286615825\n",
      "episode: 19629\t average reward: -82.2372986369269\t avg steps: 162.4\t lr: 0.0005\t epsilon: 0.050000002837639494\n",
      "episode: 19639\t average reward: -78.03919007184847\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000280940451\n",
      "episode: 19649\t average reward: -81.25172197871008\t avg steps: 160.7\t lr: 0.0005\t epsilon: 0.05000000278145047\n",
      "episode: 19659\t average reward: -78.1948051948052\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000275377458\n",
      "episode: 19669\t average reward: -78.9175788795879\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000000272637406\n",
      "episode: 19679\t average reward: -78.79677419354839\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000002699246184\n",
      "episode: 19689\t average reward: -78.6\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000267238824\n",
      "episode: 19699\t average reward: -79.4996805111821\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000000264579753\n",
      "episode: 19709\t average reward: -76.54130865829478\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.050000002619471406\n",
      "episode: 19719\t average reward: -78.94662379421221\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000259340723\n",
      "episode: 19729\t average reward: -76.49504296100463\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.0500000025676024\n",
      "episode: 19739\t average reward: -74.01293396868618\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000254205433\n",
      "episode: 19749\t average reward: -79.95422759059123\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000000251676046\n",
      "episode: 19759\t average reward: -79.78411274823831\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000000249171828\n",
      "episode: 19769\t average reward: -79.71072796934865\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.050000002466925264\n",
      "episode: 19779\t average reward: -83.91929611650485\t avg steps: 165.8\t lr: 0.0005\t epsilon: 0.05000000244237895\n",
      "episode: 19789\t average reward: -78.95099935525468\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05000000241807687\n",
      "episode: 19799\t average reward: -78.87169568020632\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.050000002394016606\n",
      "episode: 19809\t average reward: -84.69671132764921\t avg steps: 165.2\t lr: 0.0005\t epsilon: 0.050000002370195744\n",
      "episode: 19819\t average reward: -78.37370466321244\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.0500000023466119\n",
      "episode: 19829\t average reward: -79.75976937860347\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.050000002323262724\n",
      "episode: 19839\t average reward: -74.99059139784946\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.050000002300145875\n",
      "episode: 19849\t average reward: -74.70532703978422\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000000227725904\n",
      "episode: 19859\t average reward: -76.91178406846609\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05000000225459993\n",
      "episode: 19869\t average reward: -74.86734006734007\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05000000223216629\n",
      "episode: 19879\t average reward: -80.21582278481013\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000000220995586\n",
      "episode: 19889\t average reward: -78.89599483204134\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.050000002187966436\n",
      "episode: 19899\t average reward: -75.68382352941177\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.0500000021661958\n",
      "episode: 19909\t average reward: -76.74059405940594\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000214464179\n",
      "episode: 19919\t average reward: -80.7570799244808\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000000212330225\n",
      "episode: 19929\t average reward: -76.20772303595206\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000210217504\n",
      "episode: 19939\t average reward: -79.97896749521989\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000000208125805\n",
      "episode: 19949\t average reward: -81.87406483790524\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.05000000206054919\n",
      "episode: 19959\t average reward: -80.2253164556962\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.050000002040046385\n",
      "episode: 19969\t average reward: -79.13222079589217\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000201974758\n",
      "episode: 19979\t average reward: -78.47313915857605\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000199965076\n",
      "episode: 19989\t average reward: -72.62135922330097\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.0500000019797539\n",
      "episode: 19999\t average reward: -81.44603867747972\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000000196005502\n",
      "episode: 20009\t average reward: -79.848948374761\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.050000001940552145\n",
      "episode: 20019\t average reward: -76.75727513227513\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000000192124333\n",
      "episode: 20029\t average reward: -82.52222222222223\t avg steps: 163.0\t lr: 0.0005\t epsilon: 0.05000000190212664\n",
      "episode: 20039\t average reward: -76.43928334439283\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000188320016\n",
      "episode: 20049\t average reward: -86.15068493150685\t avg steps: 168.9\t lr: 0.0005\t epsilon: 0.05000000186446201\n",
      "episode: 20059\t average reward: -83.20403176542456\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.0500000018459103\n",
      "episode: 20069\t average reward: -85.82777115613825\t avg steps: 168.8\t lr: 0.0005\t epsilon: 0.05000000182754319\n",
      "episode: 20079\t average reward: -84.26662636033858\t avg steps: 166.4\t lr: 0.0005\t epsilon: 0.050000001809358825\n",
      "episode: 20089\t average reward: -80.48641819330385\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.05000000179135541\n",
      "episode: 20099\t average reward: -87.87019790454016\t avg steps: 172.8\t lr: 0.0005\t epsilon: 0.05000000177353112\n",
      "episode: 20109\t average reward: -79.24312220089571\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000175588419\n",
      "episode: 20119\t average reward: -79.61730769230769\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.050000001738412854\n",
      "episode: 20129\t average reward: -82.40937114673243\t avg steps: 163.2\t lr: 0.0005\t epsilon: 0.05000000172111536\n",
      "episode: 20139\t average reward: -82.36504014823966\t avg steps: 162.9\t lr: 0.0005\t epsilon: 0.05000000170398997\n",
      "episode: 20149\t average reward: -84.8993409227082\t avg steps: 167.9\t lr: 0.0005\t epsilon: 0.05000000168703499\n",
      "episode: 20159\t average reward: -80.21730890713835\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.05000000167024871\n",
      "episode: 20169\t average reward: -81.94489164086687\t avg steps: 162.5\t lr: 0.0005\t epsilon: 0.05000000165362946\n",
      "episode: 20179\t average reward: -78.87748556767158\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000163717557\n",
      "episode: 20189\t average reward: -81.77032898820609\t avg steps: 162.1\t lr: 0.0005\t epsilon: 0.0500000016208854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 20199\t average reward: -79.04434447300771\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000000160475732\n",
      "episode: 20209\t average reward: -79.95825426944971\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000000158878972\n",
      "episode: 20219\t average reward: -80.7369414726243\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.050000001572981\n",
      "episode: 20229\t average reward: -77.4869109947644\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000001557329574\n",
      "episode: 20239\t average reward: -78.52512886597938\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.050000001541833886\n",
      "episode: 20249\t average reward: -84.97462235649547\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.05000000152649239\n",
      "episode: 20259\t average reward: -88.13267670915411\t avg steps: 173.6\t lr: 0.0005\t epsilon: 0.05000000151130353\n",
      "episode: 20269\t average reward: -85.24835032993401\t avg steps: 167.7\t lr: 0.0005\t epsilon: 0.05000000149626581\n",
      "episode: 20279\t average reward: -89.38355376653249\t avg steps: 174.9\t lr: 0.0005\t epsilon: 0.05000000148137772\n",
      "episode: 20289\t average reward: -81.21902377972465\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.050000001466637765\n",
      "episode: 20299\t average reward: -87.63090379008746\t avg steps: 172.5\t lr: 0.0005\t epsilon: 0.050000001452044474\n",
      "episode: 20309\t average reward: -81.19364881693649\t avg steps: 161.6\t lr: 0.0005\t epsilon: 0.05000000143759639\n",
      "episode: 20319\t average reward: -76.04484605087015\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000000142329206\n",
      "episode: 20329\t average reward: -79.9232245681382\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000140913007\n",
      "episode: 20339\t average reward: -83.07478368355996\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.050000001395108996\n",
      "episode: 20349\t average reward: -85.48038049940547\t avg steps: 169.2\t lr: 0.0005\t epsilon: 0.05000000138122743\n",
      "episode: 20359\t average reward: -85.33233532934132\t avg steps: 168.0\t lr: 0.0005\t epsilon: 0.05000000136748398\n",
      "episode: 20369\t average reward: -83.89106487148103\t avg steps: 164.4\t lr: 0.0005\t epsilon: 0.05000000135387729\n",
      "episode: 20379\t average reward: -80.54591513616212\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000000134040599\n",
      "episode: 20389\t average reward: -83.20915841584159\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.05000000132706873\n",
      "episode: 20399\t average reward: -86.0279761904762\t avg steps: 169.0\t lr: 0.0005\t epsilon: 0.05000000131386417\n",
      "episode: 20409\t average reward: -82.92009987515605\t avg steps: 161.2\t lr: 0.0005\t epsilon: 0.050000001300791005\n",
      "episode: 20419\t average reward: -85.56009615384616\t avg steps: 167.4\t lr: 0.0005\t epsilon: 0.05000000128784792\n",
      "episode: 20429\t average reward: -92.44039351851852\t avg steps: 173.8\t lr: 0.0005\t epsilon: 0.050000001275033616\n",
      "episode: 20439\t average reward: -79.71646535282899\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000000126234682\n",
      "episode: 20449\t average reward: -79.46183450930083\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000124978626\n",
      "episode: 20459\t average reward: -85.34571599760335\t avg steps: 167.9\t lr: 0.0005\t epsilon: 0.050000001237350676\n",
      "episode: 20469\t average reward: -82.98199875853507\t avg steps: 162.1\t lr: 0.0005\t epsilon: 0.05000000122503884\n",
      "episode: 20479\t average reward: -79.16645408163265\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.0500000012128495\n",
      "episode: 20489\t average reward: -83.56200366524129\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.05000000120078144\n",
      "episode: 20499\t average reward: -76.73718791064388\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.050000001188833465\n",
      "episode: 20509\t average reward: -87.28504122497056\t avg steps: 170.8\t lr: 0.0005\t epsilon: 0.05000000117700437\n",
      "episode: 20519\t average reward: -83.56341463414634\t avg steps: 165.0\t lr: 0.0005\t epsilon: 0.05000000116529298\n",
      "episode: 20529\t average reward: -79.17737789203085\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.050000001153698126\n",
      "episode: 20539\t average reward: -79.93054662379421\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.050000001142218635\n",
      "episode: 20549\t average reward: -82.094468614046\t avg steps: 161.9\t lr: 0.0005\t epsilon: 0.05000000113085337\n",
      "episode: 20559\t average reward: -79.27774214239898\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000111960119\n",
      "episode: 20569\t average reward: -78.31237848347375\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000110846098\n",
      "episode: 20579\t average reward: -84.44875682231655\t avg steps: 165.9\t lr: 0.0005\t epsilon: 0.05000000109743161\n",
      "episode: 20589\t average reward: -90.33975084937713\t avg steps: 177.6\t lr: 0.0005\t epsilon: 0.05000000108651198\n",
      "episode: 20599\t average reward: -74.30305084745763\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.050000001075701\n",
      "episode: 20609\t average reward: -80.83343808925204\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.0500000010649976\n",
      "episode: 20619\t average reward: -75.95944148936171\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.050000001054400695\n",
      "episode: 20629\t average reward: -80.92834695160276\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05000000104390923\n",
      "episode: 20639\t average reward: -81.9075682382134\t avg steps: 162.2\t lr: 0.0005\t epsilon: 0.050000001033522166\n",
      "episode: 20649\t average reward: -82.20420792079207\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.05000000102323845\n",
      "episode: 20659\t average reward: -78.42227979274611\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000101305705\n",
      "episode: 20669\t average reward: -85.27914110429448\t avg steps: 164.0\t lr: 0.0005\t epsilon: 0.05000000100297697\n",
      "episode: 20679\t average reward: -80.69211356466877\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000099299718\n",
      "episode: 20689\t average reward: -76.88235294117646\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.050000000983116695\n",
      "episode: 20699\t average reward: -77.47385620915033\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000097333452\n",
      "episode: 20709\t average reward: -78.65209003215435\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000096364968\n",
      "episode: 20719\t average reward: -79.3951250801796\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.0500000009540612\n",
      "episode: 20729\t average reward: -76.5978835978836\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000000944568135\n",
      "episode: 20739\t average reward: -73.04137931034482\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000093516953\n",
      "episode: 20749\t average reward: -81.64965774735532\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.050000000925864437\n",
      "episode: 20759\t average reward: -83.0528905289053\t avg steps: 163.6\t lr: 0.0005\t epsilon: 0.05000000091665193\n",
      "episode: 20769\t average reward: -84.62364945978392\t avg steps: 167.6\t lr: 0.0005\t epsilon: 0.05000000090753109\n",
      "episode: 20779\t average reward: -74.96236559139786\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.050000000898501006\n",
      "episode: 20789\t average reward: -73.81296928327644\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.05000000088956077\n",
      "episode: 20799\t average reward: -82.28678304239402\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.050000000880709494\n",
      "episode: 20809\t average reward: -80.23640960809102\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.05000000087194629\n",
      "episode: 20819\t average reward: -74.73247978436657\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000086327028\n",
      "episode: 20829\t average reward: -76.36103723404256\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000000085468059\n",
      "episode: 20839\t average reward: -80.16327827191868\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05000000084617638\n",
      "episode: 20849\t average reward: -77.88135593220339\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000083775678\n",
      "episode: 20859\t average reward: -83.27121771217712\t avg steps: 163.6\t lr: 0.0005\t epsilon: 0.050000000829420965\n",
      "episode: 20869\t average reward: -85.96964285714286\t avg steps: 169.0\t lr: 0.0005\t epsilon: 0.05000000082116809\n",
      "episode: 20879\t average reward: -75.44214046822742\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000081299733\n",
      "episode: 20889\t average reward: -77.01454064771976\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000000080490787\n",
      "episode: 20899\t average reward: -82.06128830519074\t avg steps: 160.9\t lr: 0.0005\t epsilon: 0.050000000796898904\n",
      "episode: 20909\t average reward: -83.07753846153847\t avg steps: 163.5\t lr: 0.0005\t epsilon: 0.05000000078896963\n",
      "episode: 20919\t average reward: -77.83136482939632\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000000078111925\n",
      "episode: 20929\t average reward: -80.36259541984732\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000077334698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 20939\t average reward: -81.9857849196539\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.05000000076565205\n",
      "episode: 20949\t average reward: -81.91687344913151\t avg steps: 162.2\t lr: 0.0005\t epsilon: 0.05000000075803369\n",
      "episode: 20959\t average reward: -80.69716088328076\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000075049112\n",
      "episode: 20969\t average reward: -80.56075949367089\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000000074302361\n",
      "episode: 20979\t average reward: -77.79569190600522\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000073563041\n",
      "episode: 20989\t average reward: -77.68770331815224\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000072831076\n",
      "episode: 20999\t average reward: -78.25307443365696\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000072106395\n",
      "episode: 21009\t average reward: -76.41990771259064\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000071388924\n",
      "episode: 21019\t average reward: -74.61782579338285\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.050000000706785924\n",
      "episode: 21029\t average reward: -77.82096354166667\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050000000699753286\n",
      "episode: 21039\t average reward: -79.88910133843213\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.050000000692790626\n",
      "episode: 21049\t average reward: -79.9343949044586\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.050000000685897245\n",
      "episode: 21059\t average reward: -78.61294498381876\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.050000000679072454\n",
      "episode: 21069\t average reward: -77.65382103200523\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000067231557\n",
      "episode: 21079\t average reward: -81.21016311166876\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000000066562592\n",
      "episode: 21089\t average reward: -77.10315374507228\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000000065900283\n",
      "episode: 21099\t average reward: -78.25454545454545\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000065244564\n",
      "episode: 21109\t average reward: -82.05423940149626\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.050000000645953696\n",
      "episode: 21119\t average reward: -75.98070525615435\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000063952635\n",
      "episode: 21129\t average reward: -76.40689198144466\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.050000000633162955\n",
      "episode: 21139\t average reward: -77.56955380577428\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.050000000626862884\n",
      "episode: 21149\t average reward: -80.40900443880787\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05000000062062549\n",
      "episode: 21159\t average reward: -76.98161523309258\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05000000061445017\n",
      "episode: 21169\t average reward: -77.9875816993464\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000060833628\n",
      "episode: 21179\t average reward: -81.5626168224299\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.05000000060228323\n",
      "episode: 21189\t average reward: -81.53216739537788\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.050000000596290416\n",
      "episode: 21199\t average reward: -76.88223684210526\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000059035723\n",
      "episode: 21209\t average reward: -82.5923645320197\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.050000000584483076\n",
      "episode: 21219\t average reward: -84.49849124924563\t avg steps: 166.7\t lr: 0.0005\t epsilon: 0.050000000578667374\n",
      "episode: 21229\t average reward: -84.54918527459263\t avg steps: 166.7\t lr: 0.0005\t epsilon: 0.050000000572909535\n",
      "episode: 21239\t average reward: -82.6379417234966\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.05000000056720899\n",
      "episode: 21249\t average reward: -75.01343183344527\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.050000000561565165\n",
      "episode: 21259\t average reward: -80.65530303030303\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.0500000005559775\n",
      "episode: 21269\t average reward: -76.8665785997358\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.050000000550445435\n",
      "episode: 21279\t average reward: -77.77154046997389\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000544968407\n",
      "episode: 21289\t average reward: -77.99412915851272\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000053954588\n",
      "episode: 21299\t average reward: -84.00182926829268\t avg steps: 165.0\t lr: 0.0005\t epsilon: 0.05000000053417731\n",
      "episode: 21309\t average reward: -75.73550966022651\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05000000052886216\n",
      "episode: 21319\t average reward: -80.51133501259446\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000000052359989\n",
      "episode: 21329\t average reward: -73.55479452054794\t avg steps: 147.0\t lr: 0.0005\t epsilon: 0.050000000518389986\n",
      "episode: 21339\t average reward: -78.45184227537169\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000000051323192\n",
      "episode: 21349\t average reward: -79.79041533546327\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000000050812518\n",
      "episode: 21359\t average reward: -86.0213649851632\t avg steps: 169.5\t lr: 0.0005\t epsilon: 0.05000000050306925\n",
      "episode: 21369\t average reward: -75.2458137977227\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000049806362\n",
      "episode: 21379\t average reward: -77.09007232084156\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000000049310781\n",
      "episode: 21389\t average reward: -79.0673076923077\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.0500000004882013\n",
      "episode: 21399\t average reward: -82.70308641975309\t avg steps: 163.0\t lr: 0.0005\t epsilon: 0.05000000048334362\n",
      "episode: 21409\t average reward: -79.61203585147247\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000000047853427\n",
      "episode: 21419\t average reward: -74.58203916272788\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.050000000473772774\n",
      "episode: 21429\t average reward: -79.17477592829705\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.050000000469058656\n",
      "episode: 21439\t average reward: -82.96432964329644\t avg steps: 163.6\t lr: 0.0005\t epsilon: 0.050000000464391445\n",
      "episode: 21449\t average reward: -81.57294264339153\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.050000000459770676\n",
      "episode: 21459\t average reward: -83.1362248014661\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.05000000045519588\n",
      "episode: 21469\t average reward: -79.43897763578275\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.050000000450666604\n",
      "episode: 21479\t average reward: -79.16784112748239\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000000044618239\n",
      "episode: 21489\t average reward: -80.32867132867133\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.050000000441742805\n",
      "episode: 21499\t average reward: -76.52283256121774\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000043734739\n",
      "episode: 21509\t average reward: -76.22037283621837\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000043299571\n",
      "episode: 21519\t average reward: -74.7398921832884\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000042868733\n",
      "episode: 21529\t average reward: -74.02517006802721\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000042442183\n",
      "episode: 21539\t average reward: -78.8941935483871\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000420198754\n",
      "episode: 21549\t average reward: -81.71855541718556\t avg steps: 161.6\t lr: 0.0005\t epsilon: 0.05000000041601771\n",
      "episode: 21559\t average reward: -81.33\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.05000000041187826\n",
      "episode: 21569\t average reward: -78.18010403120937\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000040778001\n",
      "episode: 21579\t average reward: -77.40131578947368\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000040372253\n",
      "episode: 21589\t average reward: -78.37573004542504\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.050000000399705424\n",
      "episode: 21599\t average reward: -75.59731543624162\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.050000000395728286\n",
      "episode: 21609\t average reward: -75.68209255533199\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05000000039179072\n",
      "episode: 21619\t average reward: -76.19680851063829\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000000038789234\n",
      "episode: 21629\t average reward: -82.92980295566502\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.050000000384032746\n",
      "episode: 21639\t average reward: -80.65425867507886\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000038021156\n",
      "episode: 21649\t average reward: -79.99808917197453\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000000037642839\n",
      "episode: 21659\t average reward: -82.5730198019802\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.050000000372682867\n",
      "episode: 21669\t average reward: -75.40080160320642\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000036897461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 21679\t average reward: -80.39570164348926\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.05000000036530325\n",
      "episode: 21689\t average reward: -80.13869537682078\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000000036166842\n",
      "episode: 21699\t average reward: -79.4077855775367\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000000035806976\n",
      "episode: 21709\t average reward: -77.36499674690957\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.050000000354506906\n",
      "episode: 21719\t average reward: -74.84656796769852\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.050000000350979505\n",
      "episode: 21729\t average reward: -78.9800899165061\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.0500000003474872\n",
      "episode: 21739\t average reward: -83.86901152213463\t avg steps: 165.9\t lr: 0.0005\t epsilon: 0.05000000034402965\n",
      "episode: 21749\t average reward: -78.3638726445744\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000034060649\n",
      "episode: 21759\t average reward: -77.48041775456919\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.0500000003372174\n",
      "episode: 21769\t average reward: -76.03002001334222\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05000000033386203\n",
      "episode: 21779\t average reward: -78.35677083333333\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000000033054005\n",
      "episode: 21789\t average reward: -74.86137281292059\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.05000000032725112\n",
      "episode: 21799\t average reward: -78.45\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000032399492\n",
      "episode: 21809\t average reward: -78.68155339805826\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.050000000320771114\n",
      "episode: 21819\t average reward: -80.16433121019108\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000000031757939\n",
      "episode: 21829\t average reward: -88.24346310284719\t avg steps: 173.1\t lr: 0.0005\t epsilon: 0.050000000314419424\n",
      "episode: 21839\t average reward: -74.87886944818304\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.0500000003112909\n",
      "episode: 21849\t average reward: -79.09646302250803\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.0500000003081935\n",
      "episode: 21859\t average reward: -79.83877159309021\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000030512692\n",
      "episode: 21869\t average reward: -78.79407979407979\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000030209086\n",
      "episode: 21879\t average reward: -78.65892972275951\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.050000000299085\n",
      "episode: 21889\t average reward: -77.60130718954248\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000029610906\n",
      "episode: 21899\t average reward: -79.55597964376591\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.050000000293162726\n",
      "episode: 21909\t average reward: -80.63962264150943\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.050000000290245705\n",
      "episode: 21919\t average reward: -78.78737113402062\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000000028735772\n",
      "episode: 21929\t average reward: -75.89779559118236\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.050000000284498455\n",
      "episode: 21939\t average reward: -81.93092719352832\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.05000000028166765\n",
      "episode: 21949\t average reward: -75.91506303915062\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000027886501\n",
      "episode: 21959\t average reward: -80.21551176096631\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000000027609026\n",
      "episode: 21969\t average reward: -79.53329065300896\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.050000000273343115\n",
      "episode: 21979\t average reward: -81.94409937888199\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.050000000270623304\n",
      "episode: 21989\t average reward: -84.73646209386281\t avg steps: 167.2\t lr: 0.0005\t epsilon: 0.050000000267930556\n",
      "episode: 21999\t average reward: -78.47992227979275\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.050000000265264605\n",
      "episode: 22009\t average reward: -76.42042440318302\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.050000000262625174\n",
      "episode: 22019\t average reward: -78.9916129032258\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000260012015\n",
      "episode: 22029\t average reward: -79.42290467050543\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000025742485\n",
      "episode: 22039\t average reward: -73.98910823689585\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000025486343\n",
      "episode: 22049\t average reward: -81.28973717146432\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.050000000252327495\n",
      "episode: 22059\t average reward: -78.29495472186287\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.050000000249816795\n",
      "episode: 22069\t average reward: -75.85103540414161\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.050000000247331075\n",
      "episode: 22079\t average reward: -77.24441524310119\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000000024487009\n",
      "episode: 22089\t average reward: -78.81735751295336\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.0500000002424336\n",
      "episode: 22099\t average reward: -77.77083333333333\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000000024002134\n",
      "episode: 22109\t average reward: -81.1013853904282\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000000023763309\n",
      "episode: 22119\t average reward: -77.94993498049415\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.0500000002352686\n",
      "episode: 22129\t average reward: -82.11935683364254\t avg steps: 162.7\t lr: 0.0005\t epsilon: 0.05000000023292764\n",
      "episode: 22139\t average reward: -81.33709273182957\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000000023060997\n",
      "episode: 22149\t average reward: -76.58531746031746\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000000022831536\n",
      "episode: 22159\t average reward: -82.49287042777433\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.05000000022604358\n",
      "episode: 22169\t average reward: -77.65580182529335\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.050000000223794416\n",
      "episode: 22179\t average reward: -84.92414208308249\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.05000000022156762\n",
      "episode: 22189\t average reward: -77.88837820091923\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05000000021936299\n",
      "episode: 22199\t average reward: -85.58208955223881\t avg steps: 168.5\t lr: 0.0005\t epsilon: 0.05000000021718029\n",
      "episode: 22209\t average reward: -81.21016311166876\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000000021501931\n",
      "episode: 22219\t average reward: -75.90823844608171\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.050000000212879835\n",
      "episode: 22229\t average reward: -81.1442065491184\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000000021076164\n",
      "episode: 22239\t average reward: -77.8455497382199\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000000208664526\n",
      "episode: 22249\t average reward: -78.90979381443299\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.050000000206588284\n",
      "episode: 22259\t average reward: -77.72888015717092\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000020453269\n",
      "episode: 22269\t average reward: -77.17685733070348\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.050000000202497556\n",
      "episode: 22279\t average reward: -78.72762395363812\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.050000000200482675\n",
      "episode: 22289\t average reward: -79.97120921305182\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000019848784\n",
      "episode: 22299\t average reward: -74.04489795918367\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000019651285\n",
      "episode: 22309\t average reward: -81.49905719673161\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05000000019455752\n",
      "episode: 22319\t average reward: -74.0910944935418\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05000000019262164\n",
      "episode: 22329\t average reward: -76.65984147952445\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05000000019070502\n",
      "episode: 22339\t average reward: -74.84703504043127\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000018880747\n",
      "episode: 22349\t average reward: -80.63247325361863\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000000018692881\n",
      "episode: 22359\t average reward: -73.84788540245566\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05000000018506884\n",
      "episode: 22369\t average reward: -81.70125\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.05000000018322737\n",
      "episode: 22379\t average reward: -75.48655913978494\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05000000018140423\n",
      "episode: 22389\t average reward: -78.94774193548388\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000017959923\n",
      "episode: 22399\t average reward: -78.31384015594541\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.050000000177812184\n",
      "episode: 22409\t average reward: -73.37474262182567\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000017604292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 22419\t average reward: -82.15747055176689\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.050000000174291265\n",
      "episode: 22429\t average reward: -74.62052667116814\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000017255704\n",
      "episode: 22439\t average reward: -80.09936305732484\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000000017084007\n",
      "episode: 22449\t average reward: -76.98484848484848\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000016914018\n",
      "episode: 22459\t average reward: -83.22596448254745\t avg steps: 164.3\t lr: 0.0005\t epsilon: 0.050000000167457204\n",
      "episode: 22469\t average reward: -81.71285892634208\t avg steps: 161.2\t lr: 0.0005\t epsilon: 0.05000000016579098\n",
      "episode: 22479\t average reward: -75.34231805929919\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.050000000164141335\n",
      "episode: 22489\t average reward: -75.52101400933957\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.0500000001625081\n",
      "episode: 22499\t average reward: -76.53509933774835\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.050000000160891116\n",
      "episode: 22509\t average reward: -76.27508305647841\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000015929022\n",
      "episode: 22519\t average reward: -73.61054072553046\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05000000015770526\n",
      "episode: 22529\t average reward: -77.63209393346379\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000000156136065\n",
      "episode: 22539\t average reward: -76.29860650298606\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000015458249\n",
      "episode: 22549\t average reward: -76.18302387267904\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.050000000153044365\n",
      "episode: 22559\t average reward: -75.49731903485255\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000015152155\n",
      "episode: 22569\t average reward: -77.62565445026178\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000000015001388\n",
      "episode: 22579\t average reward: -80.48350253807106\t avg steps: 158.6\t lr: 0.0005\t epsilon: 0.05000000014852122\n",
      "episode: 22589\t average reward: -78.17987012987012\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000014704341\n",
      "episode: 22599\t average reward: -78.8033526756931\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.0500000001455803\n",
      "episode: 22609\t average reward: -75.70580386924617\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05000000014413175\n",
      "episode: 22619\t average reward: -78.65826873385014\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000000014269762\n",
      "episode: 22629\t average reward: -82.8232044198895\t avg steps: 163.9\t lr: 0.0005\t epsilon: 0.050000000141277756\n",
      "episode: 22639\t average reward: -73.44101508916324\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000013987202\n",
      "episode: 22649\t average reward: -76.58769027134348\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.050000000138480265\n",
      "episode: 22659\t average reward: -74.96148648648649\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000013710237\n",
      "episode: 22669\t average reward: -77.35036018336608\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.050000000135738173\n",
      "episode: 22679\t average reward: -75.52751677852349\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.05000000013438756\n",
      "episode: 22689\t average reward: -78.07282184655396\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000013305038\n",
      "episode: 22699\t average reward: -77.8310502283105\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000013172651\n",
      "episode: 22709\t average reward: -76.99076517150395\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.050000000130415806\n",
      "episode: 22719\t average reward: -75.74029451137885\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000000012911814\n",
      "episode: 22729\t average reward: -79.34551282051282\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.0500000001278334\n",
      "episode: 22739\t average reward: -79.85814249363868\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000012656144\n",
      "episode: 22749\t average reward: -74.45706558485463\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.050000000125302126\n",
      "episode: 22759\t average reward: -74.50642325895876\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05000000012405535\n",
      "episode: 22769\t average reward: -72.45795691452398\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05000000012282098\n",
      "episode: 22779\t average reward: -80.40315457413249\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000012159889\n",
      "episode: 22789\t average reward: -78.600129617628\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000012038896\n",
      "episode: 22799\t average reward: -78.578165374677\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000000011919107\n",
      "episode: 22809\t average reward: -73.48971193415638\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.0500000001180051\n",
      "episode: 22819\t average reward: -75.77458193979933\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000011683093\n",
      "episode: 22829\t average reward: -78.8999354422208\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000011566844\n",
      "episode: 22839\t average reward: -79.80700636942674\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000000011451752\n",
      "episode: 22849\t average reward: -73.39121482498284\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000011337805\n",
      "episode: 22859\t average reward: -75.73543201607502\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000011224992\n",
      "episode: 22869\t average reward: -75.68297587131367\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.050000000111133015\n",
      "episode: 22879\t average reward: -77.19579500657031\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.050000000110027226\n",
      "episode: 22889\t average reward: -79.34418901660281\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.050000000108932435\n",
      "episode: 22899\t average reward: -84.12750455373406\t avg steps: 165.7\t lr: 0.0005\t epsilon: 0.05000000010784854\n",
      "episode: 22909\t average reward: -75.83054253181514\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000010677543\n",
      "episode: 22919\t average reward: -87.10206489675517\t avg steps: 170.5\t lr: 0.0005\t epsilon: 0.050000000105713\n",
      "episode: 22929\t average reward: -80.61396825396825\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.05000000010466114\n",
      "episode: 22939\t average reward: -82.17372353673724\t avg steps: 161.6\t lr: 0.0005\t epsilon: 0.05000000010361974\n",
      "episode: 22949\t average reward: -78.11680726800779\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.050000000102588704\n",
      "episode: 22959\t average reward: -74.36043360433604\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000010156793\n",
      "episode: 22969\t average reward: -84.78567128236003\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.050000000100557315\n",
      "episode: 22979\t average reward: -82.37445753254805\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.050000000099556755\n",
      "episode: 22989\t average reward: -77.21353482260184\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.050000000098566144\n",
      "episode: 22999\t average reward: -83.03289882060832\t avg steps: 162.1\t lr: 0.0005\t epsilon: 0.050000000097585394\n",
      "episode: 23009\t average reward: -87.10248815165876\t avg steps: 169.8\t lr: 0.0005\t epsilon: 0.05000000009661441\n",
      "episode: 23019\t average reward: -89.18176470588236\t avg steps: 171.0\t lr: 0.0005\t epsilon: 0.05000000009565308\n",
      "episode: 23029\t average reward: -75.37967914438502\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000009470131\n",
      "episode: 23039\t average reward: -86.16956261234272\t avg steps: 167.9\t lr: 0.0005\t epsilon: 0.05000000009375902\n",
      "episode: 23049\t average reward: -75.94893899204244\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.0500000000928261\n",
      "episode: 23059\t average reward: -81.82453909726637\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000000009190247\n",
      "episode: 23069\t average reward: -74.18274456521739\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05000000009098802\n",
      "episode: 23079\t average reward: -77.22142390594382\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000009008267\n",
      "episode: 23089\t average reward: -79.79105431309904\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.050000000089186335\n",
      "episode: 23099\t average reward: -81.06813880126182\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000008829892\n",
      "episode: 23109\t average reward: -93.78476084538376\t avg steps: 180.8\t lr: 0.0005\t epsilon: 0.05000000008742033\n",
      "episode: 23119\t average reward: -82.7074074074074\t avg steps: 163.0\t lr: 0.0005\t epsilon: 0.050000000086550485\n",
      "episode: 23129\t average reward: -77.5344262295082\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000008568929\n",
      "episode: 23139\t average reward: -78.75551232166018\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000008483667\n",
      "episode: 23149\t average reward: -77.91395045632333\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000008399253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 23159\t average reward: -77.67756703727927\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000008315679\n",
      "episode: 23169\t average reward: -76.2271818787475\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05000000008232937\n",
      "episode: 23179\t average reward: -77.44094488188976\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.050000000081510176\n",
      "episode: 23189\t average reward: -78.59108527131782\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000000008069914\n",
      "episode: 23199\t average reward: -78.20544394037589\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000007989616\n",
      "episode: 23209\t average reward: -77.07293035479633\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000000007910119\n",
      "episode: 23219\t average reward: -76.58090185676393\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.050000000078314115\n",
      "episode: 23229\t average reward: -80.53324889170361\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000000007753488\n",
      "episode: 23239\t average reward: -76.99208965062624\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000007676339\n",
      "episode: 23249\t average reward: -76.05897945659378\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.050000000075999584\n",
      "episode: 23259\t average reward: -81.17476340694006\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000007524338\n",
      "episode: 23269\t average reward: -80.69352791878173\t avg steps: 158.6\t lr: 0.0005\t epsilon: 0.05000000007449469\n",
      "episode: 23279\t average reward: -75.24246483590088\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000007375346\n",
      "episode: 23289\t average reward: -91.8252262443439\t avg steps: 177.8\t lr: 0.0005\t epsilon: 0.0500000000730196\n",
      "episode: 23299\t average reward: -78.38896103896104\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000007229304\n",
      "episode: 23309\t average reward: -82.38437693738376\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.050000000071573715\n",
      "episode: 23319\t average reward: -77.69301110385369\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000007086154\n",
      "episode: 23329\t average reward: -85.72374701670644\t avg steps: 168.6\t lr: 0.0005\t epsilon: 0.05000000007015646\n",
      "episode: 23339\t average reward: -78.39507772020725\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.050000000069458386\n",
      "episode: 23349\t average reward: -84.73172205438067\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.050000000068767265\n",
      "episode: 23359\t average reward: -85.28691476590636\t avg steps: 167.6\t lr: 0.0005\t epsilon: 0.05000000006808302\n",
      "episode: 23369\t average reward: -81.14411579609818\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.050000000067405584\n",
      "episode: 23379\t average reward: -74.5277027027027\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.050000000066734884\n",
      "episode: 23389\t average reward: -81.14115432873275\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000000006607087\n",
      "episode: 23399\t average reward: -80.7168253968254\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.05000000006541345\n",
      "episode: 23409\t average reward: -77.56751467710372\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000006476257\n",
      "episode: 23419\t average reward: -79.60168393782384\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000006411817\n",
      "episode: 23429\t average reward: -87.0842865743528\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.05000000006348019\n",
      "episode: 23439\t average reward: -76.15462525320729\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000006284855\n",
      "episode: 23449\t average reward: -80.8265306122449\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.050000000062223195\n",
      "episode: 23459\t average reward: -90.54086956521739\t avg steps: 173.5\t lr: 0.0005\t epsilon: 0.050000000061604065\n",
      "episode: 23469\t average reward: -77.12013201320131\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.0500000000609911\n",
      "episode: 23479\t average reward: -72.11236749116608\t avg steps: 142.5\t lr: 0.0005\t epsilon: 0.05000000006038422\n",
      "episode: 23489\t average reward: -73.38689655172413\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000005978339\n",
      "episode: 23499\t average reward: -75.7479674796748\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000005918854\n",
      "episode: 23509\t average reward: -74.07508532423208\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.0500000000585996\n",
      "episode: 23519\t average reward: -69.77518248175183\t avg steps: 138.0\t lr: 0.0005\t epsilon: 0.050000000058016525\n",
      "episode: 23529\t average reward: -75.55933333333333\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000000005743925\n",
      "episode: 23539\t average reward: -73.53241379310344\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000005686772\n",
      "episode: 23549\t average reward: -74.74016282225237\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.050000000056301876\n",
      "episode: 23559\t average reward: -73.00695894224079\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.050000000055741664\n",
      "episode: 23569\t average reward: -70.34782608695652\t avg steps: 139.0\t lr: 0.0005\t epsilon: 0.050000000055187024\n",
      "episode: 23579\t average reward: -79.01249178172255\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000000005463791\n",
      "episode: 23589\t average reward: -75.25167785234899\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.050000000054094246\n",
      "episode: 23599\t average reward: -76.23280423280423\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000000053556\n",
      "episode: 23609\t average reward: -73.95075239398085\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.05000000005302311\n",
      "episode: 23619\t average reward: -75.554\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.050000000052495525\n",
      "episode: 23629\t average reward: -69.26288659793815\t avg steps: 136.8\t lr: 0.0005\t epsilon: 0.050000000051973185\n",
      "episode: 23639\t average reward: -74.36881355932204\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.050000000051456044\n",
      "episode: 23649\t average reward: -77.29258517034069\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000005094404\n",
      "episode: 23659\t average reward: -73.35492763611303\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05000000005043714\n",
      "episode: 23669\t average reward: -73.63717421124828\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000004993529\n",
      "episode: 23679\t average reward: -74.16427104722793\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05000000004943842\n",
      "episode: 23689\t average reward: -73.84784098697739\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.0500000000489465\n",
      "episode: 23699\t average reward: -73.68634179821551\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.050000000048459475\n",
      "episode: 23709\t average reward: -73.58795013850416\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.0500000000479773\n",
      "episode: 23719\t average reward: -72.89972144846797\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05000000004749991\n",
      "episode: 23729\t average reward: -72.85434173669468\t avg steps: 143.8\t lr: 0.0005\t epsilon: 0.05000000004702728\n",
      "episode: 23739\t average reward: -72.47963483146067\t avg steps: 143.4\t lr: 0.0005\t epsilon: 0.05000000004655935\n",
      "episode: 23749\t average reward: -74.87635869565217\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05000000004609608\n",
      "episode: 23759\t average reward: -74.13010899182561\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000000004563741\n",
      "episode: 23769\t average reward: -75.45351170568561\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000004518332\n",
      "episode: 23779\t average reward: -74.97668038408779\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000004473373\n",
      "episode: 23789\t average reward: -75.44722598105548\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.050000000044288624\n",
      "episode: 23799\t average reward: -78.87772637144745\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000000004384795\n",
      "episode: 23809\t average reward: -75.68779501011463\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000000004341165\n",
      "episode: 23819\t average reward: -73.98621640248105\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.0500000000429797\n",
      "episode: 23829\t average reward: -73.17325017325017\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05000000004255204\n",
      "episode: 23839\t average reward: -79.01477199743096\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.050000000042128644\n",
      "episode: 23849\t average reward: -77.38775510204081\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05000000004170946\n",
      "episode: 23859\t average reward: -79.52729608220938\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000004129444\n",
      "episode: 23869\t average reward: -74.19154737559646\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.050000000040883556\n",
      "episode: 23879\t average reward: -82.34927627438641\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000000004047676\n",
      "episode: 23889\t average reward: -70.78145219266715\t avg steps: 140.1\t lr: 0.0005\t epsilon: 0.050000000040074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 23899\t average reward: -72.66876310272536\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.050000000039675266\n",
      "episode: 23909\t average reward: -76.77938279711097\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000000039280484\n",
      "episode: 23919\t average reward: -74.39659863945579\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000003888964\n",
      "episode: 23929\t average reward: -74.58136394328157\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000003850268\n",
      "episode: 23939\t average reward: -74.73584905660377\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000003811957\n",
      "episode: 23949\t average reward: -70.45039826212889\t avg steps: 139.1\t lr: 0.0005\t epsilon: 0.05000000003774028\n",
      "episode: 23959\t average reward: -75.09919028340082\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05000000003736475\n",
      "episode: 23969\t average reward: -75.68662674650699\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000003699297\n",
      "episode: 23979\t average reward: -71.7412935323383\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.050000000036624886\n",
      "episode: 23989\t average reward: -75.39679358717434\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000003626046\n",
      "episode: 23999\t average reward: -74.27501701837986\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000003589966\n",
      "episode: 24009\t average reward: -75.66065464261857\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.050000000035542454\n",
      "episode: 24019\t average reward: -76.79803278688524\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.0500000000351888\n",
      "episode: 24029\t average reward: -75.65510340226818\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05000000003483867\n",
      "episode: 24039\t average reward: -81.30377358490566\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.050000000034492016\n",
      "episode: 24049\t average reward: -74.48632010943912\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.05000000003414882\n",
      "episode: 24059\t average reward: -75.27421555252387\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05000000003380903\n",
      "episode: 24069\t average reward: -76.3156146179402\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000003347262\n",
      "episode: 24079\t average reward: -74.71070460704607\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000003313956\n",
      "episode: 24089\t average reward: -73.00208768267224\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05000000003280982\n",
      "episode: 24099\t average reward: -74.72708894878706\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000003248336\n",
      "episode: 24109\t average reward: -79.93885350318472\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.050000000032160145\n",
      "episode: 24119\t average reward: -69.43340691685063\t avg steps: 136.9\t lr: 0.0005\t epsilon: 0.050000000031840144\n",
      "episode: 24129\t average reward: -74.61690524880709\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.05000000003152333\n",
      "episode: 24139\t average reward: -75.96969696969697\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05000000003120967\n",
      "episode: 24149\t average reward: -75.17895442359249\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.050000000030899126\n",
      "episode: 24159\t average reward: -73.26749826749827\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05000000003059168\n",
      "episode: 24169\t average reward: -72.92077831827658\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05000000003028728\n",
      "episode: 24179\t average reward: -72.98886569241475\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05000000002998592\n",
      "episode: 24189\t average reward: -77.7586898395722\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.050000000029687554\n",
      "episode: 24199\t average reward: -73.2324774462179\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.05000000002939216\n",
      "episode: 24209\t average reward: -78.33616742969261\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.050000000029099705\n",
      "episode: 24219\t average reward: -70.56443484521239\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05000000002881015\n",
      "episode: 24229\t average reward: -72.15298245614035\t avg steps: 143.5\t lr: 0.0005\t epsilon: 0.05000000002852349\n",
      "episode: 24239\t average reward: -78.2168284789644\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000002823968\n",
      "episode: 24249\t average reward: -73.26629680998613\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05000000002795869\n",
      "episode: 24259\t average reward: -73.47832071576049\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000002768049\n",
      "episode: 24269\t average reward: -75.79069767441861\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000002740507\n",
      "episode: 24279\t average reward: -75.74064171122994\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000002713238\n",
      "episode: 24289\t average reward: -75.25218560860793\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000000002686241\n",
      "episode: 24299\t average reward: -74.20887372013652\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.050000000026595125\n",
      "episode: 24309\t average reward: -71.83475177304965\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.050000000026330496\n",
      "episode: 24319\t average reward: -75.51608579088472\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.050000000026068504\n",
      "episode: 24329\t average reward: -70.72825305535586\t avg steps: 140.1\t lr: 0.0005\t epsilon: 0.05000000002580912\n",
      "episode: 24339\t average reward: -74.9972954699121\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05000000002555231\n",
      "episode: 24349\t average reward: -71.67638691322902\t avg steps: 141.6\t lr: 0.0005\t epsilon: 0.050000000025298065\n",
      "episode: 24359\t average reward: -71.96262341325811\t avg steps: 142.8\t lr: 0.0005\t epsilon: 0.05000000002504634\n",
      "episode: 24369\t average reward: -69.23105224429727\t avg steps: 136.9\t lr: 0.0005\t epsilon: 0.05000000002479713\n",
      "episode: 24379\t average reward: -75.81365187713311\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.05000000002455039\n",
      "episode: 24389\t average reward: -70.80846484935438\t avg steps: 140.4\t lr: 0.0005\t epsilon: 0.050000000024306115\n",
      "episode: 24399\t average reward: -71.05436337625179\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05000000002406427\n",
      "episode: 24409\t average reward: -70.01454545454546\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.05000000002382482\n",
      "episode: 24419\t average reward: -75.6358189081225\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000002358776\n",
      "episode: 24429\t average reward: -77.0372792674951\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000002335306\n",
      "episode: 24439\t average reward: -67.74171686746988\t avg steps: 133.8\t lr: 0.0005\t epsilon: 0.05000000002312069\n",
      "episode: 24449\t average reward: -77.19647519582246\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000002289064\n",
      "episode: 24459\t average reward: -74.39414567733152\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.050000000022662874\n",
      "episode: 24469\t average reward: -68.01953418482344\t avg steps: 134.1\t lr: 0.0005\t epsilon: 0.050000000022437374\n",
      "episode: 24479\t average reward: -75.6859614105123\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.050000000022214115\n",
      "episode: 24489\t average reward: -73.51444291609353\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.050000000021993084\n",
      "episode: 24499\t average reward: -74.84121621621621\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.050000000021774245\n",
      "episode: 24509\t average reward: -73.20124481327801\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000002155759\n",
      "episode: 24519\t average reward: -74.16871584699453\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000002134309\n",
      "episode: 24529\t average reward: -76.61948650427914\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05000000002113072\n",
      "episode: 24539\t average reward: -75.37767379679144\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000002092047\n",
      "episode: 24549\t average reward: -73.10701876302988\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.0500000000207123\n",
      "episode: 24559\t average reward: -70.06618181818182\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.05000000002050621\n",
      "episode: 24569\t average reward: -74.0580997949419\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000002030217\n",
      "episode: 24579\t average reward: -73.61894882434302\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000002010016\n",
      "episode: 24589\t average reward: -71.2310443490701\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05000000001990016\n",
      "episode: 24599\t average reward: -75.21835231078366\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000001970215\n",
      "episode: 24609\t average reward: -71.31281317108089\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.050000000019506115\n",
      "episode: 24619\t average reward: -73.60564349621473\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000001931203\n",
      "episode: 24629\t average reward: -72.37719915552428\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05000000001911987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 24639\t average reward: -73.3487250172295\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.050000000018929625\n",
      "episode: 24649\t average reward: -77.08240680183127\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000001874127\n",
      "episode: 24659\t average reward: -74.27297481279783\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000001855479\n",
      "episode: 24669\t average reward: -70.29884225759768\t avg steps: 139.2\t lr: 0.0005\t epsilon: 0.05000000001837017\n",
      "episode: 24679\t average reward: -72.97007654836464\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05000000001818738\n",
      "episode: 24689\t average reward: -74.57567567567567\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000001800641\n",
      "episode: 24699\t average reward: -70.3367198838897\t avg steps: 138.8\t lr: 0.0005\t epsilon: 0.05000000001782725\n",
      "episode: 24709\t average reward: -73.15475364330327\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.050000000017649864\n",
      "episode: 24719\t average reward: -75.6711051930759\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000001747424\n",
      "episode: 24729\t average reward: -78.34725848563968\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000001730037\n",
      "episode: 24739\t average reward: -73.97330595482546\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05000000001712823\n",
      "episode: 24749\t average reward: -72.0113475177305\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.0500000000169578\n",
      "episode: 24759\t average reward: -70.59781818181818\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.050000000016789066\n",
      "episode: 24769\t average reward: -71.97517730496453\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05000000001662201\n",
      "episode: 24779\t average reward: -70.632\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.050000000016456624\n",
      "episode: 24789\t average reward: -72.92995839112344\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05000000001629288\n",
      "episode: 24799\t average reward: -75.26280323450135\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000001613076\n",
      "episode: 24809\t average reward: -72.86968641114983\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.050000000015970256\n",
      "episode: 24819\t average reward: -73.50722642807983\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000001581135\n",
      "episode: 24829\t average reward: -75.33674863387978\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000001565402\n",
      "episode: 24839\t average reward: -72.58790436005626\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.050000000015498265\n",
      "episode: 24849\t average reward: -72.60251924422673\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.050000000015344055\n",
      "episode: 24859\t average reward: -73.84636488340192\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000001519138\n",
      "episode: 24869\t average reward: -74.84485094850949\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000001504022\n",
      "episode: 24879\t average reward: -74.3784887678693\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000001489057\n",
      "episode: 24889\t average reward: -74.25857338820302\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.050000000014742405\n",
      "episode: 24899\t average reward: -74.3251700680272\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.050000000014595716\n",
      "episode: 24909\t average reward: -69.69619326500732\t avg steps: 137.6\t lr: 0.0005\t epsilon: 0.050000000014450485\n",
      "episode: 24919\t average reward: -70.8771551724138\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.0500000000143067\n",
      "episode: 24929\t average reward: -68.10936329588014\t avg steps: 134.5\t lr: 0.0005\t epsilon: 0.050000000014164346\n",
      "episode: 24939\t average reward: -73.49517906336088\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05000000001402341\n",
      "episode: 24949\t average reward: -69.38116261957322\t avg steps: 136.9\t lr: 0.0005\t epsilon: 0.050000000013883876\n",
      "episode: 24959\t average reward: -72.2258972554539\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05000000001374573\n",
      "episode: 24969\t average reward: -73.88356164383562\t avg steps: 147.0\t lr: 0.0005\t epsilon: 0.05000000001360896\n",
      "episode: 24979\t average reward: -73.78958190541466\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.050000000013473545\n",
      "episode: 24989\t average reward: -73.0118549511855\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.05000000001333948\n",
      "episode: 24999\t average reward: -69.78796771826852\t avg steps: 137.3\t lr: 0.0005\t epsilon: 0.05000000001320675\n",
      "episode: 25009\t average reward: -75.69271877087509\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000001307534\n",
      "episode: 25019\t average reward: -72.86144156752974\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.05000000001294524\n",
      "episode: 25029\t average reward: -74.23858214042264\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.05000000001281643\n",
      "episode: 25039\t average reward: -70.62156295224312\t avg steps: 139.2\t lr: 0.0005\t epsilon: 0.05000000001268891\n",
      "episode: 25049\t average reward: -73.28978457261988\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05000000001256265\n",
      "episode: 25059\t average reward: -70.40406976744185\t avg steps: 138.6\t lr: 0.0005\t epsilon: 0.05000000001243765\n",
      "episode: 25069\t average reward: -71.50499286733238\t avg steps: 141.2\t lr: 0.0005\t epsilon: 0.05000000001231389\n",
      "episode: 25079\t average reward: -72.84497206703911\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05000000001219137\n",
      "episode: 25089\t average reward: -75.57238605898124\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000001207006\n",
      "episode: 25099\t average reward: -73.35886818495514\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.050000000011949965\n",
      "episode: 25109\t average reward: -74.34673024523161\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000000001183106\n",
      "episode: 25119\t average reward: -74.2425068119891\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.050000000011713334\n",
      "episode: 25129\t average reward: -75.14959568733154\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000001159679\n",
      "episode: 25139\t average reward: -74.99529885829416\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.050000000011481395\n",
      "episode: 25149\t average reward: -75.87790311877903\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000001136715\n",
      "episode: 25159\t average reward: -70.11062590975254\t avg steps: 138.4\t lr: 0.0005\t epsilon: 0.05000000001125405\n",
      "episode: 25169\t average reward: -73.805918788713\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000001114207\n",
      "episode: 25179\t average reward: -72.58811188811188\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.050000000011031207\n",
      "episode: 25189\t average reward: -68.94600591715977\t avg steps: 136.2\t lr: 0.0005\t epsilon: 0.05000000001092144\n",
      "episode: 25199\t average reward: -72.56399437412095\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05000000001081277\n",
      "episode: 25209\t average reward: -72.74283717679944\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.05000000001070518\n",
      "episode: 25219\t average reward: -70.76906474820144\t avg steps: 140.0\t lr: 0.0005\t epsilon: 0.050000000010598664\n",
      "episode: 25229\t average reward: -73.2848275862069\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.050000000010493206\n",
      "episode: 25239\t average reward: -74.64949152542373\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.0500000000103888\n",
      "episode: 25249\t average reward: -77.28851174934726\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000001028543\n",
      "episode: 25259\t average reward: -79.06206014075495\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.050000000010183086\n",
      "episode: 25269\t average reward: -75.48664886515354\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.050000000010081765\n",
      "episode: 25279\t average reward: -77.32985658409387\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000000998145\n",
      "episode: 25289\t average reward: -76.5956607495069\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000000000988213\n",
      "episode: 25299\t average reward: -76.02715231788079\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.0500000000097838\n",
      "episode: 25309\t average reward: -76.07350993377483\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000000000968645\n",
      "episode: 25319\t average reward: -75.81461794019934\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000959007\n",
      "episode: 25329\t average reward: -74.93077956989248\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.050000000009494644\n",
      "episode: 25339\t average reward: -75.97084161696488\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000000000940017\n",
      "episode: 25349\t average reward: -75.40881763527054\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000000930664\n",
      "episode: 25359\t average reward: -75.65246338215712\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.050000000009214035\n",
      "episode: 25369\t average reward: -74.93951612903226\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05000000000912236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 25379\t average reward: -75.92572944297082\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.050000000009031584\n",
      "episode: 25389\t average reward: -75.56495669553631\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05000000000894172\n",
      "episode: 25399\t average reward: -75.42256341789052\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.05000000000885275\n",
      "episode: 25409\t average reward: -76.44993412384717\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.050000000008764665\n",
      "episode: 25419\t average reward: -75.4188376753507\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000000867745\n",
      "episode: 25429\t average reward: -74.5195945945946\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000859111\n",
      "episode: 25439\t average reward: -74.96908602150538\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05000000000850563\n",
      "episode: 25449\t average reward: -74.81897711978466\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.050000000008420996\n",
      "episode: 25459\t average reward: -76.40804218852999\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000833721\n",
      "episode: 25469\t average reward: -75.7125748502994\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000825425\n",
      "episode: 25479\t average reward: -75.58133333333333\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000000000817212\n",
      "episode: 25489\t average reward: -75.13471849865952\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.0500000000080908\n",
      "episode: 25499\t average reward: -75.5742838107928\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.0500000000080103\n",
      "episode: 25509\t average reward: -74.83781965006729\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.050000000007930596\n",
      "episode: 25519\t average reward: -74.46991210277214\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05000000000785169\n",
      "episode: 25529\t average reward: -75.28963210702341\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000000777356\n",
      "episode: 25539\t average reward: -74.97716588314304\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.050000000007696214\n",
      "episode: 25549\t average reward: -76.27524752475247\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000761963\n",
      "episode: 25559\t average reward: -74.22184531886025\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.050000000007543816\n",
      "episode: 25569\t average reward: -74.02993197278911\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000746875\n",
      "episode: 25579\t average reward: -77.22896281800391\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000000739444\n",
      "episode: 25589\t average reward: -76.07147584381204\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000732086\n",
      "episode: 25599\t average reward: -74.41096817874069\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.05000000000724802\n",
      "episode: 25609\t average reward: -75.61758827448368\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.0500000000071759\n",
      "episode: 25619\t average reward: -74.71746459878625\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.0500000000071045\n",
      "episode: 25629\t average reward: -75.0073875083949\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.05000000000703381\n",
      "episode: 25639\t average reward: -75.81606905710491\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05000000000696382\n",
      "episode: 25649\t average reward: -75.26706827309236\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000000000689453\n",
      "episode: 25659\t average reward: -76.17460317460318\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000000006825925\n",
      "episode: 25669\t average reward: -76.89259986902422\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000675801\n",
      "episode: 25679\t average reward: -76.33267326732673\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000669076\n",
      "episode: 25689\t average reward: -76.44363876071193\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000662419\n",
      "episode: 25699\t average reward: -77.2470664928292\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000000655828\n",
      "episode: 25709\t average reward: -77.15274151436032\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000006493024\n",
      "episode: 25719\t average reward: -77.36263020833333\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050000000006428416\n",
      "episode: 25729\t average reward: -80.92650753768844\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.05000000000636445\n",
      "episode: 25739\t average reward: -76.44795783926219\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000630112\n",
      "episode: 25749\t average reward: -75.83864541832669\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05000000000623843\n",
      "episode: 25759\t average reward: -77.04771241830065\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.050000000006176354\n",
      "episode: 25769\t average reward: -78.13079896907216\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.050000000006114896\n",
      "episode: 25779\t average reward: -77.78044041450777\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.050000000006054056\n",
      "episode: 25789\t average reward: -79.59171974522293\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000000000599382\n",
      "episode: 25799\t average reward: -76.50592885375494\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000593418\n",
      "episode: 25809\t average reward: -77.330078125\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000000000587513\n",
      "episode: 25819\t average reward: -76.78754098360656\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000000581667\n",
      "episode: 25829\t average reward: -78.42517662170842\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000000575879\n",
      "episode: 25839\t average reward: -76.44202898550725\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.0500000000057015\n",
      "episode: 25849\t average reward: -77.38451528952505\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.050000000005644765\n",
      "episode: 25859\t average reward: -76.2950495049505\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000000005588595\n",
      "episode: 25869\t average reward: -77.6268656716418\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05000000000553299\n",
      "episode: 25879\t average reward: -78.90299936183791\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000000000547793\n",
      "episode: 25889\t average reward: -78.47530468248877\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000000542343\n",
      "episode: 25899\t average reward: -77.95739186571981\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.050000000005369465\n",
      "episode: 25909\t average reward: -77.90368455074338\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.050000000005316035\n",
      "episode: 25919\t average reward: -77.35026041666667\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05000000000526314\n",
      "episode: 25929\t average reward: -78.27413127413128\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000000521077\n",
      "episode: 25939\t average reward: -78.32840616966581\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.050000000005158925\n",
      "episode: 25949\t average reward: -77.13446475195822\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000000510759\n",
      "episode: 25959\t average reward: -78.28295819935691\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000505677\n",
      "episode: 25969\t average reward: -78.79872204472844\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.050000000005006456\n",
      "episode: 25979\t average reward: -78.00064557779213\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000000495664\n",
      "episode: 25989\t average reward: -78.01420271142673\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000000490732\n",
      "episode: 25999\t average reward: -76.39156229400132\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000485849\n",
      "episode: 26009\t average reward: -76.37640079103494\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000481015\n",
      "episode: 26019\t average reward: -77.40468445022772\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000476229\n",
      "episode: 26029\t average reward: -76.63140604467806\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.050000000004714905\n",
      "episode: 26039\t average reward: -76.88867059593976\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000466799\n",
      "episode: 26049\t average reward: -76.04569536423841\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000000000462154\n",
      "episode: 26059\t average reward: -77.15665796344648\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000000457556\n",
      "episode: 26069\t average reward: -78.07225806451613\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000453003\n",
      "episode: 26079\t average reward: -76.55328947368422\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000000448496\n",
      "episode: 26089\t average reward: -76.6736703873933\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000000004440326\n",
      "episode: 26099\t average reward: -77.24380704041721\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.050000000004396146\n",
      "episode: 26109\t average reward: -76.56870479947403\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.0500000000043524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 26119\t average reward: -77.16960208741031\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.0500000000043091\n",
      "episode: 26129\t average reward: -76.44927536231884\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000426622\n",
      "episode: 26139\t average reward: -77.15851272015655\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000000422377\n",
      "episode: 26149\t average reward: -77.63683527885863\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000418174\n",
      "episode: 26159\t average reward: -76.92277486910994\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000000004140135\n",
      "episode: 26169\t average reward: -76.7769028871391\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000000000409894\n",
      "episode: 26179\t average reward: -76.6585686145765\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05000000000405815\n",
      "episode: 26189\t average reward: -77.17416829745596\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000000004017775\n",
      "episode: 26199\t average reward: -77.72344559585493\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.0500000000039778\n",
      "episode: 26209\t average reward: -77.04509803921569\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000393822\n",
      "episode: 26219\t average reward: -77.79935275080906\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000000389903\n",
      "episode: 26229\t average reward: -76.49374588545095\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.050000000003860234\n",
      "episode: 26239\t average reward: -76.17977528089888\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000000000382183\n",
      "episode: 26249\t average reward: -77.28273615635179\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.0500000000037838\n",
      "episode: 26259\t average reward: -77.19895629484671\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000000374615\n",
      "episode: 26269\t average reward: -77.64396887159533\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.050000000003708876\n",
      "episode: 26279\t average reward: -76.8224115334207\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05000000000367197\n",
      "episode: 26289\t average reward: -77.10777269758329\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.050000000003635435\n",
      "episode: 26299\t average reward: -76.54671052631579\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000000359926\n",
      "episode: 26309\t average reward: -76.56015779092702\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000000000356345\n",
      "episode: 26319\t average reward: -77.49577647823261\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000352799\n",
      "episode: 26329\t average reward: -78.0516129032258\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000349289\n",
      "episode: 26339\t average reward: -77.83247089262613\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000000345813\n",
      "episode: 26349\t average reward: -77.03790849673203\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000342372\n",
      "episode: 26359\t average reward: -76.98430346631785\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000000338966\n",
      "episode: 26369\t average reward: -76.57790927021696\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000000000335593\n",
      "episode: 26379\t average reward: -77.61802853437095\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000332254\n",
      "episode: 26389\t average reward: -77.83948220064725\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.050000000003289476\n",
      "episode: 26399\t average reward: -77.53181818181818\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.050000000003256745\n",
      "episode: 26409\t average reward: -77.2509778357236\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000000322434\n",
      "episode: 26419\t average reward: -77.74400518470512\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000000319226\n",
      "episode: 26429\t average reward: -77.37280416395576\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.050000000003160495\n",
      "episode: 26439\t average reward: -76.94895287958116\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000000000312905\n",
      "episode: 26449\t average reward: -78.1159793814433\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.050000000003097914\n",
      "episode: 26459\t average reward: -77.4518855656697\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000000306709\n",
      "episode: 26469\t average reward: -78.13152804642166\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.050000000003036574\n",
      "episode: 26479\t average reward: -77.87007110536523\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.050000000003006355\n",
      "episode: 26489\t average reward: -76.87164374590701\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000297644\n",
      "episode: 26499\t average reward: -78.02002583979328\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.050000000002946826\n",
      "episode: 26509\t average reward: -77.13968668407311\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.0500000000029175\n",
      "episode: 26519\t average reward: -77.61518494484102\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05000000000288848\n",
      "episode: 26529\t average reward: -78.50160359204618\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.050000000002859736\n",
      "episode: 26539\t average reward: -77.27314211212516\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000000283128\n",
      "episode: 26549\t average reward: -77.15208877284596\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000000280311\n",
      "episode: 26559\t average reward: -78.40783558124599\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000000277521\n",
      "episode: 26569\t average reward: -78.17514488087572\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.050000000002747604\n",
      "episode: 26579\t average reward: -77.6138870863076\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.050000000002720264\n",
      "episode: 26589\t average reward: -76.77311475409836\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.050000000002693196\n",
      "episode: 26599\t average reward: -77.07576747224037\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.0500000000026664\n",
      "episode: 26609\t average reward: -78.14046391752578\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000000000263987\n",
      "episode: 26619\t average reward: -76.04238410596027\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.0500000000026136\n",
      "episode: 26629\t average reward: -78.35411311053984\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000000000258759\n",
      "episode: 26639\t average reward: -78.05548387096775\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000256185\n",
      "episode: 26649\t average reward: -78.08575112830432\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.050000000002536356\n",
      "episode: 26659\t average reward: -78.9074664964901\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000000000251112\n",
      "episode: 26669\t average reward: -77.37931034482759\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000248613\n",
      "episode: 26679\t average reward: -78.03096774193548\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000002461395\n",
      "episode: 26689\t average reward: -77.44603381014305\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000000243691\n",
      "episode: 26699\t average reward: -77.13577023498695\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000002412656\n",
      "episode: 26709\t average reward: -77.97094899935442\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.050000000002388655\n",
      "episode: 26719\t average reward: -78.55576923076923\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05000000000236488\n",
      "episode: 26729\t average reward: -77.4977257959714\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000234135\n",
      "episode: 26739\t average reward: -77.09405617243631\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000231806\n",
      "episode: 26749\t average reward: -77.16438356164383\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000000229499\n",
      "episode: 26759\t average reward: -78.4415917843389\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000000227216\n",
      "episode: 26769\t average reward: -78.6427656850192\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000000000224955\n",
      "episode: 26779\t average reward: -77.39947950553025\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.050000000002227166\n",
      "episode: 26789\t average reward: -76.93390052356021\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000000002205\n",
      "episode: 26799\t average reward: -78.21184803605924\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000000000218306\n",
      "episode: 26809\t average reward: -77.40208197787898\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000216134\n",
      "episode: 26819\t average reward: -77.14033942558747\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000000213983\n",
      "episode: 26829\t average reward: -77.24461839530332\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000000002118544\n",
      "episode: 26839\t average reward: -77.03529411764706\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.050000000002097464\n",
      "episode: 26849\t average reward: -77.88551099611902\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000000207659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 26859\t average reward: -79.06815286624204\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.050000000002055935\n",
      "episode: 26869\t average reward: -78.45926876202694\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000000203547\n",
      "episode: 26879\t average reward: -77.11618798955614\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000002015224\n",
      "episode: 26889\t average reward: -78.67946257197697\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000000199517\n",
      "episode: 26899\t average reward: -77.7279792746114\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000197532\n",
      "episode: 26909\t average reward: -78.42618741976894\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000000195566\n",
      "episode: 26919\t average reward: -78.02646868947708\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.050000000001936204\n",
      "episode: 26929\t average reward: -78.42554557124518\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000000191694\n",
      "episode: 26939\t average reward: -77.88041370394312\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000000000189787\n",
      "episode: 26949\t average reward: -77.10842586544742\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000187898\n",
      "episode: 26959\t average reward: -77.70576798444588\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.050000000001860286\n",
      "episode: 26969\t average reward: -77.82406209573092\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000000184177\n",
      "episode: 26979\t average reward: -78.26688102893891\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000182345\n",
      "episode: 26989\t average reward: -78.3258354755784\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.0500000000018053\n",
      "episode: 26999\t average reward: -78.8492975734355\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.050000000001787344\n",
      "episode: 27009\t average reward: -77.78187702265372\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000000176956\n",
      "episode: 27019\t average reward: -77.06013071895426\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000175195\n",
      "episode: 27029\t average reward: -78.07161290322581\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000173452\n",
      "episode: 27039\t average reward: -77.6750972762646\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000171726\n",
      "episode: 27049\t average reward: -77.08948399738733\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000170017\n",
      "episode: 27059\t average reward: -78.37251123956327\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.050000000001683254\n",
      "episode: 27069\t average reward: -77.32052117263844\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.0500000000016665\n",
      "episode: 27079\t average reward: -77.2671009771987\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.050000000001649926\n",
      "episode: 27089\t average reward: -76.61735700197238\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000000000163351\n",
      "episode: 27099\t average reward: -77.69928710304602\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000000161725\n",
      "episode: 27109\t average reward: -79.1558524173028\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000000160116\n",
      "episode: 27119\t average reward: -77.01765860039241\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000000158523\n",
      "episode: 27129\t average reward: -78.5157152020526\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.050000000001569456\n",
      "episode: 27139\t average reward: -78.30610932475884\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000155384\n",
      "episode: 27149\t average reward: -78.56153846153846\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.050000000001538376\n",
      "episode: 27159\t average reward: -78.25482625482626\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000000152307\n",
      "episode: 27169\t average reward: -76.92342931937172\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000000001507915\n",
      "episode: 27179\t average reward: -77.05228758169935\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000149291\n",
      "episode: 27189\t average reward: -78.1514175257732\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000000000147806\n",
      "episode: 27199\t average reward: -77.1097322011757\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000146335\n",
      "episode: 27209\t average reward: -77.53441558441558\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000000144879\n",
      "episode: 27219\t average reward: -78.4204107830552\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.050000000001434376\n",
      "episode: 27229\t average reward: -77.82664941785252\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.0500000000014201\n",
      "episode: 27239\t average reward: -77.8719275549806\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.050000000001405975\n",
      "episode: 27249\t average reward: -77.42847854356307\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.050000000001391987\n",
      "episode: 27259\t average reward: -78.32475884244373\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.050000000001378136\n",
      "episode: 27269\t average reward: -78.97385204081633\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000000000136442\n",
      "episode: 27279\t average reward: -77.13446475195822\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000001350846\n",
      "episode: 27289\t average reward: -78.01484828921885\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.050000000001337405\n",
      "episode: 27299\t average reward: -77.96578437701743\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.050000000001324096\n",
      "episode: 27309\t average reward: -76.41238471673255\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000131092\n",
      "episode: 27319\t average reward: -77.67595593000648\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.050000000001297874\n",
      "episode: 27329\t average reward: -77.84346701164294\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000000128496\n",
      "episode: 27339\t average reward: -76.87557301899149\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000127218\n",
      "episode: 27349\t average reward: -79.01464968152867\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.050000000001259516\n",
      "episode: 27359\t average reward: -77.77799352750809\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.050000000001246984\n",
      "episode: 27369\t average reward: -79.17823042647994\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05000000000123458\n",
      "episode: 27379\t average reward: -76.39353988134476\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.050000000001222296\n",
      "episode: 27389\t average reward: -78.18866709594333\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000000000121013\n",
      "episode: 27399\t average reward: -78.9010848755584\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000000000119809\n",
      "episode: 27409\t average reward: -77.44668400520156\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000000118617\n",
      "episode: 27419\t average reward: -78.83397190293742\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000000000117437\n",
      "episode: 27429\t average reward: -77.17025440313111\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000000001162684\n",
      "episode: 27439\t average reward: -77.74093264248705\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000115112\n",
      "episode: 27449\t average reward: -77.56493506493507\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000000113966\n",
      "episode: 27459\t average reward: -78.27670527670527\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000000112832\n",
      "episode: 27469\t average reward: -77.52857142857142\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.050000000001117095\n",
      "episode: 27479\t average reward: -77.7208549222798\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000110598\n",
      "episode: 27489\t average reward: -78.60794362588085\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.050000000001094974\n",
      "episode: 27499\t average reward: -77.47108512020793\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000108408\n",
      "episode: 27509\t average reward: -77.87904269081501\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000000107329\n",
      "episode: 27519\t average reward: -78.74168797953965\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05000000000106261\n",
      "episode: 27529\t average reward: -77.26353555120679\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.050000000001052036\n",
      "episode: 27539\t average reward: -77.65304798962387\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000104157\n",
      "episode: 27549\t average reward: -78.1417525773196\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.050000000001031206\n",
      "episode: 27559\t average reward: -77.97805035506778\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000000102095\n",
      "episode: 27569\t average reward: -77.1286740692358\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000101079\n",
      "episode: 27579\t average reward: -78.04709677419355\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000100073\n",
      "episode: 27589\t average reward: -78.30546623794213\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000099077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 27599\t average reward: -79.02421924792861\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000000000098091\n",
      "episode: 27609\t average reward: -77.63748378728924\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.050000000000971156\n",
      "episode: 27619\t average reward: -76.9109364767518\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000096149\n",
      "episode: 27629\t average reward: -77.52207792207793\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000000095192\n",
      "episode: 27639\t average reward: -77.081045751634\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000094245\n",
      "episode: 27649\t average reward: -78.24517374517374\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.050000000000933076\n",
      "episode: 27659\t average reward: -77.63748378728924\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000092379\n",
      "episode: 27669\t average reward: -78.03806451612903\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.0500000000009146\n",
      "episode: 27679\t average reward: -77.45578673602081\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.0500000000009055\n",
      "episode: 27689\t average reward: -77.95930232558139\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000000000089649\n",
      "episode: 27699\t average reward: -79.12285168682368\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05000000000088757\n",
      "episode: 27709\t average reward: -78.49134060295061\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000000087874\n",
      "episode: 27719\t average reward: -78.07161290322581\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000000869994\n",
      "episode: 27729\t average reward: -78.87300574345883\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.050000000000861335\n",
      "episode: 27739\t average reward: -78.20927237604636\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.050000000000852765\n",
      "episode: 27749\t average reward: -78.80447284345048\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000000000084428\n",
      "episode: 27759\t average reward: -78.97514340344168\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000000000083588\n",
      "episode: 27769\t average reward: -78.31362467866325\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000000000082756\n",
      "episode: 27779\t average reward: -78.38214515093128\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000000081933\n",
      "episode: 27789\t average reward: -78.09993552546744\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05000000000081118\n",
      "episode: 27799\t average reward: -76.71522309711285\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.0500000000008031\n",
      "episode: 27809\t average reward: -77.63229571984436\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000079512\n",
      "episode: 27819\t average reward: -77.37410540013012\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.050000000000787206\n",
      "episode: 27829\t average reward: -78.8690932311622\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000000000077937\n",
      "episode: 27839\t average reward: -77.9043309631545\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.050000000000771615\n",
      "episode: 27849\t average reward: -77.84864165588615\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000000076394\n",
      "episode: 27859\t average reward: -77.76683937823834\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.050000000000756335\n",
      "episode: 27869\t average reward: -75.83001328021248\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.050000000000748814\n",
      "episode: 27879\t average reward: -77.31205211726385\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05000000000074136\n",
      "episode: 27889\t average reward: -78.02516129032259\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000000733985\n",
      "episode: 27899\t average reward: -78.49839640795382\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000000072668\n",
      "episode: 27909\t average reward: -78.81800766283524\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000000000071945\n",
      "episode: 27919\t average reward: -77.26662320730118\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.050000000000712294\n",
      "episode: 27929\t average reward: -78.1604381443299\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.0500000000007052\n",
      "episode: 27939\t average reward: -79.20470438652256\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000000000069819\n",
      "episode: 27949\t average reward: -77.85631067961165\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000000069124\n",
      "episode: 27959\t average reward: -77.53896103896103\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.050000000000684365\n",
      "episode: 27969\t average reward: -78.76869009584665\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000000000067755\n",
      "episode: 27979\t average reward: -78.48202824133504\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000000067081\n",
      "episode: 27989\t average reward: -78.9840662842575\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000000000066414\n",
      "episode: 27999\t average reward: -77.84540750323416\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.050000000000657525\n",
      "episode: 28009\t average reward: -77.42550422901756\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000065098\n",
      "episode: 28019\t average reward: -78.02324080051646\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000000064451\n",
      "episode: 28029\t average reward: -77.86934023285899\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.050000000000638097\n",
      "episode: 28039\t average reward: -74.11156462585033\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000063175\n",
      "episode: 28049\t average reward: -80.23760463618802\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05000000000062546\n",
      "episode: 28059\t average reward: -96.95304033714629\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.05000000000061924\n",
      "episode: 28069\t average reward: -76.58955717118307\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.050000000000613075\n",
      "episode: 28079\t average reward: -107.09780092592592\t avg steps: 173.8\t lr: 0.0005\t epsilon: 0.050000000000606976\n",
      "episode: 28089\t average reward: -72.7229916897507\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05000000000060094\n",
      "episode: 28099\t average reward: -72.84567474048443\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05000000000059496\n",
      "episode: 28109\t average reward: -72.81258644536653\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000000058904\n",
      "episode: 28119\t average reward: -84.1546785486951\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.050000000000583175\n",
      "episode: 28129\t average reward: -79.77597402597402\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.050000000000577374\n",
      "episode: 28139\t average reward: -88.37291280148423\t avg steps: 162.7\t lr: 0.0005\t epsilon: 0.05000000000057163\n",
      "episode: 28149\t average reward: -72.51458333333333\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05000000000056594\n",
      "episode: 28159\t average reward: -130.86555972147832\t avg steps: 187.7\t lr: 0.0005\t epsilon: 0.05000000000056031\n",
      "episode: 28169\t average reward: -74.33220338983051\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.05000000000055473\n",
      "episode: 28179\t average reward: -166.55272727272728\t avg steps: 221.0\t lr: 0.0005\t epsilon: 0.050000000000549216\n",
      "episode: 28189\t average reward: -73.68331053351574\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.05000000000054375\n",
      "episode: 28199\t average reward: -74.51453684922245\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.050000000000538336\n",
      "episode: 28209\t average reward: -74.07142857142857\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000053298\n",
      "episode: 28219\t average reward: -79.57226182760856\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000000052768\n",
      "episode: 28229\t average reward: -73.17274604267034\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000052243\n",
      "episode: 28239\t average reward: -74.19619823489477\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000051723\n",
      "episode: 28249\t average reward: -79.72857142857143\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.050000000000512086\n",
      "episode: 28259\t average reward: -79.8316129032258\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000000506986\n",
      "episode: 28269\t average reward: -135.66684182869153\t avg steps: 191.3\t lr: 0.0005\t epsilon: 0.05000000000050194\n",
      "episode: 28279\t average reward: -74.71341874578557\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000000000049695\n",
      "episode: 28289\t average reward: -102.62755399883245\t avg steps: 172.3\t lr: 0.0005\t epsilon: 0.050000000000492005\n",
      "episode: 28299\t average reward: -72.61581137309292\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.050000000000487106\n",
      "episode: 28309\t average reward: -76.08927381745502\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05000000000048226\n",
      "episode: 28319\t average reward: -75.17789757412399\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000000047746\n",
      "episode: 28329\t average reward: -72.82975778546712\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.050000000000472715\n",
      "episode: 28339\t average reward: -72.89841050449205\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05000000000046801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 28349\t average reward: -72.01328671328672\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.050000000000463354\n",
      "episode: 28359\t average reward: -97.45427375971309\t avg steps: 168.3\t lr: 0.0005\t epsilon: 0.05000000000045874\n",
      "episode: 28369\t average reward: -73.65708418891171\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05000000000045418\n",
      "episode: 28379\t average reward: -75.38101604278074\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000044966\n",
      "episode: 28389\t average reward: -76.1093439363817\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000000000044518\n",
      "episode: 28399\t average reward: -76.1929940515532\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.050000000000440754\n",
      "episode: 28409\t average reward: -75.48331108144193\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.05000000000043637\n",
      "episode: 28419\t average reward: -78.49870967741936\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000000432025\n",
      "episode: 28429\t average reward: -120.85535617183251\t avg steps: 184.9\t lr: 0.0005\t epsilon: 0.05000000000042773\n",
      "episode: 28439\t average reward: -137.48831168831168\t avg steps: 193.5\t lr: 0.0005\t epsilon: 0.05000000000042347\n",
      "episode: 28449\t average reward: -74.06258503401361\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000041926\n",
      "episode: 28459\t average reward: -73.79371584699453\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000041509\n",
      "episode: 28469\t average reward: -72.85684647302905\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000000041096\n",
      "episode: 28479\t average reward: -75.13480885311871\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05000000000040687\n",
      "episode: 28489\t average reward: -75.86976744186046\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000040282\n",
      "episode: 28499\t average reward: -80.34763124199743\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000000000039881\n",
      "episode: 28509\t average reward: -75.94027869940278\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000000039485\n",
      "episode: 28519\t average reward: -76.03978779840848\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.05000000000039091\n",
      "episode: 28529\t average reward: -101.05266237565829\t avg steps: 171.9\t lr: 0.0005\t epsilon: 0.050000000000387027\n",
      "episode: 28539\t average reward: -76.51721854304635\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.050000000000383175\n",
      "episode: 28549\t average reward: -74.20230821452817\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000037936\n",
      "episode: 28559\t average reward: -73.01931034482759\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.050000000000375584\n",
      "episode: 28569\t average reward: -73.7431693989071\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000037185\n",
      "episode: 28579\t average reward: -98.31086577571179\t avg steps: 173.1\t lr: 0.0005\t epsilon: 0.05000000000036815\n",
      "episode: 28589\t average reward: -76.58092105263158\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000000036449\n",
      "episode: 28599\t average reward: -76.98950819672132\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000000036086\n",
      "episode: 28609\t average reward: -85.66379840196682\t avg steps: 163.7\t lr: 0.0005\t epsilon: 0.05000000000035727\n",
      "episode: 28619\t average reward: -75.77941176470588\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000035371\n",
      "episode: 28629\t average reward: -75.24898785425101\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.050000000000350195\n",
      "episode: 28639\t average reward: -97.52121559633028\t avg steps: 175.4\t lr: 0.0005\t epsilon: 0.05000000000034671\n",
      "episode: 28649\t average reward: -74.5722972972973\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000034326\n",
      "episode: 28659\t average reward: -93.27055393586006\t avg steps: 172.5\t lr: 0.0005\t epsilon: 0.05000000000033985\n",
      "episode: 28669\t average reward: -73.17825189263593\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000033646\n",
      "episode: 28679\t average reward: -77.20852459016393\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000000033312\n",
      "episode: 28689\t average reward: -72.5794587092297\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.0500000000003298\n",
      "episode: 28699\t average reward: -88.46775165762507\t avg steps: 166.9\t lr: 0.0005\t epsilon: 0.05000000000032652\n",
      "episode: 28709\t average reward: -75.38929765886287\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000000032327\n",
      "episode: 28719\t average reward: -75.20830542531814\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000032005\n",
      "episode: 28729\t average reward: -95.97588235294117\t avg steps: 171.0\t lr: 0.0005\t epsilon: 0.05000000000031687\n",
      "episode: 28739\t average reward: -75.19906166219839\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000000031372\n",
      "episode: 28749\t average reward: -189.03493821900298\t avg steps: 235.7\t lr: 0.0005\t epsilon: 0.050000000000310595\n",
      "episode: 28759\t average reward: -75.71858288770053\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000030751\n",
      "episode: 28769\t average reward: -71.22571428571429\t avg steps: 141.0\t lr: 0.0005\t epsilon: 0.05000000000030445\n",
      "episode: 28779\t average reward: -73.55502063273728\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.050000000000301414\n",
      "episode: 28789\t average reward: -75.01021102791015\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000000029842\n",
      "episode: 28799\t average reward: -76.40676841406768\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000000029545\n",
      "episode: 28809\t average reward: -73.64444444444445\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.050000000000292505\n",
      "episode: 28819\t average reward: -74.33241188666206\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.0500000000002896\n",
      "episode: 28829\t average reward: -74.74358974358974\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05000000000028672\n",
      "episode: 28839\t average reward: -69.84682713347921\t avg steps: 138.1\t lr: 0.0005\t epsilon: 0.050000000000283866\n",
      "episode: 28849\t average reward: -73.84779614325069\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05000000000028104\n",
      "episode: 28859\t average reward: -74.21457765667574\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.050000000000278245\n",
      "episode: 28869\t average reward: -72.0675105485232\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05000000000027548\n",
      "episode: 28879\t average reward: -73.97879616963064\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.050000000000272736\n",
      "episode: 28889\t average reward: -75.54222520107238\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.050000000000270016\n",
      "episode: 28899\t average reward: -74.18399452804377\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.05000000000026733\n",
      "episode: 28909\t average reward: -73.61172413793103\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000000026467\n",
      "episode: 28919\t average reward: -66.85332314744079\t avg steps: 131.9\t lr: 0.0005\t epsilon: 0.050000000000262036\n",
      "episode: 28929\t average reward: -73.20586182833217\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.050000000000259434\n",
      "episode: 28939\t average reward: -75.35377358490567\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000000025685\n",
      "episode: 28949\t average reward: -70.85169186465083\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05000000000025429\n",
      "episode: 28959\t average reward: -71.60085227272727\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05000000000025177\n",
      "episode: 28969\t average reward: -77.12736773350751\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000024926\n",
      "episode: 28979\t average reward: -72.68736915561759\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05000000000024678\n",
      "episode: 28989\t average reward: -74.47846889952153\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000024432\n",
      "episode: 28999\t average reward: -73.12734864300626\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05000000000024189\n",
      "episode: 29009\t average reward: -75.4486921529175\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.050000000000239485\n",
      "episode: 29019\t average reward: -74.17340644276902\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.050000000000237105\n",
      "episode: 29029\t average reward: -73.92544459644323\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.050000000000234746\n",
      "episode: 29039\t average reward: -73.26717557251908\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.05000000000023241\n",
      "episode: 29049\t average reward: -74.7911051212938\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.050000000000230096\n",
      "episode: 29059\t average reward: -70.52098408104197\t avg steps: 139.2\t lr: 0.0005\t epsilon: 0.05000000000022781\n",
      "episode: 29069\t average reward: -73.28313671061763\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.05000000000022554\n",
      "episode: 29079\t average reward: -72.66783216783217\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.050000000000223296\n",
      "episode: 29089\t average reward: -70.42991329479769\t avg steps: 139.4\t lr: 0.0005\t epsilon: 0.050000000000221076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 29099\t average reward: -68.28379387602689\t avg steps: 134.9\t lr: 0.0005\t epsilon: 0.050000000000218876\n",
      "episode: 29109\t average reward: -70.38294797687861\t avg steps: 139.4\t lr: 0.0005\t epsilon: 0.0500000000002167\n",
      "episode: 29119\t average reward: -72.58951048951049\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05000000000021454\n",
      "episode: 29129\t average reward: -73.37077877325981\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.0500000000002124\n",
      "episode: 29139\t average reward: -73.30171821305842\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05000000000021029\n",
      "episode: 29149\t average reward: -71.63514467184191\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.0500000000002082\n",
      "episode: 29159\t average reward: -71.4559659090909\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05000000000020613\n",
      "episode: 29169\t average reward: -73.3328738800827\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.050000000000204076\n",
      "episode: 29179\t average reward: -73.91603578802477\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000020205\n",
      "episode: 29189\t average reward: -73.69193659545141\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05000000000020004\n",
      "episode: 29199\t average reward: -75.43825503355704\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.050000000000198046\n",
      "episode: 29209\t average reward: -74.28169979437972\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.050000000000196075\n",
      "episode: 29219\t average reward: -72.8563419761738\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.050000000000194125\n",
      "episode: 29229\t average reward: -75.28446536650975\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000000000019219\n",
      "episode: 29239\t average reward: -71.2144388849178\t avg steps: 140.9\t lr: 0.0005\t epsilon: 0.05000000000019028\n",
      "episode: 29249\t average reward: -71.35458452722062\t avg steps: 140.6\t lr: 0.0005\t epsilon: 0.05000000000018839\n",
      "episode: 29259\t average reward: -73.3175487465181\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05000000000018651\n",
      "episode: 29269\t average reward: -74.22063815342838\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.050000000000184654\n",
      "episode: 29279\t average reward: -72.67295597484276\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.05000000000018282\n",
      "episode: 29289\t average reward: -77.00327653997378\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.050000000000181\n",
      "episode: 29299\t average reward: -71.40801717967072\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.0500000000001792\n",
      "episode: 29309\t average reward: -68.97405485544849\t avg steps: 135.9\t lr: 0.0005\t epsilon: 0.050000000000177416\n",
      "episode: 29319\t average reward: -72.64500349406009\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.050000000000175654\n",
      "episode: 29329\t average reward: -74.94687289845326\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.050000000000173905\n",
      "episode: 29339\t average reward: -69.01913171449596\t avg steps: 136.9\t lr: 0.0005\t epsilon: 0.05000000000017217\n",
      "episode: 29349\t average reward: -71.01779359430606\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05000000000017046\n",
      "episode: 29359\t average reward: -74.40435670524167\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.050000000000168764\n",
      "episode: 29369\t average reward: -69.96441539578794\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.050000000000167084\n",
      "episode: 29379\t average reward: -73.84368600682593\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.05000000000016542\n",
      "episode: 29389\t average reward: -75.61182001343184\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.050000000000163775\n",
      "episode: 29399\t average reward: -77.10295081967213\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.050000000000162144\n",
      "episode: 29409\t average reward: -73.36074637180373\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.050000000000160534\n",
      "episode: 29419\t average reward: -74.65989159891599\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000000015894\n",
      "episode: 29429\t average reward: -71.71125265392782\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.050000000000157356\n",
      "episode: 29439\t average reward: -75.11476510067114\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.05000000000015579\n",
      "episode: 29449\t average reward: -72.49509803921569\t avg steps: 143.8\t lr: 0.0005\t epsilon: 0.05000000000015424\n",
      "episode: 29459\t average reward: -74.15326975476839\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000000000015271\n",
      "episode: 29469\t average reward: -74.79245283018868\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000000015119\n",
      "episode: 29479\t average reward: -73.27820069204152\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05000000000014968\n",
      "episode: 29489\t average reward: -80.82846003898635\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000014819\n",
      "episode: 29499\t average reward: -72.03538570417551\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.05000000000014672\n",
      "episode: 29509\t average reward: -76.32581287325813\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.050000000000145255\n",
      "episode: 29519\t average reward: -72.95164681149264\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05000000000014381\n",
      "episode: 29529\t average reward: -76.44854881266491\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000000000014238\n",
      "episode: 29539\t average reward: -75.21312584573748\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.050000000000140966\n",
      "episode: 29549\t average reward: -76.90356671070013\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05000000000013956\n",
      "episode: 29559\t average reward: -73.63423050379572\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05000000000013817\n",
      "episode: 29569\t average reward: -73.20456116102281\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.050000000000136796\n",
      "episode: 29579\t average reward: -74.82380952380953\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.050000000000135436\n",
      "episode: 29589\t average reward: -76.49176005273566\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000013409\n",
      "episode: 29599\t average reward: -75.64075067024129\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000000013276\n",
      "episode: 29609\t average reward: -72.2137784090909\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05000000000013143\n",
      "episode: 29619\t average reward: -76.9734219269103\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000013013\n",
      "episode: 29629\t average reward: -86.77777777777777\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000000000012883\n",
      "episode: 29639\t average reward: -75.2044235924933\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000000012755\n",
      "episode: 29649\t average reward: -75.80267558528428\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.050000000000126284\n",
      "episode: 29659\t average reward: -73.15491009681881\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000000012502\n",
      "episode: 29669\t average reward: -76.1643379906853\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000012378\n",
      "episode: 29679\t average reward: -79.06429026098027\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05000000000012255\n",
      "episode: 29689\t average reward: -72.68706047819971\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05000000000012133\n",
      "episode: 29699\t average reward: -73.9020979020979\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05000000000012012\n",
      "episode: 29709\t average reward: -76.84590163934426\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000000011893\n",
      "episode: 29719\t average reward: -74.02802460697198\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000011774\n",
      "episode: 29729\t average reward: -75.5441672285907\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000000000011657\n",
      "episode: 29739\t average reward: -72.26985242445538\t avg steps: 143.3\t lr: 0.0005\t epsilon: 0.05000000000011541\n",
      "episode: 29749\t average reward: -77.27099737532808\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.050000000000114266\n",
      "episode: 29759\t average reward: -71.1552217453505\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05000000000011313\n",
      "episode: 29769\t average reward: -70.5850144092219\t avg steps: 139.8\t lr: 0.0005\t epsilon: 0.050000000000112\n",
      "episode: 29779\t average reward: -72.63712491277042\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.050000000000110886\n",
      "episode: 29789\t average reward: -73.91718001368925\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05000000000010978\n",
      "episode: 29799\t average reward: -76.34434897554527\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.050000000000108694\n",
      "episode: 29809\t average reward: -77.82577720207254\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000010761\n",
      "episode: 29819\t average reward: -72.7208653175157\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.050000000000106536\n",
      "episode: 29829\t average reward: -72.02251935256861\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05000000000010548\n",
      "episode: 29839\t average reward: -73.17164697706741\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.050000000000104426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 29849\t average reward: -73.60096818810511\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000000010339\n",
      "episode: 29859\t average reward: -73.77244688142564\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.05000000000010236\n",
      "episode: 29869\t average reward: -74.39659863945579\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.050000000000101345\n",
      "episode: 29879\t average reward: -73.2864044168392\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05000000000010033\n",
      "episode: 29889\t average reward: -73.33287101248267\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05000000000009933\n",
      "episode: 29899\t average reward: -74.64439946018894\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05000000000009835\n",
      "episode: 29909\t average reward: -71.09162491052255\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.05000000000009737\n",
      "episode: 29919\t average reward: -73.26334026334027\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.0500000000000964\n",
      "episode: 29929\t average reward: -73.7517146776406\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000000009544\n",
      "episode: 29939\t average reward: -73.53333333333333\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05000000000009449\n",
      "episode: 29949\t average reward: -75.35512129380054\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000000009355\n",
      "episode: 29959\t average reward: -72.49824067558058\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05000000000009262\n",
      "episode: 29969\t average reward: -73.15491009681881\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.0500000000000917\n",
      "episode: 29979\t average reward: -70.2429090909091\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.050000000000090784\n",
      "episode: 29989\t average reward: -72.53039832285116\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.05000000000008988\n",
      "episode: 29999\t average reward: -74.64426340801086\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000008899\n",
      "episode: 30009\t average reward: -76.44018817204301\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.050000000000088106\n",
      "episode: 30019\t average reward: -76.454363757495\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.050000000000087225\n",
      "episode: 30029\t average reward: -78.45900581020013\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000000008636\n",
      "episode: 30039\t average reward: -73.10533610533611\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.0500000000000855\n",
      "episode: 30049\t average reward: -74.32916666666667\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05000000000008465\n",
      "episode: 30059\t average reward: -76.23727693324521\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.050000000000083804\n",
      "episode: 30069\t average reward: -71.21897289586305\t avg steps: 141.2\t lr: 0.0005\t epsilon: 0.05000000000008297\n",
      "episode: 30079\t average reward: -74.49790502793296\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.050000000000082145\n",
      "episode: 30089\t average reward: -71.90516631280963\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.050000000000081334\n",
      "episode: 30099\t average reward: -73.42058011049724\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.05000000000008052\n",
      "episode: 30109\t average reward: -76.33795379537953\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000007972\n",
      "episode: 30119\t average reward: -73.93922651933701\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.050000000000078926\n",
      "episode: 30129\t average reward: -77.21815806662312\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000007814\n",
      "episode: 30139\t average reward: -74.34146341463415\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.050000000000077365\n",
      "episode: 30149\t average reward: -76.87221494102228\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.050000000000076594\n",
      "episode: 30159\t average reward: -69.8406432748538\t avg steps: 137.8\t lr: 0.0005\t epsilon: 0.05000000000007583\n",
      "episode: 30169\t average reward: -69.73099415204679\t avg steps: 137.8\t lr: 0.0005\t epsilon: 0.050000000000075075\n",
      "episode: 30179\t average reward: -73.95613433858807\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.05000000000007433\n",
      "episode: 30189\t average reward: -73.57623626373626\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05000000000007359\n",
      "episode: 30199\t average reward: -75.52144772117963\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000000007286\n",
      "episode: 30209\t average reward: -74.22814207650273\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000007213\n",
      "episode: 30219\t average reward: -72.38008415147264\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.05000000000007142\n",
      "episode: 30229\t average reward: -75.46826987307949\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.0500000000000707\n",
      "episode: 30239\t average reward: -73.2721563154222\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05000000000007\n",
      "episode: 30249\t average reward: -78.10097719869707\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05000000000006931\n",
      "episode: 30259\t average reward: -72.68938861560085\t avg steps: 143.3\t lr: 0.0005\t epsilon: 0.050000000000068615\n",
      "episode: 30269\t average reward: -73.46519641626465\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.050000000000067935\n",
      "episode: 30279\t average reward: -74.14343983684569\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.050000000000067255\n",
      "episode: 30289\t average reward: -77.37977227059612\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000006659\n",
      "episode: 30299\t average reward: -79.51171627612413\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000000000006592\n",
      "episode: 30309\t average reward: -73.55424200278163\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05000000000006527\n",
      "episode: 30319\t average reward: -74.48497267759562\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000006462\n",
      "episode: 30329\t average reward: -72.62965565706254\t avg steps: 143.3\t lr: 0.0005\t epsilon: 0.05000000000006398\n",
      "episode: 30339\t average reward: -74.58248472505092\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000006334\n",
      "episode: 30349\t average reward: -74.93437077131259\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000006271\n",
      "episode: 30359\t average reward: -76.40119363395226\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.050000000000062085\n",
      "episode: 30369\t average reward: -76.8052805280528\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000006147\n",
      "episode: 30379\t average reward: -77.97637795275591\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000000000006086\n",
      "episode: 30389\t average reward: -75.69919786096257\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000006025\n",
      "episode: 30399\t average reward: -70.31808278867102\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.05000000000005965\n",
      "episode: 30409\t average reward: -71.37793594306049\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05000000000005906\n",
      "episode: 30419\t average reward: -70.18188405797102\t avg steps: 139.0\t lr: 0.0005\t epsilon: 0.05000000000005847\n",
      "episode: 30429\t average reward: -73.56392536281963\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05000000000005789\n",
      "episode: 30439\t average reward: -76.16412971542024\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000005731\n",
      "episode: 30449\t average reward: -74.60949152542373\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.05000000000005674\n",
      "episode: 30459\t average reward: -74.32697547683924\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000000000005618\n",
      "episode: 30469\t average reward: -72.74650837988827\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05000000000005562\n",
      "episode: 30479\t average reward: -76.56311962987442\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000000000005506\n",
      "episode: 30489\t average reward: -75.19785378940308\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.050000000000054515\n",
      "episode: 30499\t average reward: -73.7136021872864\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.050000000000053973\n",
      "episode: 30509\t average reward: -74.89851150202978\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000005344\n",
      "episode: 30519\t average reward: -77.88939197930142\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.050000000000052905\n",
      "episode: 30529\t average reward: -75.74180602006689\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000000005238\n",
      "episode: 30539\t average reward: -73.42047026279391\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000000005186\n",
      "episode: 30549\t average reward: -76.32607260726073\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000000000051344\n",
      "episode: 30559\t average reward: -84.16760828625236\t avg steps: 160.3\t lr: 0.0005\t epsilon: 0.05000000000005083\n",
      "episode: 30569\t average reward: -77.5893437296946\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.050000000000050324\n",
      "episode: 30579\t average reward: -78.81161290322581\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000000049824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 30589\t average reward: -78.89003215434083\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000004933\n",
      "episode: 30599\t average reward: -70.26923076923077\t avg steps: 138.8\t lr: 0.0005\t epsilon: 0.05000000000004884\n",
      "episode: 30609\t average reward: -79.15877080665813\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000000000004835\n",
      "episode: 30619\t average reward: -74.81725543478261\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.050000000000047874\n",
      "episode: 30629\t average reward: -77.2107682206172\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000000000047395\n",
      "episode: 30639\t average reward: -78.10902011680727\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.050000000000046924\n",
      "episode: 30649\t average reward: -75.30384875084403\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000000004646\n",
      "episode: 30659\t average reward: -72.40042075736325\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.050000000000045994\n",
      "episode: 30669\t average reward: -73.03894297635605\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.050000000000045536\n",
      "episode: 30679\t average reward: -73.41229281767956\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.050000000000045085\n",
      "episode: 30689\t average reward: -74.50374914792093\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.050000000000044634\n",
      "episode: 30699\t average reward: -75.65568258238063\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000000000004419\n",
      "episode: 30709\t average reward: -72.92339832869081\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05000000000004375\n",
      "episode: 30719\t average reward: -85.59729064039409\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.050000000000043315\n",
      "episode: 30729\t average reward: -88.94114149821641\t avg steps: 169.2\t lr: 0.0005\t epsilon: 0.050000000000042885\n",
      "episode: 30739\t average reward: -78.22089155023286\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000004246\n",
      "episode: 30749\t average reward: -79.06497725795971\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000004204\n",
      "episode: 30759\t average reward: -74.85422343324251\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.050000000000041615\n",
      "episode: 30769\t average reward: -84.0982694684796\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.050000000000041206\n",
      "episode: 30779\t average reward: -75.64828513786146\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.0500000000000408\n",
      "episode: 30789\t average reward: -77.94311570782159\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000000000004039\n",
      "episode: 30799\t average reward: -77.92931258106356\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.050000000000039985\n",
      "episode: 30809\t average reward: -78.92549775208735\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000000003959\n",
      "episode: 30819\t average reward: -88.82267441860465\t avg steps: 173.0\t lr: 0.0005\t epsilon: 0.050000000000039194\n",
      "episode: 30829\t average reward: -81.53170119271815\t avg steps: 160.3\t lr: 0.0005\t epsilon: 0.050000000000038805\n",
      "episode: 30839\t average reward: -82.24388714733543\t avg steps: 160.5\t lr: 0.0005\t epsilon: 0.050000000000038416\n",
      "episode: 30849\t average reward: -73.30195258019526\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.050000000000038035\n",
      "episode: 30859\t average reward: -73.3367839889579\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05000000000003766\n",
      "episode: 30869\t average reward: -87.74672228843862\t avg steps: 168.8\t lr: 0.0005\t epsilon: 0.050000000000037285\n",
      "episode: 30879\t average reward: -74.44587280108254\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000003691\n",
      "episode: 30889\t average reward: -73.98760330578513\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05000000000003654\n",
      "episode: 30899\t average reward: -71.57203690560681\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.05000000000003618\n",
      "episode: 30909\t average reward: -71.35490753911806\t avg steps: 141.6\t lr: 0.0005\t epsilon: 0.05000000000003582\n",
      "episode: 30919\t average reward: -74.38571428571429\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000003547\n",
      "episode: 30929\t average reward: -72.80611535788742\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.050000000000035114\n",
      "episode: 30939\t average reward: -74.89227642276423\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000000003477\n",
      "episode: 30949\t average reward: -76.69815059445179\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05000000000003442\n",
      "episode: 30959\t average reward: -72.79456824512535\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05000000000003407\n",
      "episode: 30969\t average reward: -73.17397355601949\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05000000000003373\n",
      "episode: 30979\t average reward: -73.40997229916897\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.0500000000000334\n",
      "episode: 30989\t average reward: -73.89042039972433\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05000000000003307\n",
      "episode: 30999\t average reward: -76.93073878627969\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000000000003274\n",
      "episode: 31009\t average reward: -79.73341756159192\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.050000000000032414\n",
      "episode: 31019\t average reward: -71.10533910533911\t avg steps: 139.6\t lr: 0.0005\t epsilon: 0.05000000000003209\n",
      "episode: 31029\t average reward: -81.57888120678818\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05000000000003177\n",
      "episode: 31039\t average reward: -69.52685798381162\t avg steps: 136.9\t lr: 0.0005\t epsilon: 0.05000000000003146\n",
      "episode: 31049\t average reward: -70.2936046511628\t avg steps: 138.6\t lr: 0.0005\t epsilon: 0.050000000000031145\n",
      "episode: 31059\t average reward: -76.35251322751323\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000000000003083\n",
      "episode: 31069\t average reward: -75.65394912985275\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000000000003053\n",
      "episode: 31079\t average reward: -75.20847343644922\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000000000003022\n",
      "episode: 31089\t average reward: -76.27774086378737\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000002992\n",
      "episode: 31099\t average reward: -77.7401166558652\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.050000000000029625\n",
      "episode: 31109\t average reward: -76.73603723404256\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000000000002933\n",
      "episode: 31119\t average reward: -72.03118355776046\t avg steps: 142.1\t lr: 0.0005\t epsilon: 0.050000000000029035\n",
      "episode: 31129\t average reward: -74.36295283663705\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000002875\n",
      "episode: 31139\t average reward: -73.91198891198891\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05000000000002846\n",
      "episode: 31149\t average reward: -71.21557317952416\t avg steps: 139.7\t lr: 0.0005\t epsilon: 0.05000000000002818\n",
      "episode: 31159\t average reward: -72.11111111111111\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.0500000000000279\n",
      "episode: 31169\t average reward: -75.9671581769437\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000000002762\n",
      "episode: 31179\t average reward: -81.92070484581498\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000000000002735\n",
      "episode: 31189\t average reward: -76.51888667992047\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000000000002707\n",
      "episode: 31199\t average reward: -80.11202013845185\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000000000002681\n",
      "episode: 31209\t average reward: -67.16920731707317\t avg steps: 132.2\t lr: 0.0005\t epsilon: 0.05000000000002654\n",
      "episode: 31219\t average reward: -75.58438959306204\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05000000000002627\n",
      "episode: 31229\t average reward: -71.7997169143666\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.05000000000002601\n",
      "episode: 31239\t average reward: -74.48376184032476\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000002575\n",
      "episode: 31249\t average reward: -74.56782549420586\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.050000000000025496\n",
      "episode: 31259\t average reward: -82.43520782396088\t avg steps: 164.6\t lr: 0.0005\t epsilon: 0.050000000000025246\n",
      "episode: 31269\t average reward: -75.72303595206391\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000000002499\n",
      "episode: 31279\t average reward: -76.65188616810059\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000002475\n",
      "episode: 31289\t average reward: -76.01725282017253\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.0500000000000245\n",
      "episode: 31299\t average reward: -71.71073205401564\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.050000000000024254\n",
      "episode: 31309\t average reward: -74.8343475321163\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05000000000002401\n",
      "episode: 31319\t average reward: -74.02462380300958\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.050000000000023775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 31329\t average reward: -78.51189710610933\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000002354\n",
      "episode: 31339\t average reward: -74.0710868079289\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.050000000000023304\n",
      "episode: 31349\t average reward: -76.2753036437247\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.050000000000023075\n",
      "episode: 31359\t average reward: -76.39104278074866\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000002284\n",
      "episode: 31369\t average reward: -73.85123966942149\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05000000000002262\n",
      "episode: 31379\t average reward: -74.43643779741673\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05000000000002239\n",
      "episode: 31389\t average reward: -75.0281879194631\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.050000000000022166\n",
      "episode: 31399\t average reward: -74.22305593451568\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.050000000000021944\n",
      "episode: 31409\t average reward: -71.05483405483406\t avg steps: 139.6\t lr: 0.0005\t epsilon: 0.05000000000002173\n",
      "episode: 31419\t average reward: -75.2118933697881\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000002151\n",
      "episode: 31429\t average reward: -74.35466303607896\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.0500000000000213\n",
      "episode: 31439\t average reward: -71.80704225352113\t avg steps: 143.0\t lr: 0.0005\t epsilon: 0.05000000000002108\n",
      "episode: 31449\t average reward: -83.26878238341969\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.050000000000020875\n",
      "episode: 31459\t average reward: -80.38730569948187\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000002067\n",
      "episode: 31469\t average reward: -74.02405498281787\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.050000000000020466\n",
      "episode: 31479\t average reward: -75.17687074829932\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000002026\n",
      "episode: 31489\t average reward: -77.61713173264114\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.050000000000020056\n",
      "episode: 31499\t average reward: -79.00255102040816\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.050000000000019855\n",
      "episode: 31509\t average reward: -78.8595146871009\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05000000000001966\n",
      "episode: 31519\t average reward: -78.04709677419355\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000000019466\n",
      "episode: 31529\t average reward: -78.9164007657945\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000000000001927\n",
      "episode: 31539\t average reward: -71.795\t avg steps: 141.0\t lr: 0.0005\t epsilon: 0.05000000000001908\n",
      "episode: 31549\t average reward: -75.07598371777476\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.05000000000001889\n",
      "episode: 31559\t average reward: -75.62828282828283\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.0500000000000187\n",
      "episode: 31569\t average reward: -73.8842177808408\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.050000000000018516\n",
      "episode: 31579\t average reward: -72.80790960451978\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05000000000001833\n",
      "episode: 31589\t average reward: -76.37931034482759\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.05000000000001815\n",
      "episode: 31599\t average reward: -75.55727762803234\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000000001797\n",
      "episode: 31609\t average reward: -76.97485109199206\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000001779\n",
      "episode: 31619\t average reward: -72.87008426966293\t avg steps: 143.4\t lr: 0.0005\t epsilon: 0.050000000000017614\n",
      "episode: 31629\t average reward: -74.63394683026584\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.05000000000001744\n",
      "episode: 31639\t average reward: -73.44328462073764\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05000000000001727\n",
      "episode: 31649\t average reward: -78.76516129032258\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000001709\n",
      "episode: 31659\t average reward: -69.73653136531365\t avg steps: 136.5\t lr: 0.0005\t epsilon: 0.05000000000001692\n",
      "episode: 31669\t average reward: -77.00592885375494\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000001675\n",
      "episode: 31679\t average reward: -77.46013071895425\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000001659\n",
      "episode: 31689\t average reward: -77.89018843404808\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000001642\n",
      "episode: 31699\t average reward: -77.475442043222\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000001626\n",
      "episode: 31709\t average reward: -74.47612551159618\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.050000000000016094\n",
      "episode: 31719\t average reward: -74.18181818181819\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.050000000000015934\n",
      "episode: 31729\t average reward: -77.7557003257329\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05000000000001578\n",
      "episode: 31739\t average reward: -75.67294751009422\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.05000000000001562\n",
      "episode: 31749\t average reward: -80.87734668335419\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.05000000000001547\n",
      "episode: 31759\t average reward: -79.61684610512982\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000000000001531\n",
      "episode: 31769\t average reward: -75.2956698240866\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000001516\n",
      "episode: 31779\t average reward: -83.71649166151946\t avg steps: 162.9\t lr: 0.0005\t epsilon: 0.05000000000001501\n",
      "episode: 31789\t average reward: -74.20576131687243\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000000001486\n",
      "episode: 31799\t average reward: -75.7128446536651\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05000000000001471\n",
      "episode: 31809\t average reward: -78.08831168831169\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000000001457\n",
      "episode: 31819\t average reward: -77.32220039292731\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000001442\n",
      "episode: 31829\t average reward: -73.00839748075578\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.050000000000014276\n",
      "episode: 31839\t average reward: -74.537517053206\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05000000000001414\n",
      "episode: 31849\t average reward: -72.77559607293128\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.05000000000001399\n",
      "episode: 31859\t average reward: -73.0\t avg steps: 143.5\t lr: 0.0005\t epsilon: 0.05000000000001385\n",
      "episode: 31869\t average reward: -75.39503688799464\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05000000000001372\n",
      "episode: 31879\t average reward: -74.537517053206\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05000000000001358\n",
      "episode: 31889\t average reward: -78.77799104286628\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000000001344\n",
      "episode: 31899\t average reward: -75.95466666666667\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000000000001331\n",
      "episode: 31909\t average reward: -74.76938915579959\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000000001318\n",
      "episode: 31919\t average reward: -79.8169191919192\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.05000000000001305\n",
      "episode: 31929\t average reward: -77.63642297650131\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000000012916\n",
      "episode: 31939\t average reward: -76.26976744186047\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000001279\n",
      "episode: 31949\t average reward: -72.75334742776603\t avg steps: 142.9\t lr: 0.0005\t epsilon: 0.050000000000012666\n",
      "episode: 31959\t average reward: -78.14490861618799\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000000012534\n",
      "episode: 31969\t average reward: -77.14904793171372\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05000000000001241\n",
      "episode: 31979\t average reward: -77.16754270696453\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000000000001229\n",
      "episode: 31989\t average reward: -78.22330097087378\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000000001217\n",
      "episode: 31999\t average reward: -76.6867151354924\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000000000001205\n",
      "episode: 32009\t average reward: -76.55555555555556\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000000000011924\n",
      "episode: 32019\t average reward: -79.25937698664971\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.050000000000011806\n",
      "episode: 32029\t average reward: -75.07655826558266\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000000001169\n",
      "episode: 32039\t average reward: -79.46158770806659\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000000000001158\n",
      "episode: 32049\t average reward: -77.08338848444738\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000001146\n",
      "episode: 32059\t average reward: -75.39148073022312\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05000000000001135\n",
      "episode: 32069\t average reward: -77.80302035456336\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05000000000001123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 32079\t average reward: -79.18228829993537\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000000000001112\n",
      "episode: 32089\t average reward: -74.88046448087432\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000001101\n",
      "episode: 32099\t average reward: -74.85332419465388\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.0500000000000109\n",
      "episode: 32109\t average reward: -74.323991797676\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000001079\n",
      "episode: 32119\t average reward: -74.80462899931926\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000000001068\n",
      "episode: 32129\t average reward: -73.88211103495544\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.05000000000001058\n",
      "episode: 32139\t average reward: -70.06734250543084\t avg steps: 139.1\t lr: 0.0005\t epsilon: 0.050000000000010474\n",
      "episode: 32149\t average reward: -71.89373680506685\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05000000000001037\n",
      "episode: 32159\t average reward: -70.79597701149426\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.050000000000010265\n",
      "episode: 32169\t average reward: -71.41184767277856\t avg steps: 142.8\t lr: 0.0005\t epsilon: 0.05000000000001016\n",
      "episode: 32179\t average reward: -74.30088495575221\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.050000000000010064\n",
      "episode: 32189\t average reward: -77.21578947368421\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000000000996\n",
      "episode: 32199\t average reward: -71.88700564971751\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05000000000000986\n",
      "episode: 32209\t average reward: -75.01755570560432\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.050000000000009766\n",
      "episode: 32219\t average reward: -74.84527027027028\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000000967\n",
      "episode: 32229\t average reward: -67.43192133131619\t avg steps: 133.2\t lr: 0.0005\t epsilon: 0.05000000000000957\n",
      "episode: 32239\t average reward: -67.18209408194234\t avg steps: 132.8\t lr: 0.0005\t epsilon: 0.050000000000009474\n",
      "episode: 32249\t average reward: -72.23923782639379\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.050000000000009384\n",
      "episode: 32259\t average reward: -76.34970139349701\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000000000929\n",
      "episode: 32269\t average reward: -70.56524873828407\t avg steps: 139.7\t lr: 0.0005\t epsilon: 0.0500000000000092\n",
      "episode: 32279\t average reward: -74.48782138024357\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000911\n",
      "episode: 32289\t average reward: -70.20667150108774\t avg steps: 138.9\t lr: 0.0005\t epsilon: 0.050000000000009016\n",
      "episode: 32299\t average reward: -67.60333080999243\t avg steps: 133.1\t lr: 0.0005\t epsilon: 0.050000000000008926\n",
      "episode: 32309\t average reward: -71.57872340425531\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.050000000000008836\n",
      "episode: 32319\t average reward: -73.77081899518238\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.050000000000008746\n",
      "episode: 32329\t average reward: -75.71341463414635\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05000000000000866\n",
      "episode: 32339\t average reward: -76.95328947368421\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000000000857\n",
      "episode: 32349\t average reward: -75.05604921394395\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000000849\n",
      "episode: 32359\t average reward: -79.66498103666245\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.050000000000008406\n",
      "episode: 32369\t average reward: -76.03884795713329\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000000832\n",
      "episode: 32379\t average reward: -74.46153846153847\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05000000000000824\n",
      "episode: 32389\t average reward: -76.51398135818908\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.050000000000008156\n",
      "episode: 32399\t average reward: -77.0592105263158\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000000000807\n",
      "episode: 32409\t average reward: -77.37410540013012\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.050000000000007996\n",
      "episode: 32419\t average reward: -75.81216577540107\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000000791\n",
      "episode: 32429\t average reward: -70.77882523567803\t avg steps: 138.9\t lr: 0.0005\t epsilon: 0.05000000000000784\n",
      "episode: 32439\t average reward: -71.96744515215853\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.05000000000000776\n",
      "episode: 32449\t average reward: -66.01469450889404\t avg steps: 130.3\t lr: 0.0005\t epsilon: 0.050000000000007684\n",
      "episode: 32459\t average reward: -72.17168885774352\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05000000000000761\n",
      "episode: 32469\t average reward: -72.25035161744023\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05000000000000753\n",
      "episode: 32479\t average reward: -71.680624556423\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.050000000000007455\n",
      "episode: 32489\t average reward: -76.5679419525066\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000000000000738\n",
      "episode: 32499\t average reward: -71.50928571428571\t avg steps: 141.0\t lr: 0.0005\t epsilon: 0.05000000000000731\n",
      "episode: 32509\t average reward: -76.20543406229291\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000000000000723\n",
      "episode: 32519\t average reward: -74.92592592592592\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.050000000000007164\n",
      "episode: 32529\t average reward: -68.87361419068736\t avg steps: 136.3\t lr: 0.0005\t epsilon: 0.050000000000007094\n",
      "episode: 32539\t average reward: -71.41963015647227\t avg steps: 141.6\t lr: 0.0005\t epsilon: 0.05000000000000702\n",
      "episode: 32549\t average reward: -71.28439059158946\t avg steps: 141.3\t lr: 0.0005\t epsilon: 0.05000000000000695\n",
      "episode: 32559\t average reward: -74.44685172647257\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.05000000000000688\n",
      "episode: 32569\t average reward: -73.75728155339806\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05000000000000682\n",
      "episode: 32579\t average reward: -72.4136460554371\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.05000000000000675\n",
      "episode: 32589\t average reward: -75.23401360544217\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000000668\n",
      "episode: 32599\t average reward: -75.32195448460509\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.050000000000006616\n",
      "episode: 32609\t average reward: -74.70624151967435\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.050000000000006546\n",
      "episode: 32619\t average reward: -72.6345213137666\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.050000000000006484\n",
      "episode: 32629\t average reward: -74.95564516129032\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.050000000000006414\n",
      "episode: 32639\t average reward: -71.01428571428572\t avg steps: 141.0\t lr: 0.0005\t epsilon: 0.05000000000000635\n",
      "episode: 32649\t average reward: -69.74817518248175\t avg steps: 138.0\t lr: 0.0005\t epsilon: 0.05000000000000629\n",
      "episode: 32659\t average reward: -71.09103840682788\t avg steps: 141.6\t lr: 0.0005\t epsilon: 0.05000000000000623\n",
      "episode: 32669\t average reward: -73.80410958904109\t avg steps: 147.0\t lr: 0.0005\t epsilon: 0.050000000000006165\n",
      "episode: 32679\t average reward: -68.82100591715977\t avg steps: 136.2\t lr: 0.0005\t epsilon: 0.0500000000000061\n",
      "episode: 32689\t average reward: -73.7\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000000000605\n",
      "episode: 32699\t average reward: -77.826171875\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050000000000005984\n",
      "episode: 32709\t average reward: -73.82620689655172\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000000000592\n",
      "episode: 32719\t average reward: -78.2073406310367\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.050000000000005866\n",
      "episode: 32729\t average reward: -78.65428937259924\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.050000000000005804\n",
      "episode: 32739\t average reward: -74.85471826205024\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000000575\n",
      "episode: 32749\t average reward: -74.65067567567567\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000000569\n",
      "episode: 32759\t average reward: -74.0\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000000000000564\n",
      "episode: 32769\t average reward: -73.04088704088704\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05000000000000558\n",
      "episode: 32779\t average reward: -73.56121045392022\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.050000000000005526\n",
      "episode: 32789\t average reward: -73.26768377253813\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05000000000000547\n",
      "episode: 32799\t average reward: -70.49568965517241\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.050000000000005415\n",
      "episode: 32809\t average reward: -73.16804407713498\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05000000000000536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 32819\t average reward: -73.23414634146341\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.050000000000005304\n",
      "episode: 32829\t average reward: -72.8728403593642\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.050000000000005256\n",
      "episode: 32839\t average reward: -75.63291139240506\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.0500000000000052\n",
      "episode: 32849\t average reward: -70.74622573687994\t avg steps: 140.1\t lr: 0.0005\t epsilon: 0.05000000000000515\n",
      "episode: 32859\t average reward: -73.67770876466528\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.050000000000005096\n",
      "episode: 32869\t average reward: -73.37508602890571\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000000505\n",
      "episode: 32879\t average reward: -76.676\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.050000000000005\n",
      "episode: 32889\t average reward: -71.22675250357653\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05000000000000495\n",
      "episode: 32899\t average reward: -73.59751037344398\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.0500000000000049\n",
      "episode: 32909\t average reward: -73.93018480492813\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05000000000000485\n",
      "episode: 32919\t average reward: -75.97480106100795\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.050000000000004804\n",
      "episode: 32929\t average reward: -73.63598901098901\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.050000000000004756\n",
      "episode: 32939\t average reward: -75.92634372926344\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000000000471\n",
      "episode: 32949\t average reward: -73.70673076923077\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05000000000000466\n",
      "episode: 32959\t average reward: -72.60881735479356\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.05000000000000462\n",
      "episode: 32969\t average reward: -71.63055954088952\t avg steps: 140.4\t lr: 0.0005\t epsilon: 0.05000000000000457\n",
      "episode: 32979\t average reward: -67.47236941710825\t avg steps: 133.1\t lr: 0.0005\t epsilon: 0.05000000000000452\n",
      "episode: 32989\t average reward: -71.67021276595744\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05000000000000448\n",
      "episode: 32999\t average reward: -71.6711743772242\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05000000000000443\n",
      "episode: 33009\t average reward: -72.80027932960894\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05000000000000439\n",
      "episode: 33019\t average reward: -73.5237767057202\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.050000000000004347\n",
      "episode: 33029\t average reward: -72.60364145658264\t avg steps: 143.8\t lr: 0.0005\t epsilon: 0.050000000000004305\n",
      "episode: 33039\t average reward: -77.05398288347597\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.050000000000004256\n",
      "episode: 33049\t average reward: -71.406852248394\t avg steps: 141.1\t lr: 0.0005\t epsilon: 0.050000000000004215\n",
      "episode: 33059\t average reward: -70.77955039883975\t avg steps: 138.9\t lr: 0.0005\t epsilon: 0.05000000000000417\n",
      "episode: 33069\t average reward: -69.13545521835677\t avg steps: 136.1\t lr: 0.0005\t epsilon: 0.05000000000000413\n",
      "episode: 33079\t average reward: -77.95575797007157\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000000409\n",
      "episode: 33089\t average reward: -76.33601070950469\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.050000000000004055\n",
      "episode: 33099\t average reward: -75.4989816700611\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000000401\n",
      "episode: 33109\t average reward: -74.4755677907777\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000000397\n",
      "episode: 33119\t average reward: -74.82016348773843\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05000000000000393\n",
      "episode: 33129\t average reward: -77.59254414650098\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.050000000000003895\n",
      "episode: 33139\t average reward: -79.11139401654997\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.050000000000003854\n",
      "episode: 33149\t average reward: -79.32736572890026\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05000000000000382\n",
      "episode: 33159\t average reward: -77.53526697429136\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000000378\n",
      "episode: 33169\t average reward: -81.44499381953028\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.05000000000000374\n",
      "episode: 33179\t average reward: -79.49967341606794\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.0500000000000037\n",
      "episode: 33189\t average reward: -77.06788866259335\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.050000000000003667\n",
      "episode: 33199\t average reward: -81.30730793254216\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.05000000000000363\n",
      "episode: 33209\t average reward: -74.20278745644599\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.0500000000000036\n",
      "episode: 33219\t average reward: -82.53874313605857\t avg steps: 164.9\t lr: 0.0005\t epsilon: 0.050000000000003555\n",
      "episode: 33229\t average reward: -76.81891348088531\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05000000000000352\n",
      "episode: 33239\t average reward: -77.06574621959237\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.050000000000003486\n",
      "episode: 33249\t average reward: -77.25804333552199\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05000000000000345\n",
      "episode: 33259\t average reward: -75.8556077904634\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.05000000000000342\n",
      "episode: 33269\t average reward: -76.84224598930481\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000000338\n",
      "episode: 33279\t average reward: -76.96693121693121\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000000000003354\n",
      "episode: 33289\t average reward: -80.47777082028804\t avg steps: 160.7\t lr: 0.0005\t epsilon: 0.05000000000000332\n",
      "episode: 33299\t average reward: -79.78421387651177\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.050000000000003285\n",
      "episode: 33309\t average reward: -76.58161225849433\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05000000000000325\n",
      "episode: 33319\t average reward: -77.634225996081\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000000322\n",
      "episode: 33329\t average reward: -77.42744063324538\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000000000000319\n",
      "episode: 33339\t average reward: -80.20401757689893\t avg steps: 160.3\t lr: 0.0005\t epsilon: 0.05000000000000315\n",
      "episode: 33349\t average reward: -76.72690492245448\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.050000000000003125\n",
      "episode: 33359\t average reward: -76.17225201072387\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05000000000000309\n",
      "episode: 33369\t average reward: -72.84410112359551\t avg steps: 143.4\t lr: 0.0005\t epsilon: 0.05000000000000306\n",
      "episode: 33379\t average reward: -76.34993359893758\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.050000000000003035\n",
      "episode: 33389\t average reward: -79.00257069408741\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.050000000000003\n",
      "episode: 33399\t average reward: -73.13511611541168\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05000000000000297\n",
      "episode: 33409\t average reward: -76.432\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.050000000000002945\n",
      "episode: 33419\t average reward: -79.20038167938931\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000000000292\n",
      "episode: 33429\t average reward: -76.15204286671133\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000000288\n",
      "episode: 33439\t average reward: -78.53100775193798\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.050000000000002855\n",
      "episode: 33449\t average reward: -80.0506329113924\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000000000000283\n",
      "episode: 33459\t average reward: -70.48684210526316\t avg steps: 137.8\t lr: 0.0005\t epsilon: 0.0500000000000028\n",
      "episode: 33469\t average reward: -77.37557755775578\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000000277\n",
      "episode: 33479\t average reward: -78.05975049244911\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.050000000000002744\n",
      "episode: 33489\t average reward: -77.132362673726\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.050000000000002716\n",
      "episode: 33499\t average reward: -72.75859649122808\t avg steps: 143.5\t lr: 0.0005\t epsilon: 0.05000000000000269\n",
      "episode: 33509\t average reward: -77.97805035506778\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05000000000000266\n",
      "episode: 33519\t average reward: -78.29824561403508\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000000264\n",
      "episode: 33529\t average reward: -86.24119402985075\t avg steps: 168.5\t lr: 0.0005\t epsilon: 0.05000000000000261\n",
      "episode: 33539\t average reward: -79.53910256410256\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.050000000000002584\n",
      "episode: 33549\t average reward: -79.24728434504793\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.050000000000002556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 33559\t average reward: -78.08311688311689\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.050000000000002535\n",
      "episode: 33569\t average reward: -76.1998658618377\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05000000000000251\n",
      "episode: 33579\t average reward: -76.32042723631508\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.05000000000000248\n",
      "episode: 33589\t average reward: -77.51513157894736\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05000000000000246\n",
      "episode: 33599\t average reward: -81.10575719649562\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.05000000000000243\n",
      "episode: 33609\t average reward: -82.30560690080098\t avg steps: 163.3\t lr: 0.0005\t epsilon: 0.05000000000000241\n",
      "episode: 33619\t average reward: -76.06486486486486\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000000238\n",
      "episode: 33629\t average reward: -77.6984126984127\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000000000000236\n",
      "episode: 33639\t average reward: -76.0468854655057\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000000234\n",
      "episode: 33649\t average reward: -79.1153350515464\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000000000000231\n",
      "episode: 33659\t average reward: -71.13318934485241\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05000000000000229\n",
      "episode: 33669\t average reward: -78.20866141732283\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000000000000227\n",
      "episode: 33679\t average reward: -74.1681537405628\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.050000000000002244\n",
      "episode: 33689\t average reward: -77.29555997349237\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000000000000222\n",
      "episode: 33699\t average reward: -79.1193363114231\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.0500000000000022\n",
      "episode: 33709\t average reward: -72.1218993621545\t avg steps: 142.1\t lr: 0.0005\t epsilon: 0.05000000000000218\n",
      "episode: 33719\t average reward: -76.85977616853192\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05000000000000216\n",
      "episode: 33729\t average reward: -185.90153698366956\t avg steps: 209.2\t lr: 0.0005\t epsilon: 0.05000000000000214\n",
      "episode: 33739\t average reward: -83.13888888888889\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.05000000000000212\n",
      "episode: 33749\t average reward: -94.80726420620972\t avg steps: 171.7\t lr: 0.0005\t epsilon: 0.0500000000000021\n",
      "episode: 33759\t average reward: -79.58781594296825\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000000000208\n",
      "episode: 33769\t average reward: -83.12105926860025\t avg steps: 159.6\t lr: 0.0005\t epsilon: 0.05000000000000206\n",
      "episode: 33779\t average reward: -79.12653324725629\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.050000000000002036\n",
      "episode: 33789\t average reward: -134.13806706114397\t avg steps: 203.8\t lr: 0.0005\t epsilon: 0.050000000000002015\n",
      "episode: 33799\t average reward: -75.51192910702113\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.050000000000001994\n",
      "episode: 33809\t average reward: -254.98447204968943\t avg steps: 258.6\t lr: 0.0005\t epsilon: 0.05000000000000197\n",
      "episode: 33819\t average reward: -77.30511811023622\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000000000000195\n",
      "episode: 33829\t average reward: -75.74448160535117\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000000000193\n",
      "episode: 33839\t average reward: -92.39127764127764\t avg steps: 163.8\t lr: 0.0005\t epsilon: 0.05000000000000192\n",
      "episode: 33849\t average reward: -74.43160054719563\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.0500000000000019\n",
      "episode: 33859\t average reward: -79.2578073089701\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.050000000000001876\n",
      "episode: 33869\t average reward: -70.12708787218591\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.050000000000001855\n",
      "episode: 33879\t average reward: -73.31657223796034\t avg steps: 142.2\t lr: 0.0005\t epsilon: 0.05000000000000184\n",
      "episode: 33889\t average reward: -71.58865248226951\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05000000000000182\n",
      "episode: 33899\t average reward: -73.41048951048951\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05000000000000181\n",
      "episode: 33909\t average reward: -71.8376251788269\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.050000000000001786\n",
      "episode: 33919\t average reward: -117.8755905511811\t avg steps: 191.5\t lr: 0.0005\t epsilon: 0.050000000000001765\n",
      "episode: 33929\t average reward: -77.76031434184677\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05000000000000175\n",
      "episode: 33939\t average reward: -73.00487804878048\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.05000000000000173\n",
      "episode: 33949\t average reward: -73.47506925207756\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05000000000000172\n",
      "episode: 33959\t average reward: -76.09379217273954\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.050000000000001696\n",
      "episode: 33969\t average reward: -80.53752405388069\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000000000168\n",
      "episode: 33979\t average reward: -74.87280108254397\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000167\n",
      "episode: 33989\t average reward: -74.81683501683501\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05000000000000165\n",
      "episode: 33999\t average reward: -75.67811447811448\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05000000000000163\n",
      "episode: 34009\t average reward: -74.24393624393625\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05000000000000162\n",
      "episode: 34019\t average reward: -71.02083333333333\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.0500000000000016\n",
      "episode: 34029\t average reward: -73.6121045392022\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.050000000000001585\n",
      "episode: 34039\t average reward: -73.2943661971831\t avg steps: 143.0\t lr: 0.0005\t epsilon: 0.05000000000000157\n",
      "episode: 34049\t average reward: -71.27988546886185\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.05000000000000155\n",
      "episode: 34059\t average reward: -71.08751793400288\t avg steps: 140.4\t lr: 0.0005\t epsilon: 0.050000000000001536\n",
      "episode: 34069\t average reward: -68.58289962825279\t avg steps: 135.5\t lr: 0.0005\t epsilon: 0.05000000000000152\n",
      "episode: 34079\t average reward: -74.75050847457626\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.05000000000000151\n",
      "episode: 34089\t average reward: -76.02081934184017\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.050000000000001495\n",
      "episode: 34099\t average reward: -78.3751633986928\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000000148\n",
      "episode: 34109\t average reward: -74.36129032258064\t avg steps: 140.5\t lr: 0.0005\t epsilon: 0.05000000000000146\n",
      "episode: 34119\t average reward: -85.01759899434317\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.050000000000001446\n",
      "episode: 34129\t average reward: -77.05585106382979\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000000000000143\n",
      "episode: 34139\t average reward: -73.73825966850829\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.05000000000000142\n",
      "episode: 34149\t average reward: -73.8971898560658\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.050000000000001404\n",
      "episode: 34159\t average reward: -73.7464114832536\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000000139\n",
      "episode: 34169\t average reward: -81.77186311787072\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05000000000000138\n",
      "episode: 34179\t average reward: -71.98306280875089\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05000000000000136\n",
      "episode: 34189\t average reward: -107.95034642032333\t avg steps: 174.2\t lr: 0.0005\t epsilon: 0.05000000000000135\n",
      "episode: 34199\t average reward: -78.66732154551408\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.050000000000001335\n",
      "episode: 34209\t average reward: -71.30872959545778\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.05000000000000132\n",
      "episode: 34219\t average reward: -77.31225296442688\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000000131\n",
      "episode: 34229\t average reward: -72.15228070175439\t avg steps: 143.5\t lr: 0.0005\t epsilon: 0.0500000000000013\n",
      "episode: 34239\t average reward: -75.94926568758345\t avg steps: 150.8\t lr: 0.0005\t epsilon: 0.050000000000001286\n",
      "episode: 34249\t average reward: -72.52198185624565\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05000000000000127\n",
      "episode: 34259\t average reward: -66.73522640061397\t avg steps: 131.3\t lr: 0.0005\t epsilon: 0.05000000000000126\n",
      "episode: 34269\t average reward: -72.56543037088873\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.050000000000001245\n",
      "episode: 34279\t average reward: -77.35914118412492\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000000124\n",
      "episode: 34289\t average reward: -76.21024617431803\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.050000000000001224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 34299\t average reward: -69.64014869888476\t avg steps: 135.5\t lr: 0.0005\t epsilon: 0.05000000000000121\n",
      "episode: 34309\t average reward: -74.91836734693878\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.050000000000001196\n",
      "episode: 34319\t average reward: -73.37204450625869\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05000000000000119\n",
      "episode: 34329\t average reward: -76.29940515532056\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.050000000000001175\n",
      "episode: 34339\t average reward: -74.32807137954701\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000000000116\n",
      "episode: 34349\t average reward: -72.64170748775368\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.050000000000001155\n",
      "episode: 34359\t average reward: -79.22037155669443\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05000000000000114\n",
      "episode: 34369\t average reward: -79.85604606525912\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000000000113\n",
      "episode: 34379\t average reward: -83.95705128205128\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05000000000000112\n",
      "episode: 34389\t average reward: -80.09557408595253\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.050000000000001106\n",
      "episode: 34399\t average reward: -74.08356353591161\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.05000000000000109\n",
      "episode: 34409\t average reward: -79.63694676074407\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.050000000000001085\n",
      "episode: 34419\t average reward: -96.57451523545707\t avg steps: 181.5\t lr: 0.0005\t epsilon: 0.05000000000000107\n",
      "episode: 34429\t average reward: -76.97763157894737\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.050000000000001064\n",
      "episode: 34439\t average reward: -76.29840848806366\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.05000000000000105\n",
      "episode: 34449\t average reward: -76.71031746031746\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.050000000000001044\n",
      "episode: 34459\t average reward: -74.01138790035587\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05000000000000103\n",
      "episode: 34469\t average reward: -98.6196388261851\t avg steps: 178.2\t lr: 0.0005\t epsilon: 0.05000000000000102\n",
      "episode: 34479\t average reward: -80.54820051413881\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05000000000000101\n",
      "episode: 34489\t average reward: -79.92889173606662\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.050000000000001\n",
      "episode: 34499\t average reward: -69.24053452115812\t avg steps: 135.7\t lr: 0.0005\t epsilon: 0.05000000000000099\n",
      "episode: 34509\t average reward: -75.424037812289\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000000000098\n",
      "episode: 34519\t average reward: -74.41792065663475\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.050000000000000974\n",
      "episode: 34529\t average reward: -77.49083769633508\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000000000000096\n",
      "episode: 34539\t average reward: -71.39224137931035\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.05000000000000095\n",
      "episode: 34549\t average reward: -79.72457359444094\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.050000000000000946\n",
      "episode: 34559\t average reward: -73.95988934993085\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000000000093\n",
      "episode: 34569\t average reward: -84.11056811240073\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.050000000000000926\n",
      "episode: 34579\t average reward: -74.83513513513513\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000000092\n",
      "episode: 34589\t average reward: -81.19530754597336\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.050000000000000905\n",
      "episode: 34599\t average reward: -78.61351706036746\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.0500000000000009\n",
      "episode: 34609\t average reward: -144.9732477260567\t avg steps: 187.9\t lr: 0.0005\t epsilon: 0.05000000000000089\n",
      "episode: 34619\t average reward: -219.86124613345117\t avg steps: 227.3\t lr: 0.0005\t epsilon: 0.05000000000000088\n",
      "episode: 34629\t average reward: -86.12640949554896\t avg steps: 169.5\t lr: 0.0005\t epsilon: 0.05000000000000087\n",
      "episode: 34639\t average reward: -87.47514792899408\t avg steps: 170.0\t lr: 0.0005\t epsilon: 0.05000000000000086\n",
      "episode: 34649\t average reward: -79.89961880559085\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.050000000000000856\n",
      "episode: 34659\t average reward: -74.67788461538461\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05000000000000084\n",
      "episode: 34669\t average reward: -84.92719352831362\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.050000000000000835\n",
      "episode: 34679\t average reward: -75.73233695652173\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05000000000000083\n",
      "episode: 34689\t average reward: -78.21200260926288\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000000000082\n",
      "episode: 34699\t average reward: -122.08255933952529\t avg steps: 194.8\t lr: 0.0005\t epsilon: 0.050000000000000815\n",
      "episode: 34709\t average reward: -76.20883534136546\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.0500000000000008\n",
      "episode: 34719\t average reward: -75.94414535666218\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.050000000000000794\n",
      "episode: 34729\t average reward: -77.34168865435356\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000000000000079\n",
      "episode: 34739\t average reward: -78.13548387096775\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000000078\n",
      "episode: 34749\t average reward: -75.98006644518273\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000000077\n",
      "episode: 34759\t average reward: -71.11158798283262\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.050000000000000766\n",
      "episode: 34769\t average reward: -76.0569323509712\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000000076\n",
      "episode: 34779\t average reward: -76.34107498341075\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000000000075\n",
      "episode: 34789\t average reward: -77.52159685863874\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000000000000745\n",
      "episode: 34799\t average reward: -76.4774834437086\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000000000000074\n",
      "episode: 34809\t average reward: -73.99378453038673\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.050000000000000724\n",
      "episode: 34819\t average reward: -74.1011699931177\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000000072\n",
      "episode: 34829\t average reward: -76.71609042553192\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000000000000071\n",
      "episode: 34839\t average reward: -71.40329512893983\t avg steps: 140.6\t lr: 0.0005\t epsilon: 0.050000000000000704\n",
      "episode: 34849\t average reward: -76.71050892267019\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.0500000000000007\n",
      "episode: 34859\t average reward: -75.4665300546448\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000000069\n",
      "episode: 34869\t average reward: -74.9979381443299\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05000000000000068\n",
      "episode: 34879\t average reward: -74.99193006052455\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.050000000000000676\n",
      "episode: 34889\t average reward: -77.49637442320369\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000000067\n",
      "episode: 34899\t average reward: -75.56731413261889\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000000066\n",
      "episode: 34909\t average reward: -75.1894451962111\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000066\n",
      "episode: 34919\t average reward: -71.82234957020057\t avg steps: 140.6\t lr: 0.0005\t epsilon: 0.050000000000000655\n",
      "episode: 34929\t average reward: -73.15767634854772\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05000000000000065\n",
      "episode: 34939\t average reward: -76.26480372588156\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000000064\n",
      "episode: 34949\t average reward: -74.42798353909465\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.050000000000000634\n",
      "episode: 34959\t average reward: -69.25718496683861\t avg steps: 136.7\t lr: 0.0005\t epsilon: 0.05000000000000063\n",
      "episode: 34969\t average reward: -77.13324624428478\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000000062\n",
      "episode: 34979\t average reward: -75.39473684210526\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05000000000000061\n",
      "episode: 34989\t average reward: -74.4108843537415\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.050000000000000606\n",
      "episode: 34999\t average reward: -70.53597122302158\t avg steps: 140.0\t lr: 0.0005\t epsilon: 0.0500000000000006\n",
      "episode: 35009\t average reward: -70.23048869438367\t avg steps: 138.1\t lr: 0.0005\t epsilon: 0.0500000000000006\n",
      "episode: 35019\t average reward: -73.89368998628258\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000000000059\n",
      "episode: 35029\t average reward: -75.92307692307692\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.050000000000000586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 35039\t average reward: -73.36907216494845\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05000000000000058\n",
      "episode: 35049\t average reward: -70.32129963898917\t avg steps: 139.5\t lr: 0.0005\t epsilon: 0.05000000000000057\n",
      "episode: 35059\t average reward: -71.38284066330209\t avg steps: 139.7\t lr: 0.0005\t epsilon: 0.050000000000000565\n",
      "episode: 35069\t average reward: -72.73625608907446\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.050000000000000565\n",
      "episode: 35079\t average reward: -75.92585170340682\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000000000056\n",
      "episode: 35089\t average reward: -76.68729208250166\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000000055\n",
      "episode: 35099\t average reward: -75.44083840432725\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.050000000000000544\n",
      "episode: 35109\t average reward: -82.19330855018588\t avg steps: 162.4\t lr: 0.0005\t epsilon: 0.05000000000000054\n",
      "episode: 35119\t average reward: -67.63966691900076\t avg steps: 133.1\t lr: 0.0005\t epsilon: 0.05000000000000054\n",
      "episode: 35129\t average reward: -73.76368676368676\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05000000000000053\n",
      "episode: 35139\t average reward: -76.36151797603196\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000000000052\n",
      "episode: 35149\t average reward: -73.44582470669427\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.050000000000000516\n",
      "episode: 35159\t average reward: -74.38866120218579\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.050000000000000516\n",
      "episode: 35169\t average reward: -78.15282392026577\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000000051\n",
      "episode: 35179\t average reward: -76.45374149659864\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.0500000000000005\n",
      "episode: 35189\t average reward: -73.11908077994428\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.050000000000000495\n",
      "episode: 35199\t average reward: -77.56335282651072\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.050000000000000495\n",
      "episode: 35209\t average reward: -71.34485241180705\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05000000000000049\n",
      "episode: 35219\t average reward: -72.90851063829787\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05000000000000048\n",
      "episode: 35229\t average reward: -73.80425824175825\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05000000000000048\n",
      "episode: 35239\t average reward: -74.0385144429161\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.050000000000000475\n",
      "episode: 35249\t average reward: -68.51190476190476\t avg steps: 135.4\t lr: 0.0005\t epsilon: 0.05000000000000047\n",
      "episode: 35259\t average reward: -81.2579415501906\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05000000000000047\n",
      "episode: 35269\t average reward: -89.68279883381925\t avg steps: 172.5\t lr: 0.0005\t epsilon: 0.05000000000000046\n",
      "episode: 35279\t average reward: -75.39863945578232\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.050000000000000454\n",
      "episode: 35289\t average reward: -475.11686557081737\t avg steps: 445.1\t lr: 0.0005\t epsilon: 0.050000000000000454\n",
      "episode: 35299\t average reward: -74.90392422192151\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000045\n",
      "episode: 35309\t average reward: -76.20580296896087\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05000000000000044\n",
      "episode: 35319\t average reward: -439.03287108371853\t avg steps: 390.4\t lr: 0.0005\t epsilon: 0.05000000000000044\n",
      "episode: 35329\t average reward: -87.24407582938389\t avg steps: 169.8\t lr: 0.0005\t epsilon: 0.05000000000000043\n",
      "episode: 35339\t average reward: -89.05687203791469\t avg steps: 169.8\t lr: 0.0005\t epsilon: 0.05000000000000043\n",
      "episode: 35349\t average reward: -78.84734799482536\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.050000000000000426\n",
      "episode: 35359\t average reward: -75.45448460508702\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000000000000042\n",
      "episode: 35369\t average reward: -74.83412969283276\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.05000000000000042\n",
      "episode: 35379\t average reward: -70.30847212165098\t avg steps: 139.1\t lr: 0.0005\t epsilon: 0.05000000000000041\n",
      "episode: 35389\t average reward: -89.21390689451974\t avg steps: 170.7\t lr: 0.0005\t epsilon: 0.05000000000000041\n",
      "episode: 35399\t average reward: -78.13399339933993\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000000000000405\n",
      "episode: 35409\t average reward: -75.96\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.0500000000000004\n",
      "episode: 35419\t average reward: -72.03892427459306\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.0500000000000004\n",
      "episode: 35429\t average reward: -72.61678321678322\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05000000000000039\n",
      "episode: 35439\t average reward: -82.04448621553885\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05000000000000039\n",
      "episode: 35449\t average reward: -73.61829436038515\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.050000000000000384\n",
      "episode: 35459\t average reward: -74.22471147318397\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.050000000000000384\n",
      "episode: 35469\t average reward: -73.92137931034483\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000000000038\n",
      "episode: 35479\t average reward: -70.04938271604938\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.05000000000000037\n",
      "episode: 35489\t average reward: -75.6036217303823\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05000000000000037\n",
      "episode: 35499\t average reward: -76.71305500331346\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.050000000000000364\n",
      "episode: 35509\t average reward: -77.74206092028516\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.050000000000000364\n",
      "episode: 35519\t average reward: -72.67867231638418\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05000000000000036\n",
      "episode: 35529\t average reward: -78.13398058252427\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05000000000000036\n",
      "episode: 35539\t average reward: -79.19847328244275\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000000000035\n",
      "episode: 35549\t average reward: -78.1444229529336\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05000000000000035\n",
      "episode: 35559\t average reward: -79.53354430379747\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000000000000034\n",
      "episode: 35569\t average reward: -80.77306733167082\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.05000000000000034\n",
      "episode: 35579\t average reward: -82.7345942647956\t avg steps: 164.9\t lr: 0.0005\t epsilon: 0.050000000000000336\n",
      "episode: 35589\t average reward: -81.25418474891507\t avg steps: 162.3\t lr: 0.0005\t epsilon: 0.050000000000000336\n",
      "episode: 35599\t average reward: -77.18229508196721\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000000000033\n",
      "episode: 35609\t average reward: -78.44387096774193\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.05000000000000033\n",
      "episode: 35619\t average reward: -81.73563928350833\t avg steps: 162.9\t lr: 0.0005\t epsilon: 0.05000000000000032\n",
      "episode: 35629\t average reward: -80.48806532663316\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.05000000000000032\n",
      "episode: 35639\t average reward: -83.1647345942648\t avg steps: 164.9\t lr: 0.0005\t epsilon: 0.05000000000000032\n",
      "episode: 35649\t average reward: -81.87060998151571\t avg steps: 163.3\t lr: 0.0005\t epsilon: 0.050000000000000315\n",
      "episode: 35659\t average reward: -74.93929058663029\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.050000000000000315\n",
      "episode: 35669\t average reward: -77.74951203643461\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000000031\n",
      "episode: 35679\t average reward: -75.81653225806451\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05000000000000031\n",
      "episode: 35689\t average reward: -79.95271122320302\t avg steps: 159.6\t lr: 0.0005\t epsilon: 0.0500000000000003\n",
      "episode: 35699\t average reward: -79.21055979643766\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.0500000000000003\n",
      "episode: 35709\t average reward: -77.93203883495146\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.050000000000000294\n",
      "episode: 35719\t average reward: -73.89017735334242\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.050000000000000294\n",
      "episode: 35729\t average reward: -74.44482058226134\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.050000000000000294\n",
      "episode: 35739\t average reward: -74.25322471147318\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000000029\n",
      "episode: 35749\t average reward: -73.25790921595599\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.05000000000000029\n",
      "episode: 35759\t average reward: -75.4779411764706\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000000028\n",
      "episode: 35769\t average reward: -73.24501032346869\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000000028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 35779\t average reward: -79.36872218690401\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05000000000000028\n",
      "episode: 35789\t average reward: -78.85047923322684\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000000000000027\n",
      "episode: 35799\t average reward: -77.79209844559585\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000000027\n",
      "episode: 35809\t average reward: -76.34704711347047\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.050000000000000266\n",
      "episode: 35819\t average reward: -76.5592885375494\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.050000000000000266\n",
      "episode: 35829\t average reward: -74.72677966101695\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.050000000000000266\n",
      "episode: 35839\t average reward: -76.48611111111111\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000000000000026\n",
      "episode: 35849\t average reward: -75.42886041807148\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000000000000026\n",
      "episode: 35859\t average reward: -78.42149292149293\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000000000026\n",
      "episode: 35869\t average reward: -76.15221707478491\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000000025\n",
      "episode: 35879\t average reward: -74.91559756921\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000000000025\n",
      "episode: 35889\t average reward: -76.89698162729658\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.050000000000000246\n",
      "episode: 35899\t average reward: -79.69269841269842\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.050000000000000246\n",
      "episode: 35909\t average reward: -77.06544502617801\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000000000000246\n",
      "episode: 35919\t average reward: -77.56657963446476\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000000000024\n",
      "episode: 35929\t average reward: -73.67106176266482\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.05000000000000024\n",
      "episode: 35939\t average reward: -75.36302294197031\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05000000000000024\n",
      "episode: 35949\t average reward: -79.02328589909443\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05000000000000023\n",
      "episode: 35959\t average reward: -80.82730673316708\t avg steps: 161.4\t lr: 0.0005\t epsilon: 0.05000000000000023\n",
      "episode: 35969\t average reward: -83.58230958230958\t avg steps: 163.8\t lr: 0.0005\t epsilon: 0.05000000000000023\n",
      "episode: 35979\t average reward: -73.79712131596985\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.050000000000000225\n",
      "episode: 35989\t average reward: -78.56675224646983\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.050000000000000225\n",
      "episode: 35999\t average reward: -75.76415722851432\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.050000000000000225\n",
      "episode: 36009\t average reward: -77.97020725388602\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000000022\n",
      "episode: 36019\t average reward: -75.4692513368984\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000000022\n",
      "episode: 36029\t average reward: -76.52603823335531\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05000000000000022\n",
      "episode: 36039\t average reward: -77.4925178919974\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000000022\n",
      "episode: 36049\t average reward: -77.90284974093264\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000000021\n",
      "episode: 36059\t average reward: -74.88148148148149\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05000000000000021\n",
      "episode: 36069\t average reward: -77.16209150326797\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05000000000000021\n",
      "episode: 36079\t average reward: -77.29204693611473\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.050000000000000204\n",
      "episode: 36089\t average reward: -74.27679782903664\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.050000000000000204\n",
      "episode: 36099\t average reward: -78.15483870967742\t avg steps: 156.0\t lr: 0.0005\t epsilon: 0.050000000000000204\n",
      "episode: 36109\t average reward: -77.654296875\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.0500000000000002\n",
      "episode: 36119\t average reward: -84.6025957972806\t avg steps: 162.8\t lr: 0.0005\t epsilon: 0.0500000000000002\n",
      "episode: 36129\t average reward: -83.23413705583756\t avg steps: 158.6\t lr: 0.0005\t epsilon: 0.0500000000000002\n",
      "episode: 36139\t average reward: -73.48587181254307\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.0500000000000002\n",
      "episode: 36149\t average reward: -75.88755020080322\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000000000000019\n",
      "episode: 36159\t average reward: -75.76296296296296\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05000000000000019\n",
      "episode: 36169\t average reward: -74.74439157036029\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05000000000000019\n",
      "episode: 36179\t average reward: -76.74815807099799\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05000000000000019\n",
      "episode: 36189\t average reward: -79.70986093552465\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.05000000000000018\n",
      "episode: 36199\t average reward: -79.41788205453392\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05000000000000018\n",
      "episode: 36209\t average reward: -82.12046711739397\t avg steps: 163.7\t lr: 0.0005\t epsilon: 0.05000000000000018\n",
      "episode: 36219\t average reward: -79.90094637223974\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000000000018\n",
      "episode: 36229\t average reward: -83.64108761329305\t avg steps: 166.5\t lr: 0.0005\t epsilon: 0.050000000000000176\n",
      "episode: 36239\t average reward: -80.53942428035043\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.050000000000000176\n",
      "episode: 36249\t average reward: -81.10192666252331\t avg steps: 161.9\t lr: 0.0005\t epsilon: 0.050000000000000176\n",
      "episode: 36259\t average reward: -78.00065359477124\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.050000000000000176\n",
      "episode: 36269\t average reward: -81.14978247358607\t avg steps: 161.9\t lr: 0.0005\t epsilon: 0.05000000000000017\n",
      "episode: 36279\t average reward: -79.79797979797979\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.05000000000000017\n",
      "episode: 36289\t average reward: -82.8974358974359\t avg steps: 160.9\t lr: 0.0005\t epsilon: 0.05000000000000017\n",
      "episode: 36299\t average reward: -85.82571602681291\t avg steps: 165.1\t lr: 0.0005\t epsilon: 0.05000000000000017\n",
      "episode: 36309\t average reward: -71.56\t avg steps: 141.0\t lr: 0.0005\t epsilon: 0.05000000000000016\n",
      "episode: 36319\t average reward: -76.1797603195739\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000000000016\n",
      "episode: 36329\t average reward: -71.89118065433856\t avg steps: 141.6\t lr: 0.0005\t epsilon: 0.05000000000000016\n",
      "episode: 36339\t average reward: -77.20053120849934\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05000000000000016\n",
      "episode: 36349\t average reward: -72.6006968641115\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.050000000000000155\n",
      "episode: 36359\t average reward: -72.56345885634589\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.050000000000000155\n",
      "episode: 36369\t average reward: -80.6371018113679\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.050000000000000155\n",
      "episode: 36379\t average reward: -75.40535117056857\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.050000000000000155\n",
      "episode: 36389\t average reward: -77.13398692810458\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.050000000000000155\n",
      "episode: 36399\t average reward: -79.61177960734642\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000000000000015\n",
      "episode: 36409\t average reward: -73.78227494766224\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05000000000000015\n",
      "episode: 36419\t average reward: -76.45346534653466\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000000015\n",
      "episode: 36429\t average reward: -80.28216851730895\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05000000000000015\n",
      "episode: 36439\t average reward: -74.21625344352617\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05000000000000014\n",
      "episode: 36449\t average reward: -73.10110803324099\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05000000000000014\n",
      "episode: 36459\t average reward: -81.00635324015248\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05000000000000014\n",
      "episode: 36469\t average reward: -81.4593730006398\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000000000014\n",
      "episode: 36479\t average reward: -67.88293051359517\t avg steps: 133.4\t lr: 0.0005\t epsilon: 0.05000000000000014\n",
      "episode: 36489\t average reward: -74.31288343558282\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.050000000000000135\n",
      "episode: 36499\t average reward: -73.57988980716253\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.050000000000000135\n",
      "episode: 36509\t average reward: -74.0576527110501\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.050000000000000135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 36519\t average reward: -76.95313531353135\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000000000000135\n",
      "episode: 36529\t average reward: -76.52272727272727\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.050000000000000135\n",
      "episode: 36539\t average reward: -69.7727603787327\t avg steps: 138.3\t lr: 0.0005\t epsilon: 0.050000000000000135\n",
      "episode: 36549\t average reward: -75.80106453759149\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000000013\n",
      "episode: 36559\t average reward: -74.36136205698402\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05000000000000013\n",
      "episode: 36569\t average reward: -74.89348710990502\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.05000000000000013\n",
      "episode: 36579\t average reward: -68.01495886312641\t avg steps: 134.7\t lr: 0.0005\t epsilon: 0.05000000000000013\n",
      "episode: 36589\t average reward: -81.96112852664577\t avg steps: 160.5\t lr: 0.0005\t epsilon: 0.05000000000000013\n",
      "episode: 36599\t average reward: -83.55144291091594\t avg steps: 160.4\t lr: 0.0005\t epsilon: 0.05000000000000012\n",
      "episode: 36609\t average reward: -72.12898653437279\t avg steps: 142.1\t lr: 0.0005\t epsilon: 0.05000000000000012\n",
      "episode: 36619\t average reward: -77.7639429312581\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000000012\n",
      "episode: 36629\t average reward: -71.74324324324324\t avg steps: 141.6\t lr: 0.0005\t epsilon: 0.05000000000000012\n",
      "episode: 36639\t average reward: -74.26\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05000000000000012\n",
      "episode: 36649\t average reward: -75.26078167115902\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000000000012\n",
      "episode: 36659\t average reward: -73.35334713595583\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.050000000000000114\n",
      "episode: 36669\t average reward: -84.05709023941068\t avg steps: 163.9\t lr: 0.0005\t epsilon: 0.050000000000000114\n",
      "episode: 36679\t average reward: -82.19151590767311\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.050000000000000114\n",
      "episode: 36689\t average reward: -80.14503816793894\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.050000000000000114\n",
      "episode: 36699\t average reward: -75.44318181818181\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.050000000000000114\n",
      "episode: 36709\t average reward: -73.00696864111498\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.050000000000000114\n",
      "episode: 36719\t average reward: -73.74861495844875\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05000000000000011\n",
      "episode: 36729\t average reward: -77.60793237971392\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000000000011\n",
      "episode: 36739\t average reward: -76.61635638297872\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05000000000000011\n",
      "episode: 36749\t average reward: -69.61375274323336\t avg steps: 137.7\t lr: 0.0005\t epsilon: 0.05000000000000011\n",
      "episode: 36759\t average reward: -70.9484240687679\t avg steps: 140.6\t lr: 0.0005\t epsilon: 0.05000000000000011\n",
      "episode: 36769\t average reward: -72.2353770260747\t avg steps: 142.9\t lr: 0.0005\t epsilon: 0.05000000000000011\n",
      "episode: 36779\t average reward: -69.81158357771261\t avg steps: 137.4\t lr: 0.0005\t epsilon: 0.05000000000000011\n",
      "episode: 36789\t average reward: -75.60159893404398\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.0500000000000001\n",
      "episode: 36799\t average reward: -76.28910891089109\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.0500000000000001\n",
      "episode: 36809\t average reward: -71.64914772727273\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.0500000000000001\n",
      "episode: 36819\t average reward: -72.94722222222222\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.0500000000000001\n",
      "episode: 36829\t average reward: -74.92794612794613\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.0500000000000001\n",
      "episode: 36839\t average reward: -73.56641431520991\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.0500000000000001\n",
      "episode: 36849\t average reward: -70.86043165467626\t avg steps: 140.0\t lr: 0.0005\t epsilon: 0.0500000000000001\n",
      "episode: 36859\t average reward: -74.17679180887372\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36869\t average reward: -70.94604316546763\t avg steps: 140.0\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36879\t average reward: -71.35088967971531\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36889\t average reward: -71.45260156806843\t avg steps: 141.3\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36899\t average reward: -72.83588317107093\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36909\t average reward: -71.8407960199005\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36919\t average reward: -72.44622905027933\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36929\t average reward: -74.96075778078485\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000009\n",
      "episode: 36939\t average reward: -75.38513060951105\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 36949\t average reward: -73.6\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 36959\t average reward: -77.74593892137752\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 36969\t average reward: -78.57317073170732\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 36979\t average reward: -80.01385390428212\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 36989\t average reward: -77.47100977198697\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 36999\t average reward: -82.33086876155268\t avg steps: 163.3\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 37009\t average reward: -86.11499703615887\t avg steps: 169.7\t lr: 0.0005\t epsilon: 0.050000000000000086\n",
      "episode: 37019\t average reward: -86.4979399646851\t avg steps: 170.9\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37029\t average reward: -88.87405687753918\t avg steps: 173.3\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37039\t average reward: -74.4280798348245\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37049\t average reward: -74.82721088435375\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37059\t average reward: -87.14748201438849\t avg steps: 167.8\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37069\t average reward: -79.4955185659411\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37079\t average reward: -81.8364898989899\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37089\t average reward: -74.3818306010929\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37099\t average reward: -71.36688079942898\t avg steps: 141.1\t lr: 0.0005\t epsilon: 0.05000000000000008\n",
      "episode: 37109\t average reward: -75.89515593895156\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37119\t average reward: -70.30406386066764\t avg steps: 138.8\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37129\t average reward: -73.84763212079616\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37139\t average reward: -68.08051166290444\t avg steps: 133.9\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37149\t average reward: -74.97501688048615\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37159\t average reward: -74.6490156143924\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37169\t average reward: -71.06652360515021\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37179\t average reward: -75.44086021505376\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37189\t average reward: -75.631754503002\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37199\t average reward: -78.4553628773282\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000000000007\n",
      "episode: 37209\t average reward: -76.56192358366272\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37219\t average reward: -76.43280632411067\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37229\t average reward: -78.14893617021276\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37239\t average reward: -77.03206806282722\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37249\t average reward: -75.99532085561498\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37259\t average reward: -277.9209409949865\t avg steps: 260.3\t lr: 0.0005\t epsilon: 0.050000000000000065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 37269\t average reward: -111.29518664047151\t avg steps: 204.6\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37279\t average reward: -87.24736842105263\t avg steps: 172.0\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37289\t average reward: -79.20788302606485\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37299\t average reward: -78.81765834932821\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37309\t average reward: -79.2531806615776\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.050000000000000065\n",
      "episode: 37319\t average reward: -77.04930966469428\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37329\t average reward: -74.72150170648464\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37339\t average reward: -75.79797297297297\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37349\t average reward: -79.25063613231552\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37359\t average reward: -80.05667506297229\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37369\t average reward: -78.49550706033376\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37379\t average reward: -77.94509043927648\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37389\t average reward: -79.13694267515923\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37399\t average reward: -77.33224755700326\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37409\t average reward: -78.90595009596929\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37419\t average reward: -79.5373417721519\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37429\t average reward: -80.88084840923268\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37439\t average reward: -77.4479843953186\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000000000006\n",
      "episode: 37449\t average reward: -77.88924870466322\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37459\t average reward: -76.32642140468228\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37469\t average reward: -76.729873586161\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37479\t average reward: -78.73832373640435\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37489\t average reward: -82.93548387096774\t avg steps: 165.3\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37499\t average reward: -81.88724584103512\t avg steps: 163.3\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37509\t average reward: -79.21246819338423\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37519\t average reward: -75.70370370370371\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37529\t average reward: -73.0385423966363\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37539\t average reward: -74.88979591836734\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37549\t average reward: -78.78402555910543\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37559\t average reward: -78.46885035324341\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37569\t average reward: -77.36114732724903\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37579\t average reward: -75.91882900864937\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05000000000000005\n",
      "episode: 37589\t average reward: -77.32527759634226\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37599\t average reward: -77.46158854166667\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37609\t average reward: -67.53770739064856\t avg steps: 133.6\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37619\t average reward: -69.22230428360413\t avg steps: 136.4\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37629\t average reward: -74.91485013623978\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37639\t average reward: -77.87035830618892\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37649\t average reward: -75.08760107816711\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37659\t average reward: -70.11256354393609\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37669\t average reward: -68.99851301115241\t avg steps: 135.5\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37679\t average reward: -73.75824175824175\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37689\t average reward: -70.86652236652236\t avg steps: 139.6\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37699\t average reward: -76.65850430178689\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37709\t average reward: -74.90675675675676\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37719\t average reward: -70.12061403508773\t avg steps: 137.8\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37729\t average reward: -77.75522193211488\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37739\t average reward: -80.85856697819315\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37749\t average reward: -79.54084863837872\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.050000000000000044\n",
      "episode: 37759\t average reward: -77.909681611436\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37769\t average reward: -74.81069958847736\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37779\t average reward: -79.17394094993581\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37789\t average reward: -73.66388888888889\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37799\t average reward: -76.54003970880211\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37809\t average reward: -75.29161028416779\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37819\t average reward: -74.72869802317655\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37829\t average reward: -76.49171636845593\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37839\t average reward: -75.47535449020931\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37849\t average reward: -75.25389302640488\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37859\t average reward: -77.76010430247719\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37869\t average reward: -78.73561732385262\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37879\t average reward: -82.9473361910594\t avg steps: 164.3\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37889\t average reward: -80.6026282853567\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37899\t average reward: -83.5989110707804\t avg steps: 166.3\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37909\t average reward: -79.48795944233207\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37919\t average reward: -78.44608472400513\t avg steps: 156.8\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37929\t average reward: -77.23613829093281\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37939\t average reward: -74.87886944818304\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37949\t average reward: -77.34442270058709\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05000000000000004\n",
      "episode: 37959\t average reward: -74.56216216216217\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 37969\t average reward: -71.94613749114103\t avg steps: 142.1\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 37979\t average reward: -76.31130204890945\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 37989\t average reward: -75.41549766199064\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 37999\t average reward: -73.34390075809786\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05000000000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 38009\t average reward: -73.33680555555556\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38019\t average reward: -74.93711967545639\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38029\t average reward: -73.00698324022346\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38039\t average reward: -78.28635778635778\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38049\t average reward: -68.5829596412556\t avg steps: 134.8\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38059\t average reward: -76.69047619047619\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38069\t average reward: -79.50765306122449\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38079\t average reward: -79.0019267822736\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38089\t average reward: -78.99166132135984\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38099\t average reward: -76.64513981358189\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38109\t average reward: -76.87812911725955\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38119\t average reward: -76.19933110367893\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38129\t average reward: -78.21789883268482\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38139\t average reward: -74.01664355062414\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38149\t average reward: -76.64441506939855\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38159\t average reward: -77.4775828460039\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38169\t average reward: -76.83234323432343\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38179\t average reward: -75.2398097826087\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38189\t average reward: -73.37290502793296\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38199\t average reward: -75.63317599460552\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000000000000003\n",
      "episode: 38209\t average reward: -75.03632625085675\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38219\t average reward: -74.82866894197952\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38229\t average reward: -75.52684563758389\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38239\t average reward: -76.51259946949602\t avg steps: 151.8\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38249\t average reward: -70.069270449521\t avg steps: 136.7\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38259\t average reward: -75.31347325660121\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38269\t average reward: -72.19577464788732\t avg steps: 143.0\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38279\t average reward: -77.53583168967785\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38289\t average reward: -71.16607015032211\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38299\t average reward: -74.08686730506156\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38309\t average reward: -72.49649859943978\t avg steps: 143.8\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38319\t average reward: -71.19884726224784\t avg steps: 139.8\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38329\t average reward: -69.7\t avg steps: 138.0\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38339\t average reward: -77.24086161879896\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38349\t average reward: -76.31551155115511\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38359\t average reward: -72.03352353780313\t avg steps: 141.2\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38369\t average reward: -70.3442265795207\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38379\t average reward: -74.19904240766074\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38389\t average reward: -72.22551092318534\t avg steps: 142.9\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38399\t average reward: -75.96330887258172\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38409\t average reward: -74.99864864864865\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38419\t average reward: -73.27494766224703\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38429\t average reward: -74.73242320819112\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38439\t average reward: -75.39945836154367\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38449\t average reward: -81.31878557874762\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38459\t average reward: -75.3367139959432\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38469\t average reward: -75.64213369345038\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38479\t average reward: -78.79590531030071\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38489\t average reward: -79.91293375394322\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38499\t average reward: -76.91153342070773\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38509\t average reward: -81.22526446795271\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38519\t average reward: -77.85621761658031\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38529\t average reward: -73.3970893970894\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38539\t average reward: -72.46881569726699\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.050000000000000024\n",
      "episode: 38549\t average reward: -75.23828647925033\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38559\t average reward: -76.57312252964427\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38569\t average reward: -74.0\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38579\t average reward: -76.09271523178808\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38589\t average reward: -75.0877785280216\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38599\t average reward: -75.06562922868741\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38609\t average reward: -80.16782773907536\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38619\t average reward: -74.41536369816451\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38629\t average reward: -74.12697323266987\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38639\t average reward: -71.68754448398576\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38649\t average reward: -78.55771725032426\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38659\t average reward: -77.77098243331164\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38669\t average reward: -75.47916666666667\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38679\t average reward: -79.10382165605095\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38689\t average reward: -76.51451187335093\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38699\t average reward: -73.57941988950276\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38709\t average reward: -77.85537459283388\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38719\t average reward: -79.03408360128617\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38729\t average reward: -70.26773957571324\t avg steps: 137.7\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38739\t average reward: -70.66133720930233\t avg steps: 138.6\t lr: 0.0005\t epsilon: 0.05000000000000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 38749\t average reward: -72.60676532769556\t avg steps: 142.9\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38759\t average reward: -75.80681818181819\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38769\t average reward: -76.46798679867987\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38779\t average reward: -77.86854153041203\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38789\t average reward: -74.75967413441956\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38799\t average reward: -73.64099037138926\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38809\t average reward: -85.32349323493234\t avg steps: 163.6\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38819\t average reward: -100.3420745920746\t avg steps: 172.6\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38829\t average reward: -78.84947643979058\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38839\t average reward: -81.3969465648855\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38849\t average reward: -76.2808764940239\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38859\t average reward: -199.25589066918002\t avg steps: 213.2\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38869\t average reward: -90.15286624203821\t avg steps: 173.7\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38879\t average reward: -73.79792387543253\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38889\t average reward: -72.24699221514508\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38899\t average reward: -72.8\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38909\t average reward: -87.51547694251421\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38919\t average reward: -82.57160883280757\t avg steps: 159.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38929\t average reward: -446.4194236926361\t avg steps: 282.1\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38939\t average reward: -68.97919762258543\t avg steps: 135.6\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38949\t average reward: -73.63548830811554\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38959\t average reward: -81.45765998707175\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38969\t average reward: -76.50301003344481\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38979\t average reward: -79.30395333765392\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38989\t average reward: -70.17711370262391\t avg steps: 138.2\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 38999\t average reward: -73.17451523545706\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 39009\t average reward: -72.54367575122292\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 39019\t average reward: -68.67163067758749\t avg steps: 135.3\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 39029\t average reward: -72.80375782881002\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 39039\t average reward: -71.4391459074733\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 39049\t average reward: -73.00627177700349\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.05000000000000002\n",
      "episode: 39059\t average reward: -70.75852066715011\t avg steps: 138.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39069\t average reward: -71.79312813171082\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39079\t average reward: -74.1379781420765\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39089\t average reward: -71.07974137931035\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39099\t average reward: -73.89773507206588\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39109\t average reward: -75.35198921105867\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39119\t average reward: -72.28941836019622\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39129\t average reward: -77.55666666666667\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39139\t average reward: -73.9047619047619\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39149\t average reward: -88.7719298245614\t avg steps: 166.3\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39159\t average reward: -74.89851150202978\t avg steps: 148.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39169\t average reward: -75.38274932614556\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39179\t average reward: -80.66950819672131\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39189\t average reward: -73.7302676733013\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39199\t average reward: -71.258226037196\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39209\t average reward: -73.98009608785175\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39219\t average reward: -72.86433566433567\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39229\t average reward: -73.4020618556701\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39239\t average reward: -71.197715917202\t avg steps: 141.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39249\t average reward: -73.29688581314879\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39259\t average reward: -75.37084745762712\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39269\t average reward: -73.06237006237006\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39279\t average reward: -68.5254110612855\t avg steps: 134.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39289\t average reward: -73.50485436893204\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39299\t average reward: -81.46713465220166\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39309\t average reward: -81.19047619047619\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39319\t average reward: -84.49384316267012\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39329\t average reward: -76.93873517786561\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39339\t average reward: -72.84933426769446\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39349\t average reward: -73.33821478382148\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39359\t average reward: -72.91946778711484\t avg steps: 143.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39369\t average reward: -71.14367816091954\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39379\t average reward: -77.14128187456926\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39389\t average reward: -70.61483081353492\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39399\t average reward: -70.50181554103122\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39409\t average reward: -70.68455402465555\t avg steps: 138.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39419\t average reward: -74.03453038674033\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39429\t average reward: -74.29246575342465\t avg steps: 147.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39439\t average reward: -73.13970064148253\t avg steps: 141.3\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39449\t average reward: -93.1078431372549\t avg steps: 164.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39459\t average reward: -90.79169038133182\t avg steps: 176.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39469\t average reward: -268.79411764705884\t avg steps: 317.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39479\t average reward: -141.9517766497462\t avg steps: 198.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39489\t average reward: -78.65734720416125\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 39499\t average reward: -74.61709520500348\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39509\t average reward: -84.8360450563204\t avg steps: 160.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39519\t average reward: -71.31724627395316\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39529\t average reward: -74.12032630863358\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39539\t average reward: -75.651677852349\t avg steps: 150.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39549\t average reward: -73.1459649122807\t avg steps: 143.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39559\t average reward: -75.59324324324324\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39569\t average reward: -78.36522301228183\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39579\t average reward: -80.87695190505934\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39589\t average reward: -81.64876543209877\t avg steps: 163.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39599\t average reward: -76.18570474281897\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39609\t average reward: -74.53150684931506\t avg steps: 147.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39619\t average reward: -79.58202099737532\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39629\t average reward: -73.98494182067077\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39639\t average reward: -73.09192200557104\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39649\t average reward: -74.88130968622102\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39659\t average reward: -78.16097240473061\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39669\t average reward: -69.30280649926145\t avg steps: 136.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39679\t average reward: -76.10522832561217\t avg steps: 152.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39689\t average reward: -78.08268733850129\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39699\t average reward: -76.61188118811882\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39709\t average reward: -77.8368010403121\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39719\t average reward: -81.77819314641745\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39729\t average reward: -78.23904639175258\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39739\t average reward: -78.30610932475884\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39749\t average reward: -80.0484886649874\t avg steps: 159.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39759\t average reward: -85.2954954954955\t avg steps: 167.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39769\t average reward: -77.94795055302538\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39779\t average reward: -86.9903672486454\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39789\t average reward: -111.74044157242865\t avg steps: 186.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39799\t average reward: -78.0487012987013\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39809\t average reward: -142.57102001906577\t avg steps: 210.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39819\t average reward: -76.6156462585034\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39829\t average reward: -78.54019933554817\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39839\t average reward: -76.75666666666666\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39849\t average reward: -80.98754669987547\t avg steps: 161.6\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39859\t average reward: -76.4066225165563\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39869\t average reward: -82.30049261083744\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39879\t average reward: -84.96805304400242\t avg steps: 166.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39889\t average reward: -78.69526248399488\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39899\t average reward: -80.08118313404657\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39909\t average reward: -79.63630613535737\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39919\t average reward: -80.40414833438089\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39929\t average reward: -79.02868068833652\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39939\t average reward: -84.16625\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39949\t average reward: -77.67824377457406\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39959\t average reward: -76.58705803869246\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39969\t average reward: -91.23858173076923\t avg steps: 167.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39979\t average reward: -77.40488771466315\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39989\t average reward: -79.15637065637065\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 39999\t average reward: -74.28776486671224\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40009\t average reward: -68.40820895522388\t avg steps: 135.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40019\t average reward: -79.0741469816273\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40029\t average reward: -77.90867279894876\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40039\t average reward: -106.78602860286028\t avg steps: 182.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40049\t average reward: -68.96607669616519\t avg steps: 136.6\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40059\t average reward: -71.5113475177305\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40069\t average reward: -71.78820184790334\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40079\t average reward: -71.49318996415771\t avg steps: 140.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40089\t average reward: -69.85756026296566\t avg steps: 137.9\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40099\t average reward: -78.04895561357702\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40109\t average reward: -81.99201474201475\t avg steps: 163.8\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40119\t average reward: -78.26319218241042\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40129\t average reward: -74.89336978810663\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40139\t average reward: -76.7594684385382\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40149\t average reward: -71.95335689045936\t avg steps: 142.5\t lr: 0.0005\t epsilon: 0.05000000000000001\n",
      "episode: 40159\t average reward: -77.63907284768212\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40169\t average reward: -76.10997963340122\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40179\t average reward: -70.7546494992847\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40189\t average reward: -73.7581881533101\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40199\t average reward: -67.24067022086824\t avg steps: 132.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40209\t average reward: -77.216\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40219\t average reward: -76.77449046679816\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40229\t average reward: -88.85535714285714\t avg steps: 169.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40239\t average reward: -137.07190894981895\t avg steps: 194.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40249\t average reward: -74.90311418685121\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 40259\t average reward: -81.94164619164619\t avg steps: 163.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40269\t average reward: -80.08825396825397\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40279\t average reward: -71.52567760342367\t avg steps: 141.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40289\t average reward: -67.05837755875663\t avg steps: 132.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40299\t average reward: -69.78209831254586\t avg steps: 137.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40309\t average reward: -74.19417475728156\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40319\t average reward: -72.5025053686471\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40329\t average reward: -71.92095977417078\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40339\t average reward: -76.95767195767196\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40349\t average reward: -75.62892223738062\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40359\t average reward: -76.67526455026454\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40369\t average reward: -75.26490514905149\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40379\t average reward: -73.75103734439834\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40389\t average reward: -71.9080541696365\t avg steps: 141.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40399\t average reward: -71.71265189421015\t avg steps: 140.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40409\t average reward: -77.21644736842106\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40419\t average reward: -79.37939859245041\t avg steps: 157.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40429\t average reward: -80.05079365079365\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40439\t average reward: -82.3799751243781\t avg steps: 161.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40449\t average reward: -72.47903340440654\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40459\t average reward: -72.80905233380481\t avg steps: 142.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40469\t average reward: -73.00210378681626\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40479\t average reward: -70.03263234227701\t avg steps: 138.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40489\t average reward: -74.45130315500685\t avg steps: 146.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40499\t average reward: -80.34052287581699\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40509\t average reward: -83.91447770311545\t avg steps: 164.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40519\t average reward: -73.1937062937063\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40529\t average reward: -76.79349269588313\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40539\t average reward: -78.98589743589744\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40549\t average reward: -81.5734445157152\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40559\t average reward: -75.83668005354752\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40569\t average reward: -76.371467025572\t avg steps: 149.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40579\t average reward: -75.11268556005398\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40589\t average reward: -83.43269821757836\t avg steps: 163.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40599\t average reward: -81.61635220125787\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40609\t average reward: -78.30702341137123\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40619\t average reward: -78.65283267457181\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40629\t average reward: -72.7696750902527\t avg steps: 139.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40639\t average reward: -77.38795986622074\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40649\t average reward: -68.8827067669173\t avg steps: 134.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40659\t average reward: -71.04613095238095\t avg steps: 135.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40669\t average reward: -70.3360534124629\t avg steps: 135.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40679\t average reward: -69.86775631500743\t avg steps: 135.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40689\t average reward: -75.46817538896747\t avg steps: 142.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40699\t average reward: -76.8153428377461\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40709\t average reward: -75.74809688581315\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40719\t average reward: -68.27160493827161\t avg steps: 130.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40729\t average reward: -75.27715877437326\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40739\t average reward: -79.45603674540682\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40749\t average reward: -74.91061452513966\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40759\t average reward: -73.67067137809187\t avg steps: 142.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40769\t average reward: -70.09889298892989\t avg steps: 136.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40779\t average reward: -71.36926438455936\t avg steps: 138.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40789\t average reward: -70.67503692762186\t avg steps: 136.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40799\t average reward: -75.46894197952219\t avg steps: 147.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40809\t average reward: -79.84463462804477\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40819\t average reward: -69.96747352496217\t avg steps: 133.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40829\t average reward: -70.99484915378954\t avg steps: 136.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40839\t average reward: -77.50371370695476\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40849\t average reward: -67.0935085007728\t avg steps: 130.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40859\t average reward: -74.91337491337491\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40869\t average reward: -68.29380664652568\t avg steps: 133.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40879\t average reward: -78.01126573889994\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40889\t average reward: -77.72574123989219\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40899\t average reward: -70.29955290611028\t avg steps: 135.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40909\t average reward: -73.48079658605974\t avg steps: 141.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40919\t average reward: -62.70751633986928\t avg steps: 123.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40929\t average reward: -77.99128686327077\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40939\t average reward: -78.04467805519054\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40949\t average reward: -66.91035548686244\t avg steps: 130.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40959\t average reward: -75.49268292682927\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40969\t average reward: -71.04264705882353\t avg steps: 137.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40979\t average reward: -74.86763686763686\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40989\t average reward: -74.26126126126127\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 40999\t average reward: -73.57551896921976\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41009\t average reward: -68.7022086824067\t avg steps: 132.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41019\t average reward: -72.44040697674419\t avg steps: 138.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41029\t average reward: -70.67380073800739\t avg steps: 136.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41039\t average reward: -69.61429635145197\t avg steps: 135.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41049\t average reward: -73.38224767358625\t avg steps: 140.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41059\t average reward: -68.8103186646434\t avg steps: 132.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41069\t average reward: -74.11777150916784\t avg steps: 142.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41079\t average reward: -76.19123783031989\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41089\t average reward: -78.10434782608695\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41099\t average reward: -71.03723008190617\t avg steps: 135.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41109\t average reward: -73.85381355932203\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 41119\t average reward: -68.79422930903569\t avg steps: 132.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41129\t average reward: -66.57098283931357\t avg steps: 129.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41139\t average reward: -77.91716368455931\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41149\t average reward: -77.00816882232812\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41159\t average reward: -68.78201219512195\t avg steps: 132.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41169\t average reward: -74.54690757470466\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41179\t average reward: -60.140797285835454\t avg steps: 118.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41189\t average reward: -73.32408759124088\t avg steps: 138.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41199\t average reward: -72.95667870036101\t avg steps: 139.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41209\t average reward: -69.93721633888049\t avg steps: 133.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41219\t average reward: -70.30786350148368\t avg steps: 135.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41229\t average reward: -70.35555555555555\t avg steps: 136.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41239\t average reward: -65.35438042620363\t avg steps: 127.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41249\t average reward: -77.51403743315508\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41259\t average reward: -70.13803230543319\t avg steps: 137.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41269\t average reward: -73.7231638418079\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41279\t average reward: -69.08039068369646\t avg steps: 134.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41289\t average reward: -72.80709219858156\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41299\t average reward: -73.8805340829234\t avg steps: 143.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41309\t average reward: -73.28186453022579\t avg steps: 138.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41319\t average reward: -68.95030120481928\t avg steps: 133.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41329\t average reward: -70.64259395725865\t avg steps: 136.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41339\t average reward: -70.17717717717717\t avg steps: 134.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41349\t average reward: -71.18791451731761\t avg steps: 136.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41359\t average reward: -81.73055028462998\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41369\t average reward: -71.61449275362318\t avg steps: 139.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41379\t average reward: -65.6267716535433\t avg steps: 128.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41389\t average reward: -71.90537634408602\t avg steps: 140.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41399\t average reward: -72.4396551724138\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41409\t average reward: -74.88639551192146\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41419\t average reward: -68.56067588325652\t avg steps: 131.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41429\t average reward: -75.14275862068966\t avg steps: 146.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41439\t average reward: -73.16195190947666\t avg steps: 142.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41449\t average reward: -80.79845460399227\t avg steps: 156.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41459\t average reward: -79.47619047619048\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41469\t average reward: -70.1453744493392\t avg steps: 137.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41479\t average reward: -64.15954875100725\t avg steps: 125.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41489\t average reward: -68.30704441041348\t avg steps: 131.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41499\t average reward: -71.84487734487735\t avg steps: 139.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41509\t average reward: -78.24881033310673\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41519\t average reward: -73.60284697508897\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41529\t average reward: -72.41386861313869\t avg steps: 138.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41539\t average reward: -74.89198855507868\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41549\t average reward: -72.15290739411343\t avg steps: 140.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41559\t average reward: -79.83661417322834\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41569\t average reward: -70.74207811348563\t avg steps: 136.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41579\t average reward: -66.46884735202492\t avg steps: 129.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41589\t average reward: -72.98376852505292\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41599\t average reward: -65.31637519872814\t avg steps: 126.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41609\t average reward: -70.04098360655738\t avg steps: 135.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41619\t average reward: -65.42722265932336\t avg steps: 128.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41629\t average reward: -77.33261494252874\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41639\t average reward: -68.9849510910459\t avg steps: 133.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41649\t average reward: -67.31664098613251\t avg steps: 130.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41659\t average reward: -69.90692479523454\t avg steps: 135.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41669\t average reward: -68.95037593984962\t avg steps: 134.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41679\t average reward: -72.005772005772\t avg steps: 139.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41689\t average reward: -70.22991071428571\t avg steps: 135.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41699\t average reward: -77.6156394963552\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41709\t average reward: -70.18442932728647\t avg steps: 133.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41719\t average reward: -68.44402420574886\t avg steps: 133.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41729\t average reward: -73.47125621007807\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41739\t average reward: -80.50880626223092\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41749\t average reward: -72.88420300214439\t avg steps: 140.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41759\t average reward: -77.28666666666666\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41769\t average reward: -67.49730976172175\t avg steps: 131.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41779\t average reward: -73.67021276595744\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41789\t average reward: -68.19454958364875\t avg steps: 133.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41799\t average reward: -70.86183719193428\t avg steps: 134.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41809\t average reward: -67.61585835257891\t avg steps: 130.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41819\t average reward: -66.9032507739938\t avg steps: 130.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41829\t average reward: -66.45553822152885\t avg steps: 129.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41839\t average reward: -75.10589060308556\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41849\t average reward: -72.84582743988685\t avg steps: 142.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41859\t average reward: -67.01467181467181\t avg steps: 130.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41869\t average reward: -59.60613810741688\t avg steps: 118.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41879\t average reward: -69.65430267062314\t avg steps: 135.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41889\t average reward: -72.2275664034458\t avg steps: 140.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41899\t average reward: -77.62135922330097\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41909\t average reward: -73.69105113636364\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41919\t average reward: -72.37383845604003\t avg steps: 140.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41929\t average reward: -74.13310104529617\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41939\t average reward: -78.0127345844504\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41949\t average reward: -71.50757029560202\t avg steps: 139.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41959\t average reward: -73.83017543859648\t avg steps: 143.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41969\t average reward: -70.47524020694752\t avg steps: 136.3\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 41979\t average reward: -69.4810408921933\t avg steps: 135.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41989\t average reward: -68.65399239543726\t avg steps: 132.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 41999\t average reward: -75.07268877911079\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42009\t average reward: -69.69821162444113\t avg steps: 135.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42019\t average reward: -75.65578231292517\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42029\t average reward: -66.7919254658385\t avg steps: 129.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42039\t average reward: -72.72838616714698\t avg steps: 139.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42049\t average reward: -68.20789074355083\t avg steps: 132.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42059\t average reward: -69.65952732644018\t avg steps: 136.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42069\t average reward: -67.66946564885497\t avg steps: 132.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42079\t average reward: -68.01370906321401\t avg steps: 132.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42089\t average reward: -68.68609865470852\t avg steps: 134.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42099\t average reward: -68.08883826879271\t avg steps: 132.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42109\t average reward: -73.71448763250883\t avg steps: 142.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42119\t average reward: -75.1591382904795\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42129\t average reward: -72.19812002892263\t avg steps: 139.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42139\t average reward: -65.11137440758294\t avg steps: 127.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42149\t average reward: -68.07261724659607\t avg steps: 133.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42159\t average reward: -72.85103349964362\t avg steps: 141.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42169\t average reward: -64.8967434471803\t avg steps: 126.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42179\t average reward: -67.16991426344505\t avg steps: 129.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42189\t average reward: -81.34210526315789\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42199\t average reward: -69.63146067415731\t avg steps: 134.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42209\t average reward: -74.83573883161512\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42219\t average reward: -80.80970873786407\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42229\t average reward: -79.84507978723404\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42239\t average reward: -83.15025906735751\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42249\t average reward: -70.45132743362832\t avg steps: 136.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42259\t average reward: -74.96805555555555\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42269\t average reward: -77.84635938543754\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42279\t average reward: -71.44014869888476\t avg steps: 135.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42289\t average reward: -84.80579531442663\t avg steps: 163.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42299\t average reward: -81.43177323665128\t avg steps: 152.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42309\t average reward: -75.5847871598046\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42319\t average reward: -71.37745454545454\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42329\t average reward: -68.6420972644377\t avg steps: 132.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42339\t average reward: -68.54915514592933\t avg steps: 131.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42349\t average reward: -63.97323600973236\t avg steps: 124.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42359\t average reward: -70.75430711610487\t avg steps: 134.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42369\t average reward: -73.63307310149042\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42379\t average reward: -67.52080123266563\t avg steps: 130.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42389\t average reward: -76.40902679830748\t avg steps: 142.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42399\t average reward: -75.51420454545455\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42409\t average reward: -77.58025520483547\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42419\t average reward: -88.76539589442815\t avg steps: 171.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42429\t average reward: -74.96413199426112\t avg steps: 140.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42439\t average reward: -81.67603833865815\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42449\t average reward: -82.2479233226837\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42459\t average reward: -75.654157468727\t avg steps: 136.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42469\t average reward: -76.21418826739426\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42479\t average reward: -79.24497991967871\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42489\t average reward: -80.112285336856\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42499\t average reward: -65.01869918699187\t avg steps: 124.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42509\t average reward: -73.71469740634005\t avg steps: 139.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42519\t average reward: -69.4297520661157\t avg steps: 134.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42529\t average reward: -83.69889162561576\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42539\t average reward: -74.70161857846587\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42549\t average reward: -74.19971771347919\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42559\t average reward: -85.41976047904191\t avg steps: 168.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42569\t average reward: -75.09065155807366\t avg steps: 142.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42579\t average reward: -74.14194915254237\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42589\t average reward: -66.99922360248448\t avg steps: 129.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42599\t average reward: -61.83986655546288\t avg steps: 120.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42609\t average reward: -68.48892284186402\t avg steps: 131.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42619\t average reward: -64.5016155088853\t avg steps: 124.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42629\t average reward: -79.57189973614776\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42639\t average reward: -75.64449064449065\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42649\t average reward: -71.87463556851311\t avg steps: 138.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42659\t average reward: -92.2760736196319\t avg steps: 180.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42669\t average reward: -75.87068381855111\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42679\t average reward: -76.88005483207677\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42689\t average reward: -78.37738419618529\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42699\t average reward: -77.76819407008087\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42709\t average reward: -93.16620651573716\t avg steps: 182.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42719\t average reward: -80.8272181454303\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42729\t average reward: -77.4099590723056\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42739\t average reward: -77.4648382559775\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42749\t average reward: -72.52221412964312\t avg steps: 138.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42759\t average reward: -75.08380681818181\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42769\t average reward: -74.291782729805\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42779\t average reward: -70.4167916041979\t avg steps: 134.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42789\t average reward: -72.11622807017544\t avg steps: 137.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42799\t average reward: -73.89964157706093\t avg steps: 140.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42809\t average reward: -76.62648083623694\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42819\t average reward: -91.58385446276293\t avg steps: 176.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42829\t average reward: -65.63512429831596\t avg steps: 125.7\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 42839\t average reward: -82.7230376515635\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42849\t average reward: -85.78373493975904\t avg steps: 167.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42859\t average reward: -75.72746628814762\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42869\t average reward: -63.046744574290486\t avg steps: 120.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42879\t average reward: -79.76205997392438\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42889\t average reward: -83.07770700636942\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42899\t average reward: -79.9953642384106\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42909\t average reward: -76.70604781997187\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42919\t average reward: -69.55623565416985\t avg steps: 131.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42929\t average reward: -79.57415254237289\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42939\t average reward: -74.56832971800434\t avg steps: 139.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42949\t average reward: -66.27522195318805\t avg steps: 124.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42959\t average reward: -69.4168547780286\t avg steps: 133.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42969\t average reward: -76.48569434752268\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42979\t average reward: -87.0373269114991\t avg steps: 167.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42989\t average reward: -70.58952959028832\t avg steps: 132.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 42999\t average reward: -81.56012861736335\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43009\t average reward: -76.94568245125348\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43019\t average reward: -83.19541693189052\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43029\t average reward: -80.92217135382603\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43039\t average reward: -80.93830334190231\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43049\t average reward: -83.58642363293527\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43059\t average reward: -76.53808864265928\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43069\t average reward: -78.54472091459314\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43079\t average reward: -61.48040033361134\t avg steps: 120.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43089\t average reward: -80.66951942067149\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43099\t average reward: -75.38881019830028\t avg steps: 142.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43109\t average reward: -57.71553994732221\t avg steps: 114.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43119\t average reward: -77.16287094547964\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43129\t average reward: -61.74590163934426\t avg steps: 123.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43139\t average reward: -82.30407124681933\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43149\t average reward: -85.37196601941747\t avg steps: 165.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43159\t average reward: -72.75471698113208\t avg steps: 138.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43169\t average reward: -57.17579505300353\t avg steps: 114.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43179\t average reward: -61.8671679197995\t avg steps: 120.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43189\t average reward: -67.08281733746131\t avg steps: 130.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43199\t average reward: -74.08279337652988\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43209\t average reward: -65.25457438345266\t avg steps: 126.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43219\t average reward: -76.48218029350105\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43229\t average reward: -62.78360655737705\t avg steps: 123.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43239\t average reward: -70.1196388261851\t avg steps: 133.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43249\t average reward: -62.637622149837135\t avg steps: 123.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43259\t average reward: -72.86373467916366\t avg steps: 139.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43269\t average reward: -61.83445378151261\t avg steps: 120.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43279\t average reward: -70.12509307520476\t avg steps: 135.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43289\t average reward: -71.2800586510264\t avg steps: 137.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43299\t average reward: -63.35004108463435\t avg steps: 122.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43309\t average reward: -68.63085188027628\t avg steps: 131.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43319\t average reward: -58.22406277244987\t avg steps: 115.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43329\t average reward: -77.5774456521739\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43339\t average reward: -65.87421383647799\t avg steps: 128.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43349\t average reward: -69.60964230171074\t avg steps: 129.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43359\t average reward: -65.99033037872684\t avg steps: 125.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43369\t average reward: -69.9341408024224\t avg steps: 133.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43379\t average reward: -72.54730713245998\t avg steps: 138.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43389\t average reward: -67.78012519561815\t avg steps: 128.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43399\t average reward: -68.66718995290424\t avg steps: 128.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43409\t average reward: -69.16370656370657\t avg steps: 130.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43419\t average reward: -60.60953177257525\t avg steps: 120.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43429\t average reward: -66.35697399527187\t avg steps: 127.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43439\t average reward: -64.2553017944535\t avg steps: 123.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43449\t average reward: -66.82170542635659\t avg steps: 130.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43459\t average reward: -77.2324774462179\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43469\t average reward: -76.24860335195531\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43479\t average reward: -69.80015197568389\t avg steps: 132.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43489\t average reward: -71.34001484780995\t avg steps: 135.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43499\t average reward: -67.64444444444445\t avg steps: 127.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43509\t average reward: -64.52931596091206\t avg steps: 123.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43519\t average reward: -65.21238938053098\t avg steps: 125.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43529\t average reward: -65.76133651551312\t avg steps: 126.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43539\t average reward: -63.552845528455286\t avg steps: 124.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43549\t average reward: -73.48991354466858\t avg steps: 139.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43559\t average reward: -76.96957403651116\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43569\t average reward: -64.53516572352466\t avg steps: 124.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43579\t average reward: -61.90725126475548\t avg steps: 119.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43589\t average reward: -61.96697713801863\t avg steps: 119.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43599\t average reward: -83.72405220633934\t avg steps: 161.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43609\t average reward: -65.36604987932422\t avg steps: 125.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43619\t average reward: -73.57534246575342\t avg steps: 139.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43629\t average reward: -63.18319327731093\t avg steps: 120.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43639\t average reward: -74.31709039548022\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43649\t average reward: -60.3862660944206\t avg steps: 117.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43659\t average reward: -76.54033379694019\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43669\t average reward: -64.04780876494024\t avg steps: 126.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43679\t average reward: -81.23460790667531\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43689\t average reward: -69.51798010711553\t avg steps: 131.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43699\t average reward: -65.55564451561249\t avg steps: 125.9\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 43709\t average reward: -69.05167173252279\t avg steps: 132.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43719\t average reward: -73.13163636363636\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43729\t average reward: -61.9635761589404\t avg steps: 121.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43739\t average reward: -75.57102473498233\t avg steps: 142.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43749\t average reward: -68.82194934765924\t avg steps: 131.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43759\t average reward: -75.05911330049261\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43769\t average reward: -68.10355486862441\t avg steps: 130.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43779\t average reward: -81.86722797927462\t avg steps: 155.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43789\t average reward: -68.78056188306758\t avg steps: 132.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43799\t average reward: -68.24750957854405\t avg steps: 131.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43809\t average reward: -75.20446364290856\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43819\t average reward: -72.23293768545994\t avg steps: 135.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43829\t average reward: -63.90422077922078\t avg steps: 124.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43839\t average reward: -71.40135033758439\t avg steps: 134.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43849\t average reward: -64.00243902439024\t avg steps: 124.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43859\t average reward: -61.17899159663865\t avg steps: 120.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43869\t average reward: -61.492753623188406\t avg steps: 118.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43879\t average reward: -70.21072226358898\t avg steps: 135.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43889\t average reward: -62.10517666392769\t avg steps: 122.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43899\t average reward: -67.57334384858044\t avg steps: 127.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43909\t average reward: -71.52682563338301\t avg steps: 135.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43919\t average reward: -63.17416189697465\t avg steps: 123.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43929\t average reward: -61.591750841750844\t avg steps: 119.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43939\t average reward: -74.5343347639485\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43949\t average reward: -73.41619718309859\t avg steps: 143.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43959\t average reward: -65.81046788263284\t avg steps: 127.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43969\t average reward: -61.18549747048904\t avg steps: 119.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43979\t average reward: -75.98588567395907\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43989\t average reward: -69.71732522796353\t avg steps: 132.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 43999\t average reward: -70.59037037037037\t avg steps: 136.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44009\t average reward: -69.43811693242218\t avg steps: 132.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44019\t average reward: -61.39662447257384\t avg steps: 119.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44029\t average reward: -66.44392156862745\t avg steps: 128.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44039\t average reward: -66.03027888446215\t avg steps: 126.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44049\t average reward: -60.86347826086956\t avg steps: 116.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44059\t average reward: -66.62616099071208\t avg steps: 130.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44069\t average reward: -62.553104575163395\t avg steps: 123.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44079\t average reward: -65.3706965572458\t avg steps: 125.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44089\t average reward: -70.67991004497752\t avg steps: 134.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44099\t average reward: -72.08733624454149\t avg steps: 138.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44109\t average reward: -82.40167633784655\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44119\t average reward: -68.23938223938224\t avg steps: 130.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44129\t average reward: -73.29797979797979\t avg steps: 139.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44139\t average reward: -69.19954819277109\t avg steps: 133.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44149\t average reward: -65.18124006359301\t avg steps: 126.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44159\t average reward: -70.38536953242836\t avg steps: 133.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44169\t average reward: -68.82059046177139\t avg steps: 133.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44179\t average reward: -82.50221659278024\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44189\t average reward: -75.59958217270194\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44199\t average reward: -74.92248062015504\t avg steps: 142.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44209\t average reward: -65.63571428571429\t avg steps: 127.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44219\t average reward: -75.04404679972471\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44229\t average reward: -74.03218884120172\t avg steps: 140.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44239\t average reward: -71.19898329702251\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44249\t average reward: -78.02830188679245\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44259\t average reward: -71.46711012564671\t avg steps: 136.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44269\t average reward: -75.57035003431709\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44279\t average reward: -56.23264201983769\t avg steps: 111.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44289\t average reward: -64.5163666121113\t avg steps: 123.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44299\t average reward: -68.57490494296577\t avg steps: 132.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44309\t average reward: -75.70111731843575\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44319\t average reward: -70.00738007380073\t avg steps: 136.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44329\t average reward: -69.17960426179604\t avg steps: 132.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44339\t average reward: -76.74791666666667\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44349\t average reward: -60.39637305699482\t avg steps: 116.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44359\t average reward: -77.81171548117155\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44369\t average reward: -67.2871835443038\t avg steps: 127.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44379\t average reward: -61.35117056856188\t avg steps: 120.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44389\t average reward: -60.85204081632653\t avg steps: 118.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44399\t average reward: -67.45839753466872\t avg steps: 130.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44409\t average reward: -76.02367288378767\t avg steps: 140.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44419\t average reward: -68.88820826952526\t avg steps: 131.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44429\t average reward: -60.33901192504259\t avg steps: 118.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44439\t average reward: -55.59981684981685\t avg steps: 110.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44449\t average reward: -55.74611872146119\t avg steps: 110.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44459\t average reward: -65.95843325339729\t avg steps: 126.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44469\t average reward: -65.22948207171315\t avg steps: 126.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44479\t average reward: -69.51874062968515\t avg steps: 134.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44489\t average reward: -70.51988217967599\t avg steps: 136.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44499\t average reward: -72.4546783625731\t avg steps: 137.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44509\t average reward: -64.36706827309237\t avg steps: 125.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44519\t average reward: -60.73027989821883\t avg steps: 118.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44529\t average reward: -73.13280689160086\t avg steps: 140.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44539\t average reward: -75.14315642458101\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44549\t average reward: -76.29916897506925\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44559\t average reward: -75.79432132963989\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 44569\t average reward: -71.01490312965723\t avg steps: 135.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44579\t average reward: -70.47067557535263\t avg steps: 135.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44589\t average reward: -68.3216995447648\t avg steps: 132.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44599\t average reward: -80.50839793281654\t avg steps: 155.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44609\t average reward: -77.34794520547945\t avg steps: 147.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44619\t average reward: -77.13445945945946\t avg steps: 149.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44629\t average reward: -65.31633466135459\t avg steps: 126.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44639\t average reward: -76.48168624740843\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44649\t average reward: -78.10187667560322\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44659\t average reward: -61.11392405063291\t avg steps: 119.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44669\t average reward: -68.71230769230769\t avg steps: 131.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44679\t average reward: -75.57924263674614\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44689\t average reward: -73.16220130340334\t avg steps: 139.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44699\t average reward: -70.79088277858176\t avg steps: 139.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44709\t average reward: -54.50837988826816\t avg steps: 108.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44719\t average reward: -66.46251993620415\t avg steps: 126.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44729\t average reward: -58.306748466257666\t avg steps: 115.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44739\t average reward: -59.703508771929826\t avg steps: 115.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44749\t average reward: -75.60082872928177\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44759\t average reward: -71.86969253294289\t avg steps: 137.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44769\t average reward: -62.35831960461285\t avg steps: 122.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44779\t average reward: -67.35458786936236\t avg steps: 129.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44789\t average reward: -57.74381625441696\t avg steps: 114.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44799\t average reward: -62.9641401792991\t avg steps: 123.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44809\t average reward: -66.09826589595376\t avg steps: 122.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44819\t average reward: -65.85403225806452\t avg steps: 125.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44829\t average reward: -57.242692648361384\t avg steps: 113.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44839\t average reward: -58.276350752878656\t avg steps: 113.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44849\t average reward: -63.86067600989283\t avg steps: 122.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44859\t average reward: -67.42734375\t avg steps: 129.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44869\t average reward: -62.6878612716763\t avg steps: 122.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44879\t average reward: -56.40847610459874\t avg steps: 111.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44889\t average reward: -69.40622627182992\t avg steps: 132.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44899\t average reward: -72.31054545454545\t avg steps: 138.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44909\t average reward: -70.90090771558245\t avg steps: 133.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44919\t average reward: -66.67160686427457\t avg steps: 129.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44929\t average reward: -55.95656108597285\t avg steps: 111.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44939\t average reward: -59.076449912126535\t avg steps: 114.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44949\t average reward: -66.10862619808307\t avg steps: 126.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44959\t average reward: -58.75152041702867\t avg steps: 116.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44969\t average reward: -70.10373760488177\t avg steps: 132.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44979\t average reward: -67.56877897990726\t avg steps: 130.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44989\t average reward: -68.67112509834776\t avg steps: 128.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 44999\t average reward: -62.84798685291701\t avg steps: 122.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45009\t average reward: -65.83094098883572\t avg steps: 126.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45019\t average reward: -58.37688888888889\t avg steps: 113.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45029\t average reward: -72.52064896755162\t avg steps: 136.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45039\t average reward: -66.92301649646504\t avg steps: 128.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45049\t average reward: -62.87911184210526\t avg steps: 122.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45059\t average reward: -74.63770250368188\t avg steps: 136.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45069\t average reward: -74.07997065297138\t avg steps: 137.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45079\t average reward: -53.859848484848484\t avg steps: 106.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45089\t average reward: -66.92234548335975\t avg steps: 127.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45099\t average reward: -76.83321554770318\t avg steps: 142.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45109\t average reward: -68.5795631825273\t avg steps: 129.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45119\t average reward: -66.75856697819314\t avg steps: 129.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45129\t average reward: -61.87479131886477\t avg steps: 120.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45139\t average reward: -63.260149130074566\t avg steps: 121.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45149\t average reward: -73.06062767475035\t avg steps: 141.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45159\t average reward: -76.62286931818181\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45169\t average reward: -58.45847750865052\t avg steps: 116.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45179\t average reward: -59.473099914602905\t avg steps: 118.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45189\t average reward: -57.685534591194966\t avg steps: 112.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45199\t average reward: -71.87211895910781\t avg steps: 135.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45209\t average reward: -59.669291338582674\t avg steps: 115.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45219\t average reward: -65.95945945945945\t avg steps: 126.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45229\t average reward: -60.76724137931034\t avg steps: 117.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45239\t average reward: -68.057344854674\t avg steps: 128.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45249\t average reward: -68.52668759811617\t avg steps: 128.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45259\t average reward: -60.27863247863248\t avg steps: 118.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45269\t average reward: -67.07861635220125\t avg steps: 128.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45279\t average reward: -66.76003210272873\t avg steps: 125.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45289\t average reward: -69.22213740458015\t avg steps: 132.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45299\t average reward: -69.25652841781874\t avg steps: 131.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45309\t average reward: -76.73143650242886\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45319\t average reward: -70.56724267468068\t avg steps: 134.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45329\t average reward: -72.55628177196805\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45339\t average reward: -72.11853448275862\t avg steps: 140.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45349\t average reward: -75.82198246797033\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45359\t average reward: -69.94744744744744\t avg steps: 134.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45369\t average reward: -76.15400134498991\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45379\t average reward: -74.12986111111111\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45389\t average reward: -70.25846833578792\t avg steps: 136.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45399\t average reward: -73.58142758142758\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45409\t average reward: -75.6588471849866\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45419\t average reward: -72.13195435092724\t avg steps: 141.2\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 45429\t average reward: -74.0321004884857\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45439\t average reward: -68.70428893905192\t avg steps: 133.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45449\t average reward: -78.90543130990416\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45459\t average reward: -71.42908309455588\t avg steps: 140.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45469\t average reward: -71.7971119133574\t avg steps: 139.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45479\t average reward: -75.26004084411164\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45489\t average reward: -75.74982911825018\t avg steps: 147.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45499\t average reward: -78.7797619047619\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45509\t average reward: -78.08144796380091\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45519\t average reward: -80.2784090909091\t avg steps: 159.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45529\t average reward: -79.56822549647661\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45539\t average reward: -77.51876234364714\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45549\t average reward: -71.64457392571012\t avg steps: 138.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45559\t average reward: -74.38424657534246\t avg steps: 147.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45569\t average reward: -73.9841488628532\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45579\t average reward: -72.43890449438203\t avg steps: 143.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45589\t average reward: -73.9553264604811\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45599\t average reward: -69.50521609538004\t avg steps: 135.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45609\t average reward: -75.8695652173913\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45619\t average reward: -73.15179198875614\t avg steps: 143.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45629\t average reward: -73.35575589459084\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45639\t average reward: -77.7292490118577\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45649\t average reward: -76.42819148936171\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45659\t average reward: -73.2970159611381\t avg steps: 145.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45669\t average reward: -75.9334229993275\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45679\t average reward: -74.32140399174122\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45689\t average reward: -77.67488643737832\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45699\t average reward: -81.92118226600985\t avg steps: 163.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45709\t average reward: -80.52441344324667\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45719\t average reward: -80.60609911054638\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45729\t average reward: -80.86154814348647\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45739\t average reward: -78.69712793733682\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45749\t average reward: -72.73799435028249\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45759\t average reward: -79.72250639386189\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45769\t average reward: -75.26237288135593\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45779\t average reward: -72.95345557122708\t avg steps: 142.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45789\t average reward: -78.25632706035042\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45799\t average reward: -78.7247119078105\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45809\t average reward: -76.77376171352076\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45819\t average reward: -78.42699545749514\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45829\t average reward: -82.7958561852529\t avg steps: 165.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45839\t average reward: -75.1347615756738\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45849\t average reward: -81.6894835096453\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45859\t average reward: -76.45016501650166\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45869\t average reward: -80.03182686187142\t avg steps: 158.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45879\t average reward: -80.03846153846153\t avg steps: 159.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45889\t average reward: -84.12590361445783\t avg steps: 167.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45899\t average reward: -78.13668600902643\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45909\t average reward: -78.02408854166667\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45919\t average reward: -79.05534105534106\t avg steps: 156.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45929\t average reward: -71.98494623655914\t avg steps: 140.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45939\t average reward: -79.1764331210191\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45949\t average reward: -76.07278911564626\t avg steps: 148.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45959\t average reward: -85.5979809976247\t avg steps: 169.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45969\t average reward: -80.8411214953271\t avg steps: 161.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45979\t average reward: -78.05208333333333\t avg steps: 154.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45989\t average reward: -73.92906815020862\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 45999\t average reward: -78.34692556634305\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46009\t average reward: -78.98019169329073\t avg steps: 157.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46019\t average reward: -77.8713259307642\t avg steps: 154.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46029\t average reward: -79.35241730279898\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46039\t average reward: -81.01617921593031\t avg steps: 161.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46049\t average reward: -76.68175765645806\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46059\t average reward: -76.14333556597455\t avg steps: 150.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46069\t average reward: -76.33734939759036\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46079\t average reward: -79.99619530754597\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46089\t average reward: -80.33793969849246\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46099\t average reward: -80.7738246505718\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46109\t average reward: -77.65228758169934\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46119\t average reward: -80.25914249684742\t avg steps: 159.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46129\t average reward: -78.78092783505154\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46139\t average reward: -79.42312579415501\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46149\t average reward: -81.55816831683168\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46159\t average reward: -81.26149068322981\t avg steps: 162.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46169\t average reward: -77.8755700325733\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46179\t average reward: -79.98612862547289\t avg steps: 159.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46189\t average reward: -79.68884664131812\t avg steps: 158.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46199\t average reward: -80.48997493734336\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46209\t average reward: -76.16834339369551\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46219\t average reward: -74.54651162790698\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46229\t average reward: -76.98283828382839\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46239\t average reward: -78.21231979030144\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46249\t average reward: -80.14946168461051\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46259\t average reward: -79.95256166982922\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46269\t average reward: -81.94591194968554\t avg steps: 160.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46279\t average reward: -78.17662337662338\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 46289\t average reward: -76.96893588896232\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46299\t average reward: -74.77754820936639\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46309\t average reward: -79.88164556962025\t avg steps: 159.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46319\t average reward: -81.52230483271376\t avg steps: 162.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46329\t average reward: -77.99288486416559\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46339\t average reward: -76.82939632545931\t avg steps: 153.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46349\t average reward: -79.90192307692308\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46359\t average reward: -73.9126213592233\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46369\t average reward: -77.54586857514639\t avg steps: 154.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46379\t average reward: -77.92043984476068\t avg steps: 155.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46389\t average reward: -81.90998766954377\t avg steps: 163.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46399\t average reward: -80.46992481203007\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46409\t average reward: -79.49714648065948\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46419\t average reward: -78.97894065092534\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46429\t average reward: -78.24306898774984\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46439\t average reward: -79.08035714285714\t avg steps: 157.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46449\t average reward: -80.86525265127885\t avg steps: 161.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46459\t average reward: -79.83428209993674\t avg steps: 159.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46469\t average reward: -83.26727272727273\t avg steps: 166.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46479\t average reward: -79.60291323622546\t avg steps: 158.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46489\t average reward: -81.24689054726367\t avg steps: 161.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46499\t average reward: -79.41968253968254\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46509\t average reward: -72.8973277074543\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46519\t average reward: -75.83288409703503\t avg steps: 149.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46529\t average reward: -72.53111739745403\t avg steps: 142.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46539\t average reward: -73.20931849791377\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46549\t average reward: -80.22208121827411\t avg steps: 158.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46559\t average reward: -77.96767937944408\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46569\t average reward: -75.7575962187711\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46579\t average reward: -80.67422810333963\t avg steps: 159.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46589\t average reward: -75.20626276378489\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46599\t average reward: -77.7587574355585\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46609\t average reward: -79.23635195889531\t avg steps: 156.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46619\t average reward: -78.75435203094777\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46629\t average reward: -80.25502512562814\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46639\t average reward: -79.62833545108005\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46649\t average reward: -79.50792644261256\t avg steps: 158.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46659\t average reward: -77.4874835309618\t avg steps: 152.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46669\t average reward: -75.20488466757124\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46679\t average reward: -79.22229299363057\t avg steps: 158.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46689\t average reward: -83.17661847894406\t avg steps: 160.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46699\t average reward: -78.88554987212277\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46709\t average reward: -77.59389213775178\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46719\t average reward: -77.57394136807818\t avg steps: 154.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46729\t average reward: -82.87202925045703\t avg steps: 165.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46739\t average reward: -80.92857142857143\t avg steps: 160.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46749\t average reward: -79.13892445582586\t avg steps: 157.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46759\t average reward: -81.48452970297029\t avg steps: 162.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46769\t average reward: -78.44408740359897\t avg steps: 156.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46779\t average reward: -79.02873563218391\t avg steps: 157.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46789\t average reward: -84.49605821710128\t avg steps: 165.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46799\t average reward: -83.1006670709521\t avg steps: 165.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46809\t average reward: -82.50733496332518\t avg steps: 164.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46819\t average reward: -84.44404113732607\t avg steps: 166.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46829\t average reward: -78.76655948553055\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46839\t average reward: -79.00255264837268\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46849\t average reward: -79.21351179094965\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46859\t average reward: -80.70875\t avg steps: 161.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46869\t average reward: -80.25235997482693\t avg steps: 159.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46879\t average reward: -76.46831220813876\t avg steps: 150.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46889\t average reward: -74.43956043956044\t avg steps: 146.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46899\t average reward: -78.33203631647211\t avg steps: 155.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46909\t average reward: -80.34108040201005\t avg steps: 160.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46919\t average reward: -79.2842574888464\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46929\t average reward: -78.81719050673509\t avg steps: 156.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46939\t average reward: -75.04928131416838\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46949\t average reward: -75.88836583725622\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46959\t average reward: -73.06188466947961\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46969\t average reward: -79.74399494310998\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46979\t average reward: -76.48537234042553\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46989\t average reward: -73.84854771784232\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 46999\t average reward: -75.72083614295347\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47009\t average reward: -77.7830065359477\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47019\t average reward: -73.8553633217993\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47029\t average reward: -72.90530035335689\t avg steps: 142.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47039\t average reward: -74.5615491009682\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47049\t average reward: -73.9447895100069\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47059\t average reward: -77.99217731421122\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47069\t average reward: -80.82674199623352\t avg steps: 160.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47079\t average reward: -80.01590330788804\t avg steps: 158.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47089\t average reward: -73.07197763801537\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47099\t average reward: -78.03326810176125\t avg steps: 154.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47109\t average reward: -79.90265486725664\t avg steps: 159.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47119\t average reward: -78.40232108317214\t avg steps: 156.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47129\t average reward: -79.09942638623328\t avg steps: 157.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47139\t average reward: -78.66946417043253\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 47149\t average reward: -78.94042280589366\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47159\t average reward: -79.3879365079365\t avg steps: 158.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47169\t average reward: -78.03102779573368\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47179\t average reward: -75.71124417831005\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47189\t average reward: -75.80735785953178\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47199\t average reward: -72.85594405594405\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47209\t average reward: -73.39623955431755\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47219\t average reward: -73.29647546648238\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47229\t average reward: -72.88440111420613\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47239\t average reward: -70.27545787545787\t avg steps: 137.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47249\t average reward: -75.63848202396804\t avg steps: 151.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47259\t average reward: -73.14295676429568\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47269\t average reward: -79.25384615384615\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47279\t average reward: -73.71814404432133\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47289\t average reward: -72.92922214435879\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47299\t average reward: -74.0485968514716\t avg steps: 147.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47309\t average reward: -76.9869109947644\t avg steps: 153.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47319\t average reward: -75.0607697501688\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47329\t average reward: -75.09127789046653\t avg steps: 148.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47339\t average reward: -78.20876288659794\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47349\t average reward: -77.77705767984446\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47359\t average reward: -78.25921137685843\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47369\t average reward: -75.41065407956845\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47379\t average reward: -71.99571122230165\t avg steps: 140.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47389\t average reward: -72.73916083916085\t avg steps: 144.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47399\t average reward: -73.81942544459645\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47409\t average reward: -78.89833759590793\t avg steps: 157.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47419\t average reward: -77.24655737704919\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47429\t average reward: -73.375173370319\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47439\t average reward: -71.40143369175627\t avg steps: 140.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47449\t average reward: -76.65374507227332\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47459\t average reward: -72.93653032440056\t avg steps: 142.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47469\t average reward: -73.10746685275646\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47479\t average reward: -74.80625424881033\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47489\t average reward: -78.28910891089109\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47499\t average reward: -73.15212840195395\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47509\t average reward: -76.02173913043478\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47519\t average reward: -77.67478604344964\t avg steps: 152.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47529\t average reward: -77.1281045751634\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47539\t average reward: -73.37561317449195\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47549\t average reward: -71.34250543084721\t avg steps: 139.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47559\t average reward: -74.3030095759234\t avg steps: 147.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47569\t average reward: -76.11059602649007\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47579\t average reward: -69.02007434944238\t avg steps: 135.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47589\t average reward: -74.15405777166437\t avg steps: 146.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47599\t average reward: -74.39427012278308\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47609\t average reward: -73.91638108293351\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47619\t average reward: -70.05113221329438\t avg steps: 137.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47629\t average reward: -74.22032742155525\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47639\t average reward: -72.7302032235459\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47649\t average reward: -70.81435823060188\t avg steps: 138.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47659\t average reward: -71.88002822865208\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47669\t average reward: -72.32321806633733\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47679\t average reward: -78.93569131832797\t avg steps: 156.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47689\t average reward: -79.25242091672047\t avg steps: 155.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47699\t average reward: -72.49509803921569\t avg steps: 143.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47709\t average reward: -71.52077363896848\t avg steps: 140.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47719\t average reward: -73.28720445062586\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47729\t average reward: -73.27000695894225\t avg steps: 144.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47739\t average reward: -80.01780038143674\t avg steps: 158.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47749\t average reward: -77.66120576671035\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47759\t average reward: -75.8578135479544\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47769\t average reward: -77.21090670170828\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47779\t average reward: -76.34832992501704\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47789\t average reward: -69.52810650887574\t avg steps: 136.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47799\t average reward: -74.15159944367177\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47809\t average reward: -77.43953185955787\t avg steps: 154.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47819\t average reward: -69.32693726937269\t avg steps: 136.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47829\t average reward: -79.07849393746011\t avg steps: 157.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47839\t average reward: -70.46165084002922\t avg steps: 137.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47849\t average reward: -73.4750346740638\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47859\t average reward: -69.56563421828909\t avg steps: 136.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47869\t average reward: -74.52073419442556\t avg steps: 148.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47879\t average reward: -72.45467322557977\t avg steps: 143.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47889\t average reward: -72.8787456445993\t avg steps: 144.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47899\t average reward: -74.55600814663951\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47909\t average reward: -74.99932523616734\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47919\t average reward: -76.9612097304405\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47929\t average reward: -73.58774948382657\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47939\t average reward: -76.20590207914151\t avg steps: 150.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47949\t average reward: -75.74949899799599\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47959\t average reward: -74.48165760869566\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47969\t average reward: -76.36675461741424\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47979\t average reward: -74.89631650750341\t avg steps: 147.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47989\t average reward: -80.54043887147336\t avg steps: 160.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 47999\t average reward: -73.89600550964187\t avg steps: 146.2\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 48009\t average reward: -77.15862524785194\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48019\t average reward: -78.41365979381443\t avg steps: 156.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48029\t average reward: -72.62991573033707\t avg steps: 143.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48039\t average reward: -74.87759336099585\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48049\t average reward: -75.14844804318489\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48059\t average reward: -75.87959866220736\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48069\t average reward: -71.65103056147832\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48079\t average reward: -75.28881355932204\t avg steps: 148.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48089\t average reward: -75.40080160320642\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48099\t average reward: -75.00402955003358\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48109\t average reward: -76.78726198292843\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48119\t average reward: -72.86880669923238\t avg steps: 144.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48129\t average reward: -78.19233268356075\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48139\t average reward: -77.46295081967213\t avg steps: 153.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48149\t average reward: -77.3070404172099\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48159\t average reward: -78.44841012329655\t avg steps: 155.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48169\t average reward: -78.63717948717948\t avg steps: 157.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48179\t average reward: -78.1025974025974\t avg steps: 155.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48189\t average reward: -75.85103540414161\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48199\t average reward: -73.33518005540166\t avg steps: 145.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48209\t average reward: -77.07717678100263\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48219\t average reward: -72.49611856033874\t avg steps: 142.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48229\t average reward: -75.7125748502994\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48239\t average reward: -75.61425716189207\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48249\t average reward: -76.20568783068784\t avg steps: 152.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48259\t average reward: -77.85418016850292\t avg steps: 155.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48269\t average reward: -80.94316052467208\t avg steps: 161.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48279\t average reward: -75.3937165775401\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48289\t average reward: -76.58684210526316\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48299\t average reward: -75.32486631016043\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48309\t average reward: -78.00646412411119\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48319\t average reward: -75.3836898395722\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48329\t average reward: -74.3170731707317\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48339\t average reward: -75.22021419009371\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48349\t average reward: -74.58879135719108\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48359\t average reward: -76.40396039603961\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48369\t average reward: -76.15298013245034\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48379\t average reward: -76.06295559973492\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48389\t average reward: -75.54133333333333\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48399\t average reward: -77.1462140992167\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48409\t average reward: -76.53092105263158\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48419\t average reward: -76.0317880794702\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48429\t average reward: -75.8074369189907\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48439\t average reward: -76.30870712401055\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48449\t average reward: -75.72140957446808\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48459\t average reward: -76.18638466622605\t avg steps: 152.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48469\t average reward: -75.71609042553192\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48479\t average reward: -76.68680236375575\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48489\t average reward: -76.8656618610747\t avg steps: 153.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48499\t average reward: -77.04313725490196\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48509\t average reward: -75.51733333333334\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48519\t average reward: -76.01258278145696\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48529\t average reward: -76.65177398160316\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48539\t average reward: -75.8472775564409\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48549\t average reward: -74.91061827956989\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48559\t average reward: -75.3190635451505\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48569\t average reward: -75.29698996655519\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48579\t average reward: -75.556\t avg steps: 151.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48589\t average reward: -75.59826782145237\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48599\t average reward: -75.27023411371238\t avg steps: 150.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48609\t average reward: -76.0523178807947\t avg steps: 152.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48619\t average reward: -76.28976897689769\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48629\t average reward: -76.54671052631579\t avg steps: 153.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48639\t average reward: -74.57123565158676\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48649\t average reward: -74.36763710223426\t avg steps: 148.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48659\t average reward: -75.56628914057295\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48669\t average reward: -75.66999334664006\t avg steps: 151.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48679\t average reward: -75.77142857142857\t avg steps: 151.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48689\t average reward: -75.86595885865958\t avg steps: 151.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48699\t average reward: -76.33377308707124\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48709\t average reward: -75.88844621513944\t avg steps: 151.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48719\t average reward: -75.73869680851064\t avg steps: 151.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48729\t average reward: -76.69033530571993\t avg steps: 153.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48739\t average reward: -77.97349709114415\t avg steps: 155.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48749\t average reward: -77.28487614080835\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48759\t average reward: -77.04251144538914\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48769\t average reward: -77.33050847457628\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48779\t average reward: -76.332892998679\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48789\t average reward: -74.91129032258064\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48799\t average reward: -74.77575757575758\t avg steps: 149.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48809\t average reward: -77.07450980392157\t avg steps: 154.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48819\t average reward: -76.00463883366469\t avg steps: 151.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48829\t average reward: -76.3036303630363\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48839\t average reward: -76.24834874504623\t avg steps: 152.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48849\t average reward: -76.77281680892975\t avg steps: 153.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48859\t average reward: -76.37994722955145\t avg steps: 152.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48869\t average reward: -74.96843519140363\t avg steps: 149.9\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 48879\t average reward: -74.34010840108401\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48889\t average reward: -73.72131147540983\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48899\t average reward: -74.18138586956522\t avg steps: 148.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48909\t average reward: -73.9550408719346\t avg steps: 147.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48919\t average reward: -74.16700610997964\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48929\t average reward: -73.87593728698023\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48939\t average reward: -74.27137042062415\t avg steps: 148.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48949\t average reward: -72.4394993045897\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48959\t average reward: -70.71632216678546\t avg steps: 141.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48969\t average reward: -73.20853406744666\t avg steps: 146.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48979\t average reward: -87.08464939987365\t avg steps: 159.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48989\t average reward: -73.32091097308489\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 48999\t average reward: -67.76568405139834\t avg steps: 133.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49009\t average reward: -72.05907172995781\t avg steps: 143.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49019\t average reward: -73.27605244996549\t avg steps: 145.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49029\t average reward: -71.53357142857143\t avg steps: 141.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49039\t average reward: -72.29515108924807\t avg steps: 143.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49049\t average reward: -73.95106822880771\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49059\t average reward: -68.89732142857143\t avg steps: 135.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49069\t average reward: -69.89132020423048\t avg steps: 138.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49079\t average reward: -75.2318339100346\t avg steps: 145.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49089\t average reward: -73.4741980474198\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49099\t average reward: -70.53188405797101\t avg steps: 139.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49109\t average reward: -71.35444839857651\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49119\t average reward: -73.22222222222223\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49129\t average reward: -71.54852624011502\t avg steps: 140.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49139\t average reward: -77.28943937418514\t avg steps: 154.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49149\t average reward: -79.42693773824651\t avg steps: 158.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49159\t average reward: -71.50960854092527\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49169\t average reward: -75.65350578624916\t avg steps: 147.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49179\t average reward: -74.34010840108401\t avg steps: 148.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49189\t average reward: -71.38220640569395\t avg steps: 141.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49199\t average reward: -77.66252452583387\t avg steps: 153.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49209\t average reward: -76.9592641261498\t avg steps: 153.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49219\t average reward: -70.05972323379461\t avg steps: 138.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49229\t average reward: -71.72163495419309\t avg steps: 142.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49239\t average reward: -71.90915697674419\t avg steps: 138.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49249\t average reward: -71.6531914893617\t avg steps: 142.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49259\t average reward: -73.87845303867404\t avg steps: 145.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49269\t average reward: -72.73254189944134\t avg steps: 144.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49279\t average reward: -77.83940620782727\t avg steps: 149.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49289\t average reward: -72.79846046186144\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49299\t average reward: -73.37569444444445\t avg steps: 145.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49309\t average reward: -73.07991660875608\t avg steps: 144.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49319\t average reward: -73.31859018659296\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49329\t average reward: -73.66735395189004\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49339\t average reward: -73.24464409122322\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49349\t average reward: -72.61791462561231\t avg steps: 143.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49359\t average reward: -81.15594541910332\t avg steps: 154.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49369\t average reward: -71.55610795454545\t avg steps: 141.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49379\t average reward: -77.93656957928802\t avg steps: 155.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49389\t average reward: -76.87295350360183\t avg steps: 153.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49399\t average reward: -77.15013054830287\t avg steps: 154.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49409\t average reward: -78.57335041639975\t avg steps: 157.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49419\t average reward: -71.8619957537155\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49429\t average reward: -70.9164265129683\t avg steps: 139.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49439\t average reward: -69.32100591715977\t avg steps: 136.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49449\t average reward: -72.30682617874736\t avg steps: 143.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49459\t average reward: -73.52515506547209\t avg steps: 146.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49469\t average reward: -75.71209084836339\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49479\t average reward: -75.04301075268818\t avg steps: 149.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49489\t average reward: -73.9923928077455\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49499\t average reward: -73.07345807345807\t avg steps: 145.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49509\t average reward: -75.1580013504389\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49519\t average reward: -70.92754662840746\t avg steps: 140.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49529\t average reward: -73.91547375596456\t avg steps: 147.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49539\t average reward: -73.40877437325905\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49549\t average reward: -75.39297771775827\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49559\t average reward: -70.06131386861314\t avg steps: 138.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49569\t average reward: -77.0990099009901\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49579\t average reward: -75.8103217158177\t avg steps: 150.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49589\t average reward: -76.56562291805463\t avg steps: 151.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49599\t average reward: -73.25984796129924\t avg steps: 145.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49609\t average reward: -72.74860724233983\t avg steps: 144.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49619\t average reward: -71.93630573248407\t avg steps: 142.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49629\t average reward: -75.22423025435073\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49639\t average reward: -75.4442217768871\t avg steps: 150.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49649\t average reward: -75.68661735036987\t avg steps: 149.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49659\t average reward: -73.31604426002767\t avg steps: 145.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49669\t average reward: -70.51619870410367\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49679\t average reward: -71.21454283657307\t avg steps: 139.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49689\t average reward: -71.2733761598858\t avg steps: 141.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49699\t average reward: -72.89308176100629\t avg steps: 144.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49709\t average reward: -71.63397299218195\t avg steps: 141.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49719\t average reward: -70.0072939460248\t avg steps: 138.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49729\t average reward: -73.47772446881426\t avg steps: 146.9\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 49739\t average reward: -75.399064171123\t avg steps: 150.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49749\t average reward: -72.06991525423729\t avg steps: 142.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49759\t average reward: -74.15953835709436\t avg steps: 148.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49769\t average reward: -70.45896877269426\t avg steps: 138.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49779\t average reward: -74.76429567642957\t avg steps: 144.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49789\t average reward: -69.97520058351569\t avg steps: 138.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49799\t average reward: -75.50803212851406\t avg steps: 150.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49809\t average reward: -73.49072164948454\t avg steps: 146.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49819\t average reward: -70.60057887120115\t avg steps: 139.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49829\t average reward: -72.4179523141655\t avg steps: 143.6\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49839\t average reward: -71.62810503903478\t avg steps: 141.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49849\t average reward: -72.66620305980528\t avg steps: 144.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49859\t average reward: -72.23826208829713\t avg steps: 143.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49869\t average reward: -73.79615648593\t avg steps: 146.7\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49879\t average reward: -71.85010706638116\t avg steps: 141.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49889\t average reward: -71.25843503230438\t avg steps: 140.3\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49899\t average reward: -76.48646864686468\t avg steps: 152.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49909\t average reward: -74.1714480874317\t avg steps: 147.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49919\t average reward: -73.02011095700416\t avg steps: 145.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49929\t average reward: -70.36666666666666\t avg steps: 139.0\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49939\t average reward: -71.94483734087694\t avg steps: 142.4\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49949\t average reward: -70.0430029154519\t avg steps: 138.2\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49959\t average reward: -69.9663988312637\t avg steps: 137.9\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49969\t average reward: -69.68055555555556\t avg steps: 137.8\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49979\t average reward: -77.2525320729237\t avg steps: 149.1\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49989\t average reward: -71.38853046594983\t avg steps: 140.5\t lr: 0.0005\t epsilon: 0.05\n",
      "episode: 49999\t average reward: -74.66891436277815\t avg steps: 149.3\t lr: 0.0005\t epsilon: 0.05\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _backend_agg: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18988\\3126524296.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_car\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[0m_pylab_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_active\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m     \u001b[0mallnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fignums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[0mnext_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallnums\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallnums\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;31m# If the manager explicitly overrides pyplot_show, use it even if a global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;31m# show is already present, as the latter may be here for backcompat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m     manager_class = getattr(getattr(backend_mod, \"FigureCanvas\", None),\n\u001b[0m\u001b[0;32m    327\u001b[0m                             \"manager_class\", None)\n\u001b[0;32m    328\u001b[0m     \u001b[1;31m# We can't compare directly manager_class.pyplot_show and FMB.pyplot_show because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m_warn_if_gui_out_of_main_thread\u001b[1;34m()\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_active\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                     \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m_get_backend_mod\u001b[1;34m()\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mSwitching\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteractive\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0monly\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mevent\u001b[0m \u001b[0mloop\u001b[0m \u001b[1;32mfor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0manother\u001b[0m \u001b[0minteractive\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mstarted\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mSwitching\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mfrom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[0mnon\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0minteractive\u001b[0m \u001b[0mbackends\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0malways\u001b[0m \u001b[0mpossible\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[1;34m(newbackend)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;31m# Classically, backends can directly export these functions.  This should\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# keep working for backcompat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m     \u001b[0mnew_figure_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_figure_manager\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"show\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbackend_mod\u001b[1;34m()\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# keep working for backcompat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[0mnew_figure_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_figure_manager\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"show\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;31m# In that classical approach, backends are implemented as modules, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib_inline\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_inline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"0.1.6\"\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_agg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend_agg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pylab_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBboxBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend_agg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRendererAgg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_RendererAgg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _backend_agg: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "# initialize size of state and action space\n",
    "state_space = 20 * 20\n",
    "action_space = env.action_space.n\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Training parameters\n",
    "n_training_episodes = 50000  # Total training episodes\n",
    "initial_lr = 0.2  # Learning rate       # old: 1\n",
    "k = 0.0005  # lr decay                    # old: 0.005\n",
    "min_lr = 0.0005\n",
    "\n",
    "\n",
    "# Environment parameters\n",
    "max_steps = 10000  # Max steps per episode\n",
    "gamma = 0.99  # Discounting rate\n",
    "eval_seed = []  # The evaluation seed of the environment\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1#0.95   # Exploration probability at start                     # old: 1\n",
    "min_epsilon = 0.05  # Minimum exploration probability\n",
    "decay_rate = 0.001  # Exponential decay rate for exploration prob           # old: 0.002\n",
    "\n",
    "\n",
    "grid_x, grid_v = initialize_grids()\n",
    "state_to_qtable = initialize_state_dict()\n",
    "\n",
    "# Training\n",
    "q_car = initialize_q_table(state_space, action_space)\n",
    "q_car, avg_rewards, total_steps = train(q_car)\n",
    "\n",
    "\n",
    "#\n",
    "# Plot Q values for random init training\n",
    "actions = np.max(q_car, axis=1)\n",
    "actions = actions.reshape((20, 20))\n",
    "plt.figure(figsize=(16, 12))\n",
    "ax = plt.subplot(111)\n",
    "ax = sns.heatmap(actions, annot=True)\n",
    "plt.ylim(0, 20)\n",
    "plt.xlabel(\"Position\", fontsize=20)\n",
    "plt.ylabel(\"Velocity\", fontsize=20)\n",
    "plt.title(\"Q values for optimal action - random init w/ lr decay\", fontdict={'fontsize': 25})\n",
    "# plt.savefig('plots/v_values_rand_decay')\n",
    "with open('plots/q_values.pkl','wb') as fid:\n",
    "    pickle.dump(ax, fid)\n",
    "plt.savefig('plots/q_values_rand_decay.png')\n",
    "plt.close()\n",
    "\n",
    "plot_steps(total_steps, 'rand_decay')\n",
    "plot_rewards(avg_rewards, 'rand_decay')\n",
    "\n",
    "# # Save Q table\n",
    "np.savetxt('data/q_rand_decay.txt', q_car)\n",
    "np.array(avg_rewards)\n",
    "np.savetxt('data/avg_rewards_rand_decay.txt', avg_rewards)\n",
    "np.array(total_steps)\n",
    "np.savetxt('data/total_steps_rand_decay.txt', total_steps)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ca530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import greedy_policy, initialize_grids, initialize_state_dict, get_closest_in_grid\n",
    "import matplotlib.image as img\n",
    "\n",
    "\n",
    "# Evaluation Parameters\n",
    "seed = []\n",
    "n_eval_episodes = 1\n",
    "max_steps = 10000\n",
    "\n",
    "# load q table\n",
    "q = np.loadtxt('data/q_rand_decay.txt')\n",
    "\n",
    "# initialize discretization\n",
    "grid_x, grid_v = initialize_grids()\n",
    "state_to_qtable = initialize_state_dict()\n",
    "\n",
    "# trace\n",
    "file = open('trace/trace_eval.txt', 'w')\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "for episode in range(n_eval_episodes):\n",
    "    if seed:\n",
    "        state = env.reset(seed=seed[episode])\n",
    "    else:\n",
    "        state = env.reset()[0]\n",
    "    step = 0\n",
    "    terminated = False\n",
    "    total_rewards_ep = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        action = greedy_policy(q, state, grid_x, grid_v, state_to_qtable)\n",
    "\n",
    "        # write current state and action taken to trace\n",
    "        file.write(f'{state[0]},{state[1]},{action}\\n')\n",
    "\n",
    "        new_state, reward, terminated, truncated, info = env.step(action)\n",
    "        total_rewards_ep += reward\n",
    "\n",
    "        if terminated:  # or truncated:\n",
    "            break\n",
    "        state = new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40daa0f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _backend_agg: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18988\\2940343755.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# plot trace onto plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m# ax.imshow(plot, extent=[0, 20, 0, 20])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'plots/q_values.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m     \u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1456\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[0m_pylab_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_active\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m     \u001b[0mallnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fignums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[0mnext_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallnums\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallnums\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;31m# If the manager explicitly overrides pyplot_show, use it even if a global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;31m# show is already present, as the latter may be here for backcompat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m     manager_class = getattr(getattr(backend_mod, \"FigureCanvas\", None),\n\u001b[0m\u001b[0;32m    327\u001b[0m                             \"manager_class\", None)\n\u001b[0;32m    328\u001b[0m     \u001b[1;31m# We can't compare directly manager_class.pyplot_show and FMB.pyplot_show because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m_warn_if_gui_out_of_main_thread\u001b[1;34m()\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_active\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                     \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m_get_backend_mod\u001b[1;34m()\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mSwitching\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteractive\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0monly\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mevent\u001b[0m \u001b[0mloop\u001b[0m \u001b[1;32mfor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0manother\u001b[0m \u001b[0minteractive\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mstarted\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mSwitching\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mfrom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[0mnon\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0minteractive\u001b[0m \u001b[0mbackends\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0malways\u001b[0m \u001b[0mpossible\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[1;34m(newbackend)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;31m# Classically, backends can directly export these functions.  This should\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# keep working for backcompat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m     \u001b[0mnew_figure_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_figure_manager\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"show\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbackend_mod\u001b[1;34m()\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# keep working for backcompat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[0mnew_figure_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_figure_manager\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"show\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;31m# In that classical approach, backends are implemented as modules, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib_inline\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_inline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"0.1.6\"\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_agg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend_agg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pylab_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBboxBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend_agg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRendererAgg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_RendererAgg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _backend_agg: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "trace = []\n",
    "actions = []\n",
    "\n",
    "# load trace and actions into list\n",
    "with open('trace/trace_eval.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        x, v, a = line.split(',')\n",
    "        trace.append((float(x), float(v)))\n",
    "        actions.append(int(a))\n",
    "\n",
    "# discretize trace\n",
    "trace_discrete = []\n",
    "grid_x, grid_v = initialize_grids()\n",
    "state_to_q = initialize_state_dict()\n",
    "for trac in trace:\n",
    "    # state = state_to_q[get_closest_in_grid(np.asarray(trac), grid_x, grid_v)]\n",
    "    x, v = get_closest_in_grid(np.asarray(trac), grid_x, grid_v)\n",
    "    state = [grid_x.index(x)+0.5, grid_v.index(v)+0.5]\n",
    "    trace_discrete.append(state)\n",
    "\n",
    "# load v values plot\n",
    "plot = img.imread('plots/q_values_rand_decay.png')\n",
    "\n",
    "# plot trace onto plot\n",
    "fig, ax = plt.subplots()\n",
    "# ax.imshow(plot, extent=[0, 20, 0, 20])\n",
    "with open('plots/q_values.pkl', 'rb') as fid:\n",
    "    ax = pickle.load(fid)\n",
    "ax.plot(*zip(*trace_discrete[::1]))\n",
    "\n",
    "# plot starting point\n",
    "sns.lineplot(x=[trace_discrete[0][0]], y=[trace_discrete[0][1]], marker='o', markersize=25, markeredgecolor='green', color='green', markeredgewidth=2)\n",
    "# plot finish point\n",
    "sns.lineplot(x=[trace_discrete[-1][0]+1], y=[trace_discrete[-1][1]], marker='o', markersize=25, markeredgecolor='red', color='red', markeredgewidth=2)\n",
    "\n",
    "ax.set_xticklabels(grid_x)\n",
    "ax.set_yticklabels(grid_v)\n",
    "plt.savefig('trace/trace.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbbc311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
